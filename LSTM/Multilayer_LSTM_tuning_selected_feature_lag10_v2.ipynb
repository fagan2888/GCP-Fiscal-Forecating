{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "* Country: United States, France, Germany, Japan, United Kingdom, Italy, Canada\n",
    "* Time period: 1950-2018, 69 years\n",
    "* Target variable: `ngdp_rpch` for annual data, `ngdp_r_sa_pcha` and `ngdp_r_sa_pchy` (respectively) for quarterly data\n",
    "* Train-test split: 1950-2009 (train, â‰¤ x  years, depends on data availability), x - y (test, z years)   \n",
    "  _Need further discussion. Here I divide the dataset by x/y just as the working paper did. Now for the ML model family we do not need to do such split._\n",
    "  \n",
    "* LSTM Model\n",
    "* CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Module 1: Importing the libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras = tf.keras\n",
    "\n",
    "# Print all outputs in a code block\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# from tf.random import set_seed\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# from keras.callbacks import ResetStatesCallback()\n",
    "\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten,Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # Use the %tensorflow_version magic if in colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import random\n",
    "# from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "\n",
    "seed_global = 42\n",
    "\n",
    "# Source: https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(seed_global)\n",
    "\n",
    "#  Giving an eror \n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(seed_global)\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/58638701/importerror-cannot-import-name-set-random-seed-from-tensorflow-c-users-po\n",
    "\n",
    "tf.random.set_seed(seed_global)\n",
    "\n",
    "# Copy paste this code snippet in every model code chunk \n",
    "seed(seed_global)\n",
    "tf.random.set_seed(seed_global)\n",
    "\n",
    "# --Ignore--\n",
    "# tf.random.set_seed(seed)\n",
    "# # This is giving me an error\n",
    "\n",
    "# #  Global Seed\n",
    "# # random.seed (2019) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery gdp_quarterly_q\n",
    "\n",
    "SELECT *\n",
    "FROM `deep-nexus.temp_for_imf_data.WEO_G7_Quarterly`\n",
    "ORDER BY time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "gdp_quarterly_q.year = (gdp_quarterly_q.time+40)//4 + 1950\n",
    "gdp_quarterly_q.quarter = (gdp_quarterly_q.time+40)%4 + 1\n",
    "gdp_quarterly_q.time = gdp_quarterly_q.year.astype('str') + 'Q' + gdp_quarterly_q.quarter.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>ifscode</th>\n",
       "      <th>time</th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>...</th>\n",
       "      <th>pcpi_sa</th>\n",
       "      <th>pcpi_sa_pcha</th>\n",
       "      <th>pcpi_sa_pchy</th>\n",
       "      <th>pppgdp</th>\n",
       "      <th>pppsh</th>\n",
       "      <th>pppwgt</th>\n",
       "      <th>tmgwgt</th>\n",
       "      <th>tmwgt</th>\n",
       "      <th>txgwgt</th>\n",
       "      <th>txwgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>111</td>\n",
       "      <td>1950Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>112</td>\n",
       "      <td>1950Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.776393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.776393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>132</td>\n",
       "      <td>1950Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.016824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.016824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>134</td>\n",
       "      <td>1950Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>136</td>\n",
       "      <td>1950Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  ifscode    time  gdpwgt  lc  le       llf  lulcm  lur  \\\n",
       "0   United States      111  1950Q1     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "1  United Kingdom      112  1950Q1     NaN NaN NaN       NaN    NaN  NaN   \n",
       "2          France      132  1950Q1     NaN NaN NaN       NaN    NaN  NaN   \n",
       "3         Germany      134  1950Q1     NaN NaN NaN       NaN    NaN  NaN   \n",
       "4           Italy      136  1950Q1     NaN NaN NaN       NaN    NaN  NaN   \n",
       "\n",
       "   ncg_r  ...  pcpi_sa  pcpi_sa_pcha  pcpi_sa_pchy      pppgdp  pppsh  \\\n",
       "0    NaN  ...      NaN           NaN           NaN  301.782705    NaN   \n",
       "1    NaN  ...      NaN           NaN           NaN   72.776393    NaN   \n",
       "2    NaN  ...      NaN           NaN           NaN   47.016824    NaN   \n",
       "3    NaN  ...      NaN           NaN           NaN         NaN    NaN   \n",
       "4    NaN  ...      NaN           NaN           NaN         NaN    NaN   \n",
       "\n",
       "       pppwgt  tmgwgt  tmwgt  txgwgt  txwgt  \n",
       "0  301.782705     NaN    NaN     NaN    NaN  \n",
       "1   72.776393     NaN    NaN     NaN    NaN  \n",
       "2   47.016824     NaN    NaN     NaN    NaN  \n",
       "3         NaN     NaN    NaN     NaN    NaN  \n",
       "4         NaN     NaN    NaN     NaN    NaN  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_quarterly_q = pd.DataFrame(gdp_quarterly_q)\n",
    "gdp_quarterly_q.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States', 'United Kingdom', 'France', 'Germany', 'Italy',\n",
       "       'Canada', 'Japan'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Countries: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['United States']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting a subset of countries\n",
    "gdp_quarterly_q.country.unique()\n",
    "\n",
    "selected_countries = list(gdp_quarterly_q.country.unique())[0:1]\n",
    "print(\"\\nSelected Countries: \\n\")\n",
    "selected_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_2 = gdp_quarterly_q\n",
    "\n",
    "# for i in selected_countries:\n",
    "#    dataset_2[i] = gdp_quarterly_q[gdp_quarterly_q['country'] == i]\n",
    "\n",
    "# https://stackoverflow.com/questions/51583888/concatenate-dataframe-name-with-variable-value-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Forest Regressor\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # random forest model creation\n",
    "\n",
    "# # Set Seed\n",
    "# seed(seed_global)\n",
    "# tensorflow.random.set_seed(seed_global)\n",
    "\n",
    "\n",
    "# rfr = RandomForestRegressor(n_estimators = 1000)\n",
    "\n",
    "# rfr.fit(X_train, y_train)\n",
    "\n",
    "# # predictions\n",
    "# y_pred = rfr.predict(X_test)\n",
    "\n",
    "# metrics_mse[\"random_forest\"] =  mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# print(\"Random Forest Test MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Variable Importance\n",
    "\n",
    "# # Top i factors by importance\n",
    "\n",
    "# i = 20\n",
    "# importances = rf_reg.feature_importances_\n",
    "# indices = np.argsort(importances)[-(i-1):]\n",
    "# features = X.columns\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "# plt.title('Feature Importances - Random Forest Regressor')\n",
    "# plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "# plt.yticks(range(len(indices)), features[indices])\n",
    "# plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>ifscode</th>\n",
       "      <th>time</th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>...</th>\n",
       "      <th>pcpi_sa</th>\n",
       "      <th>pcpi_sa_pcha</th>\n",
       "      <th>pcpi_sa_pchy</th>\n",
       "      <th>pppgdp</th>\n",
       "      <th>pppsh</th>\n",
       "      <th>pppwgt</th>\n",
       "      <th>tmgwgt</th>\n",
       "      <th>tmwgt</th>\n",
       "      <th>txgwgt</th>\n",
       "      <th>txwgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>111</td>\n",
       "      <td>1950Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>United States</td>\n",
       "      <td>111</td>\n",
       "      <td>1950Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>United States</td>\n",
       "      <td>111</td>\n",
       "      <td>1950Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>United States</td>\n",
       "      <td>111</td>\n",
       "      <td>1950Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.782705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>United States</td>\n",
       "      <td>111</td>\n",
       "      <td>1951Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.993057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.993057</td>\n",
       "      <td>8.709073</td>\n",
       "      <td>11.508033</td>\n",
       "      <td>10.159067</td>\n",
       "      <td>12.875869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  ifscode    time  gdpwgt  lc  le       llf  lulcm  lur  \\\n",
       "0   United States      111  1950Q1     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "7   United States      111  1950Q2     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "14  United States      111  1950Q3     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "21  United States      111  1950Q4     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "28  United States      111  1951Q1     NaN NaN NaN  0.062002    NaN  NaN   \n",
       "\n",
       "    ncg_r  ...  pcpi_sa  pcpi_sa_pcha  pcpi_sa_pchy      pppgdp  pppsh  \\\n",
       "0     NaN  ...      NaN           NaN           NaN  301.782705    NaN   \n",
       "7     NaN  ...      NaN           NaN           NaN  301.782705    NaN   \n",
       "14    NaN  ...      NaN           NaN           NaN  301.782705    NaN   \n",
       "21    NaN  ...      NaN           NaN           NaN  301.782705    NaN   \n",
       "28    NaN  ...      NaN           NaN           NaN  348.993057    NaN   \n",
       "\n",
       "        pppwgt    tmgwgt      tmwgt     txgwgt      txwgt  \n",
       "0   301.782705       NaN        NaN        NaN        NaN  \n",
       "7   301.782705       NaN        NaN        NaN        NaN  \n",
       "14  301.782705       NaN        NaN        NaN        NaN  \n",
       "21  301.782705       NaN        NaN        NaN        NaN  \n",
       "28  348.993057  8.709073  11.508033  10.159067  12.875869  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter data by country\n",
    "\n",
    "dataset = gdp_quarterly_q[gdp_quarterly_q['country'].isin(selected_countries)]\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "# print (\"#\", \"column name\", \"missing values\")\n",
    "# for i in range(len(dataset.columns)):\n",
    "#     print(i, dataset.columns[i], \" \", dataset.iloc[i].isnull().count())\n",
    "\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>ncp_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>pcpi_sa</th>\n",
       "      <th>pcpi_sa_pcha</th>\n",
       "      <th>pcpi_sa_pchy</th>\n",
       "      <th>pppgdp</th>\n",
       "      <th>pppsh</th>\n",
       "      <th>pppwgt</th>\n",
       "      <th>tmgwgt</th>\n",
       "      <th>tmwgt</th>\n",
       "      <th>txgwgt</th>\n",
       "      <th>txwgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10628.0</td>\n",
       "      <td>153.952333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.571</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2565.6</td>\n",
       "      <td>0.469925</td>\n",
       "      <td>12729.7</td>\n",
       "      <td>1.139334</td>\n",
       "      <td>...</td>\n",
       "      <td>247.273333</td>\n",
       "      <td>3.141889</td>\n",
       "      <td>2.109865</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>15.284951</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>2221.075</td>\n",
       "      <td>2739.425</td>\n",
       "      <td>1444.025</td>\n",
       "      <td>2220.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10786.0</td>\n",
       "      <td>154.951667</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>111.839</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>2578.3</td>\n",
       "      <td>0.495011</td>\n",
       "      <td>12782.9</td>\n",
       "      <td>0.417920</td>\n",
       "      <td>...</td>\n",
       "      <td>249.250333</td>\n",
       "      <td>3.236639</td>\n",
       "      <td>2.222997</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10876.1</td>\n",
       "      <td>155.449000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.132</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>0.531358</td>\n",
       "      <td>12909.2</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>...</td>\n",
       "      <td>250.578667</td>\n",
       "      <td>2.148827</td>\n",
       "      <td>2.668825</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10994.3</td>\n",
       "      <td>155.879000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.681</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.540123</td>\n",
       "      <td>13019.8</td>\n",
       "      <td>0.856753</td>\n",
       "      <td>...</td>\n",
       "      <td>251.828667</td>\n",
       "      <td>2.010362</td>\n",
       "      <td>2.632912</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>11057.4</td>\n",
       "      <td>156.776667</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>111.370</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2605.7</td>\n",
       "      <td>-0.011512</td>\n",
       "      <td>13066.3</td>\n",
       "      <td>0.357148</td>\n",
       "      <td>...</td>\n",
       "      <td>252.759000</td>\n",
       "      <td>1.485933</td>\n",
       "      <td>2.218463</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gdpwgt       lc          le       llf    lulcm       lur   ncg_r  \\\n",
       "1897  18155.700000  10628.0  153.952333  0.160311  110.571  4.133333  2565.6   \n",
       "1904  18819.741667  10786.0  154.951667  0.162071  111.839  4.066667  2578.3   \n",
       "1911  18819.741667  10876.1  155.449000  0.162071  110.132  3.900000  2592.0   \n",
       "1918  18819.741667  10994.3  155.879000  0.162071  110.681  3.800000  2606.0   \n",
       "1925  18819.741667  11057.4  156.776667  0.162071  111.370  3.800000  2605.7   \n",
       "\n",
       "      ncg_rpch    ncp_r  ncp_rpch  ...     pcpi_sa  pcpi_sa_pcha  \\\n",
       "1897  0.469925  12729.7  1.139334  ...  247.273333      3.141889   \n",
       "1904  0.495011  12782.9  0.417920  ...  249.250333      3.236639   \n",
       "1911  0.531358  12909.2  0.988039  ...  250.578667      2.148827   \n",
       "1918  0.540123  13019.8  0.856753  ...  251.828667      2.010362   \n",
       "1925 -0.011512  13066.3  0.357148  ...  252.759000      1.485933   \n",
       "\n",
       "      pcpi_sa_pchy    pppgdp      pppsh    pppwgt    tmgwgt     tmwgt  \\\n",
       "1897      2.109865  19519.40  15.284951  19519.40  2221.075  2739.425   \n",
       "1904      2.222997  20580.25  15.195560  20580.25  2379.800  2932.075   \n",
       "1911      2.668825  20580.25  15.195560  20580.25  2379.800  2932.075   \n",
       "1918      2.632912  20580.25  15.195560  20580.25  2379.800  2932.075   \n",
       "1925      2.218463  20580.25  15.195560  20580.25  2379.800  2932.075   \n",
       "\n",
       "        txgwgt     txwgt  \n",
       "1897  1444.025  2220.625  \n",
       "1904  1538.375  2356.725  \n",
       "1911  1538.375  2356.725  \n",
       "1918  1538.375  2356.725  \n",
       "1925  1538.375  2356.725  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input = dataset\n",
    "dataset_input = dataset_input.drop(columns = ['country', 'ifscode', 'time', 'ngdp_r_sa_pcha', 'ngdp_r_sa_pchy', 'ngdp_dpchy'])\n",
    "dataset_input.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>ncp_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>pppgdp</th>\n",
       "      <th>pppsh</th>\n",
       "      <th>pppwgt</th>\n",
       "      <th>tmgwgt</th>\n",
       "      <th>tmwgt</th>\n",
       "      <th>txgwgt</th>\n",
       "      <th>txwgt</th>\n",
       "      <th>time</th>\n",
       "      <th>ngdp_r_sa_pcha</th>\n",
       "      <th>1_step_ahead_ngdp_r_sa_pcha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10456.7</td>\n",
       "      <td>153.815333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.185</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2553.6</td>\n",
       "      <td>0.145104</td>\n",
       "      <td>12586.3</td>\n",
       "      <td>0.586595</td>\n",
       "      <td>...</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>15.284951</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>2221.075</td>\n",
       "      <td>2739.425</td>\n",
       "      <td>1444.025</td>\n",
       "      <td>2220.625</td>\n",
       "      <td>2017Q3</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>3.545494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10628.0</td>\n",
       "      <td>153.952333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.571</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2565.6</td>\n",
       "      <td>0.469925</td>\n",
       "      <td>12729.7</td>\n",
       "      <td>1.139334</td>\n",
       "      <td>...</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>15.284951</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>2221.075</td>\n",
       "      <td>2739.425</td>\n",
       "      <td>1444.025</td>\n",
       "      <td>2220.625</td>\n",
       "      <td>2017Q4</td>\n",
       "      <td>3.545494</td>\n",
       "      <td>2.552107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10786.0</td>\n",
       "      <td>154.951667</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>111.839</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>2578.3</td>\n",
       "      <td>0.495011</td>\n",
       "      <td>12782.9</td>\n",
       "      <td>0.417920</td>\n",
       "      <td>...</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "      <td>2018Q1</td>\n",
       "      <td>2.552107</td>\n",
       "      <td>3.512025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10876.1</td>\n",
       "      <td>155.449000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.132</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>0.531358</td>\n",
       "      <td>12909.2</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>...</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "      <td>2018Q2</td>\n",
       "      <td>3.512025</td>\n",
       "      <td>2.926498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10994.3</td>\n",
       "      <td>155.879000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.681</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.540123</td>\n",
       "      <td>13019.8</td>\n",
       "      <td>0.856753</td>\n",
       "      <td>...</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "      <td>2018Q3</td>\n",
       "      <td>2.926498</td>\n",
       "      <td>1.089155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gdpwgt       lc          le       llf    lulcm       lur   ncg_r  \\\n",
       "1890  18155.700000  10456.7  153.815333  0.160311  110.185  4.300000  2553.6   \n",
       "1897  18155.700000  10628.0  153.952333  0.160311  110.571  4.133333  2565.6   \n",
       "1904  18819.741667  10786.0  154.951667  0.162071  111.839  4.066667  2578.3   \n",
       "1911  18819.741667  10876.1  155.449000  0.162071  110.132  3.900000  2592.0   \n",
       "1918  18819.741667  10994.3  155.879000  0.162071  110.681  3.800000  2606.0   \n",
       "\n",
       "      ncg_rpch    ncp_r  ncp_rpch  ...    pppgdp      pppsh    pppwgt  \\\n",
       "1890  0.145104  12586.3  0.586595  ...  19519.40  15.284951  19519.40   \n",
       "1897  0.469925  12729.7  1.139334  ...  19519.40  15.284951  19519.40   \n",
       "1904  0.495011  12782.9  0.417920  ...  20580.25  15.195560  20580.25   \n",
       "1911  0.531358  12909.2  0.988039  ...  20580.25  15.195560  20580.25   \n",
       "1918  0.540123  13019.8  0.856753  ...  20580.25  15.195560  20580.25   \n",
       "\n",
       "        tmgwgt     tmwgt    txgwgt     txwgt    time  ngdp_r_sa_pcha  \\\n",
       "1890  2221.075  2739.425  1444.025  2220.625  2017Q3        3.202964   \n",
       "1897  2221.075  2739.425  1444.025  2220.625  2017Q4        3.545494   \n",
       "1904  2379.800  2932.075  1538.375  2356.725  2018Q1        2.552107   \n",
       "1911  2379.800  2932.075  1538.375  2356.725  2018Q2        3.512025   \n",
       "1918  2379.800  2932.075  1538.375  2356.725  2018Q3        2.926498   \n",
       "\n",
       "      1_step_ahead_ngdp_r_sa_pcha  \n",
       "1890                     3.545494  \n",
       "1897                     2.552107  \n",
       "1904                     3.512025  \n",
       "1911                     2.926498  \n",
       "1918                     1.089155  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outcome vaiable (Column Name) = ngdp_r_sa_pcha\n",
    "\n",
    "outcome_variable = \"ngdp_r_sa_pcha\"\n",
    "predicted_variable = \"1_step_ahead_\" + outcome_variable\n",
    "\n",
    "dataset_1 = dataset_input\n",
    "dataset_1[\"time\"] = dataset[\"time\"]\n",
    "# dataset_1[num_cols] = dataset[num_cols]\n",
    "dataset_1[outcome_variable] = dataset[outcome_variable]\n",
    "\n",
    "dataset_1[predicted_variable] = dataset_1[outcome_variable].shift(-1)\n",
    "\n",
    "# # Source: https://stackoverflow.com/questions/20095673/shift-column-in-pandas-dataframe-up-by-one\n",
    "\n",
    "dataset_1 = dataset_1[:-1] \n",
    "\n",
    "dataset_1.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>1_step_ahead_ngdp_r_sa_pcha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>2017Q3</td>\n",
       "      <td>3.545494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>2017Q4</td>\n",
       "      <td>2.552107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2018Q1</td>\n",
       "      <td>3.512025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>2018Q2</td>\n",
       "      <td>2.926498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2018Q3</td>\n",
       "      <td>1.089155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  1_step_ahead_ngdp_r_sa_pcha\n",
       "1890  2017Q3                     3.545494\n",
       "1897  2017Q4                     2.552107\n",
       "1904  2018Q1                     3.512025\n",
       "1911  2018Q2                     2.926498\n",
       "1918  2018Q3                     1.089155"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Columns\n",
    "\n",
    "# ngdp_r_sa_pcha: WEO: Gross domestic product, constant prices, seasonally adjusted, quarter-over-quarter percent change, annualized (Percent, Units).\n",
    "\n",
    "dataset_Y = dataset_1[[\"time\", predicted_variable]]\n",
    "dataset_Y.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before adding the lagged variables to the input dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>ncp_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>pcpi_sa_pcha</th>\n",
       "      <th>pcpi_sa_pchy</th>\n",
       "      <th>pppgdp</th>\n",
       "      <th>pppsh</th>\n",
       "      <th>pppwgt</th>\n",
       "      <th>tmgwgt</th>\n",
       "      <th>tmwgt</th>\n",
       "      <th>txgwgt</th>\n",
       "      <th>txwgt</th>\n",
       "      <th>ngdp_r_sa_pcha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10456.7</td>\n",
       "      <td>153.815333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.185</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2553.6</td>\n",
       "      <td>0.145104</td>\n",
       "      <td>12586.3</td>\n",
       "      <td>0.586595</td>\n",
       "      <td>...</td>\n",
       "      <td>2.153214</td>\n",
       "      <td>1.981427</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>15.284951</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>2221.075</td>\n",
       "      <td>2739.425</td>\n",
       "      <td>1444.025</td>\n",
       "      <td>2220.625</td>\n",
       "      <td>3.202964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10628.0</td>\n",
       "      <td>153.952333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.571</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2565.6</td>\n",
       "      <td>0.469925</td>\n",
       "      <td>12729.7</td>\n",
       "      <td>1.139334</td>\n",
       "      <td>...</td>\n",
       "      <td>3.141889</td>\n",
       "      <td>2.109865</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>15.284951</td>\n",
       "      <td>19519.40</td>\n",
       "      <td>2221.075</td>\n",
       "      <td>2739.425</td>\n",
       "      <td>1444.025</td>\n",
       "      <td>2220.625</td>\n",
       "      <td>3.545494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10786.0</td>\n",
       "      <td>154.951667</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>111.839</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>2578.3</td>\n",
       "      <td>0.495011</td>\n",
       "      <td>12782.9</td>\n",
       "      <td>0.417920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.236639</td>\n",
       "      <td>2.222997</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "      <td>2.552107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10876.1</td>\n",
       "      <td>155.449000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.132</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>0.531358</td>\n",
       "      <td>12909.2</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>...</td>\n",
       "      <td>2.148827</td>\n",
       "      <td>2.668825</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "      <td>3.512025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10994.3</td>\n",
       "      <td>155.879000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.681</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.540123</td>\n",
       "      <td>13019.8</td>\n",
       "      <td>0.856753</td>\n",
       "      <td>...</td>\n",
       "      <td>2.010362</td>\n",
       "      <td>2.632912</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>15.195560</td>\n",
       "      <td>20580.25</td>\n",
       "      <td>2379.800</td>\n",
       "      <td>2932.075</td>\n",
       "      <td>1538.375</td>\n",
       "      <td>2356.725</td>\n",
       "      <td>2.926498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gdpwgt       lc          le       llf    lulcm       lur   ncg_r  \\\n",
       "1890  18155.700000  10456.7  153.815333  0.160311  110.185  4.300000  2553.6   \n",
       "1897  18155.700000  10628.0  153.952333  0.160311  110.571  4.133333  2565.6   \n",
       "1904  18819.741667  10786.0  154.951667  0.162071  111.839  4.066667  2578.3   \n",
       "1911  18819.741667  10876.1  155.449000  0.162071  110.132  3.900000  2592.0   \n",
       "1918  18819.741667  10994.3  155.879000  0.162071  110.681  3.800000  2606.0   \n",
       "\n",
       "      ncg_rpch    ncp_r  ncp_rpch  ...  pcpi_sa_pcha  pcpi_sa_pchy    pppgdp  \\\n",
       "1890  0.145104  12586.3  0.586595  ...      2.153214      1.981427  19519.40   \n",
       "1897  0.469925  12729.7  1.139334  ...      3.141889      2.109865  19519.40   \n",
       "1904  0.495011  12782.9  0.417920  ...      3.236639      2.222997  20580.25   \n",
       "1911  0.531358  12909.2  0.988039  ...      2.148827      2.668825  20580.25   \n",
       "1918  0.540123  13019.8  0.856753  ...      2.010362      2.632912  20580.25   \n",
       "\n",
       "          pppsh    pppwgt    tmgwgt     tmwgt    txgwgt     txwgt  \\\n",
       "1890  15.284951  19519.40  2221.075  2739.425  1444.025  2220.625   \n",
       "1897  15.284951  19519.40  2221.075  2739.425  1444.025  2220.625   \n",
       "1904  15.195560  20580.25  2379.800  2932.075  1538.375  2356.725   \n",
       "1911  15.195560  20580.25  2379.800  2932.075  1538.375  2356.725   \n",
       "1918  15.195560  20580.25  2379.800  2932.075  1538.375  2356.725   \n",
       "\n",
       "      ngdp_r_sa_pcha  \n",
       "1890        3.202964  \n",
       "1897        3.545494  \n",
       "1904        2.552107  \n",
       "1911        3.512025  \n",
       "1918        2.926498  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding the lagged variables to the input dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>ncp_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10456.7</td>\n",
       "      <td>153.815333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.185</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2553.6</td>\n",
       "      <td>0.145104</td>\n",
       "      <td>12586.3</td>\n",
       "      <td>0.586595</td>\n",
       "      <td>...</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>1.327969</td>\n",
       "      <td>2.998835</td>\n",
       "      <td>3.177823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10628.0</td>\n",
       "      <td>153.952333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.571</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2565.6</td>\n",
       "      <td>0.469925</td>\n",
       "      <td>12729.7</td>\n",
       "      <td>1.139334</td>\n",
       "      <td>...</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>1.327969</td>\n",
       "      <td>2.998835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10786.0</td>\n",
       "      <td>154.951667</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>111.839</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>2578.3</td>\n",
       "      <td>0.495011</td>\n",
       "      <td>12782.9</td>\n",
       "      <td>0.417920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.545494</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>1.327969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10876.1</td>\n",
       "      <td>155.449000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.132</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>0.531358</td>\n",
       "      <td>12909.2</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>...</td>\n",
       "      <td>2.552107</td>\n",
       "      <td>3.545494</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "      <td>0.130624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10994.3</td>\n",
       "      <td>155.879000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.681</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.540123</td>\n",
       "      <td>13019.8</td>\n",
       "      <td>0.856753</td>\n",
       "      <td>...</td>\n",
       "      <td>3.512025</td>\n",
       "      <td>2.552107</td>\n",
       "      <td>3.545494</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gdpwgt       lc          le       llf    lulcm       lur   ncg_r  \\\n",
       "1890  18155.700000  10456.7  153.815333  0.160311  110.185  4.300000  2553.6   \n",
       "1897  18155.700000  10628.0  153.952333  0.160311  110.571  4.133333  2565.6   \n",
       "1904  18819.741667  10786.0  154.951667  0.162071  111.839  4.066667  2578.3   \n",
       "1911  18819.741667  10876.1  155.449000  0.162071  110.132  3.900000  2592.0   \n",
       "1918  18819.741667  10994.3  155.879000  0.162071  110.681  3.800000  2606.0   \n",
       "\n",
       "      ncg_rpch    ncp_r  ncp_rpch  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "1890  0.145104  12586.3  0.586595  ...          2.152692          2.288202   \n",
       "1897  0.469925  12729.7  1.139334  ...          3.202964          2.152692   \n",
       "1904  0.495011  12782.9  0.417920  ...          3.545494          3.202964   \n",
       "1911  0.531358  12909.2  0.988039  ...          2.552107          3.545494   \n",
       "1918  0.540123  13019.8  0.856753  ...          3.512025          2.552107   \n",
       "\n",
       "      ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "1890          2.024769          2.187866          1.895214          2.027962   \n",
       "1897          2.288202          2.024769          2.187866          1.895214   \n",
       "1904          2.152692          2.288202          2.024769          2.187866   \n",
       "1911          3.202964          2.152692          2.288202          2.024769   \n",
       "1918          3.545494          3.202964          2.152692          2.288202   \n",
       "\n",
       "      ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "1890          0.130624          1.327969          2.998835           3.177823  \n",
       "1897          2.027962          0.130624          1.327969           2.998835  \n",
       "1904          1.895214          2.027962          0.130624           1.327969  \n",
       "1911          2.187866          1.895214          2.027962           0.130624  \n",
       "1918          2.024769          2.187866          1.895214           2.027962  \n",
       "\n",
       "[5 rows x 671 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Window size and crearting the lagged columns\n",
    "\n",
    "#  Using a lag = 0 for identifying initial variable importance by fitting a randowm forest \n",
    "# window size \n",
    "lag = 10\n",
    "dataset_input_l = dataset_1\n",
    "\n",
    "# Drop the 1) preducted outcome variable and 2) time variable \n",
    "\n",
    "dataset_input_l = dataset_input_l.drop(columns = [\"time\", predicted_variable])\n",
    "\n",
    "print(\"Before adding the lagged variables to the input dataset: \")\n",
    "dataset_input_l.tail(5)\n",
    "\n",
    "# Lagging each column in num_columns by the entire range of lag factors\n",
    "\n",
    "for j in dataset_input_l.columns:\n",
    "    for i in range(1, (lag + 1), 1):\n",
    "        new_col = str(j)+\"-\"+str(i)\n",
    "        dataset_input_l[str(new_col)] = dataset_input_l[str(j)].shift(i)\n",
    "    \n",
    "print(\"After adding the lagged variables to the input dataset: \")\n",
    "dataset_input_l.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>1_step_ahead_ngdp_r_sa_pcha</th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1950Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1950Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1950Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1951Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 673 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time  1_step_ahead_ngdp_r_sa_pcha  gdpwgt  lc  le       llf  lulcm  lur  \\\n",
       "0   1950Q1                          NaN     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "7   1950Q2                          NaN     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "14  1950Q3                          NaN     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "21  1950Q4                          NaN     NaN NaN NaN  0.062128    NaN  NaN   \n",
       "28  1951Q1                          NaN     NaN NaN NaN  0.062002    NaN  NaN   \n",
       "\n",
       "    ncg_r  ncg_rpch  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "0     NaN       NaN  ...               NaN               NaN   \n",
       "7     NaN       NaN  ...               NaN               NaN   \n",
       "14    NaN       NaN  ...               NaN               NaN   \n",
       "21    NaN       NaN  ...               NaN               NaN   \n",
       "28    NaN       NaN  ...               NaN               NaN   \n",
       "\n",
       "    ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "0                NaN               NaN               NaN               NaN   \n",
       "7                NaN               NaN               NaN               NaN   \n",
       "14               NaN               NaN               NaN               NaN   \n",
       "21               NaN               NaN               NaN               NaN   \n",
       "28               NaN               NaN               NaN               NaN   \n",
       "\n",
       "    ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "0                NaN               NaN               NaN                NaN  \n",
       "7                NaN               NaN               NaN                NaN  \n",
       "14               NaN               NaN               NaN                NaN  \n",
       "21               NaN               NaN               NaN                NaN  \n",
       "28               NaN               NaN               NaN                NaN  \n",
       "\n",
       "[5 rows x 673 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(275, 673)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns names:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['time', '1_step_ahead_ngdp_r_sa_pcha', 'gdpwgt', 'lc', 'le', 'llf',\n",
       "       'lulcm', 'lur', 'ncg_r', 'ncg_rpch',\n",
       "       ...\n",
       "       'ngdp_r_sa_pcha-1', 'ngdp_r_sa_pcha-2', 'ngdp_r_sa_pcha-3',\n",
       "       'ngdp_r_sa_pcha-4', 'ngdp_r_sa_pcha-5', 'ngdp_r_sa_pcha-6',\n",
       "       'ngdp_r_sa_pcha-7', 'ngdp_r_sa_pcha-8', 'ngdp_r_sa_pcha-9',\n",
       "       'ngdp_r_sa_pcha-10'],\n",
       "      dtype='object', length=673)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining Input and Output Values\n",
    "\n",
    "# X1 = dataset_input\n",
    "# X = pd.concat([X1, X2, dataset_Y], axis=1)\n",
    "X = pd.concat([dataset_Y, dataset_input_l], axis=1)\n",
    "X.head(5)\n",
    "X.shape\n",
    "\n",
    "print(\"\\nColumns names:\\n\")\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After dropping rows with missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145, 673)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>1_step_ahead_ngdp_r_sa_pcha</th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>1982Q3</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>2897.225</td>\n",
       "      <td>1904.8</td>\n",
       "      <td>99.543333</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>92.663</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>1515.5</td>\n",
       "      <td>1.026598</td>\n",
       "      <td>...</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "      <td>-7.985864</td>\n",
       "      <td>1.261758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1982Q4</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>2897.225</td>\n",
       "      <td>1918.1</td>\n",
       "      <td>99.119667</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>93.691</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>1532.7</td>\n",
       "      <td>1.134939</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "      <td>-7.985864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>1983Q1</td>\n",
       "      <td>9.421777</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>1947.2</td>\n",
       "      <td>99.143000</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>92.971</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>1549.5</td>\n",
       "      <td>1.096105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>1983Q2</td>\n",
       "      <td>8.238399</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>1986.3</td>\n",
       "      <td>99.945000</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>92.457</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>1561.6</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>...</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>1983Q3</td>\n",
       "      <td>8.609839</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>2029.6</td>\n",
       "      <td>101.610667</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>91.532</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>1580.2</td>\n",
       "      <td>1.191086</td>\n",
       "      <td>...</td>\n",
       "      <td>9.421777</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 673 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  1_step_ahead_ngdp_r_sa_pcha    gdpwgt      lc          le  \\\n",
       "910  1982Q3                     0.158923  2897.225  1904.8   99.543333   \n",
       "917  1982Q4                     5.373663  2897.225  1918.1   99.119667   \n",
       "924  1983Q1                     9.421777  3136.050  1947.2   99.143000   \n",
       "931  1983Q2                     8.238399  3136.050  1986.3   99.945000   \n",
       "938  1983Q3                     8.609839  3136.050  2029.6  101.610667   \n",
       "\n",
       "          llf   lulcm        lur   ncg_r  ncg_rpch  ...  ngdp_r_sa_pcha-1  \\\n",
       "910  0.110231  92.663   9.900000  1515.5  1.026598  ...          1.837425   \n",
       "917  0.110231  93.691  10.666667  1532.7  1.134939  ...         -1.520719   \n",
       "924  0.111528  92.971  10.366667  1549.5  1.096105  ...          0.158923   \n",
       "931  0.111528  92.457  10.133333  1561.6  0.780897  ...          5.373663   \n",
       "938  0.111528  91.532   9.366667  1580.2  1.191086  ...          9.421777   \n",
       "\n",
       "     ngdp_r_sa_pcha-2  ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  \\\n",
       "910         -6.069358         -4.285831          4.872232         -2.926867   \n",
       "917          1.837425         -6.069358         -4.285831          4.872232   \n",
       "924         -1.520719          1.837425         -6.069358         -4.285831   \n",
       "931          0.158923         -1.520719          1.837425         -6.069358   \n",
       "938          5.373663          0.158923         -1.520719          1.837425   \n",
       "\n",
       "     ngdp_r_sa_pcha-6  ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  \\\n",
       "910          8.070747          7.668385         -0.476985         -7.985864   \n",
       "917         -2.926867          8.070747          7.668385         -0.476985   \n",
       "924          4.872232         -2.926867          8.070747          7.668385   \n",
       "931         -4.285831          4.872232         -2.926867          8.070747   \n",
       "938         -6.069358         -4.285831          4.872232         -2.926867   \n",
       "\n",
       "     ngdp_r_sa_pcha-10  \n",
       "910           1.261758  \n",
       "917          -7.985864  \n",
       "924          -0.476985  \n",
       "931           7.668385  \n",
       "938           8.070747  \n",
       "\n",
       "[5 rows x 673 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>1_step_ahead_ngdp_r_sa_pcha</th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>2017Q3</td>\n",
       "      <td>3.545494</td>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10456.7</td>\n",
       "      <td>153.815333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.185</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2553.6</td>\n",
       "      <td>0.145104</td>\n",
       "      <td>...</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>1.327969</td>\n",
       "      <td>2.998835</td>\n",
       "      <td>3.177823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>2017Q4</td>\n",
       "      <td>2.552107</td>\n",
       "      <td>18155.700000</td>\n",
       "      <td>10628.0</td>\n",
       "      <td>153.952333</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>110.571</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2565.6</td>\n",
       "      <td>0.469925</td>\n",
       "      <td>...</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>1.327969</td>\n",
       "      <td>2.998835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2018Q1</td>\n",
       "      <td>3.512025</td>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10786.0</td>\n",
       "      <td>154.951667</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>111.839</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>2578.3</td>\n",
       "      <td>0.495011</td>\n",
       "      <td>...</td>\n",
       "      <td>3.545494</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>1.327969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>2018Q2</td>\n",
       "      <td>2.926498</td>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10876.1</td>\n",
       "      <td>155.449000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.132</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>0.531358</td>\n",
       "      <td>...</td>\n",
       "      <td>2.552107</td>\n",
       "      <td>3.545494</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "      <td>0.130624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2018Q3</td>\n",
       "      <td>1.089155</td>\n",
       "      <td>18819.741667</td>\n",
       "      <td>10994.3</td>\n",
       "      <td>155.879000</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>110.681</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.540123</td>\n",
       "      <td>...</td>\n",
       "      <td>3.512025</td>\n",
       "      <td>2.552107</td>\n",
       "      <td>3.545494</td>\n",
       "      <td>3.202964</td>\n",
       "      <td>2.152692</td>\n",
       "      <td>2.288202</td>\n",
       "      <td>2.024769</td>\n",
       "      <td>2.187866</td>\n",
       "      <td>1.895214</td>\n",
       "      <td>2.027962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 673 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  1_step_ahead_ngdp_r_sa_pcha        gdpwgt       lc          le  \\\n",
       "1890  2017Q3                     3.545494  18155.700000  10456.7  153.815333   \n",
       "1897  2017Q4                     2.552107  18155.700000  10628.0  153.952333   \n",
       "1904  2018Q1                     3.512025  18819.741667  10786.0  154.951667   \n",
       "1911  2018Q2                     2.926498  18819.741667  10876.1  155.449000   \n",
       "1918  2018Q3                     1.089155  18819.741667  10994.3  155.879000   \n",
       "\n",
       "           llf    lulcm       lur   ncg_r  ncg_rpch  ...  ngdp_r_sa_pcha-1  \\\n",
       "1890  0.160311  110.185  4.300000  2553.6  0.145104  ...          2.152692   \n",
       "1897  0.160311  110.571  4.133333  2565.6  0.469925  ...          3.202964   \n",
       "1904  0.162071  111.839  4.066667  2578.3  0.495011  ...          3.545494   \n",
       "1911  0.162071  110.132  3.900000  2592.0  0.531358  ...          2.552107   \n",
       "1918  0.162071  110.681  3.800000  2606.0  0.540123  ...          3.512025   \n",
       "\n",
       "      ngdp_r_sa_pcha-2  ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  \\\n",
       "1890          2.288202          2.024769          2.187866          1.895214   \n",
       "1897          2.152692          2.288202          2.024769          2.187866   \n",
       "1904          3.202964          2.152692          2.288202          2.024769   \n",
       "1911          3.545494          3.202964          2.152692          2.288202   \n",
       "1918          2.552107          3.545494          3.202964          2.152692   \n",
       "\n",
       "      ngdp_r_sa_pcha-6  ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  \\\n",
       "1890          2.027962          0.130624          1.327969          2.998835   \n",
       "1897          1.895214          2.027962          0.130624          1.327969   \n",
       "1904          2.187866          1.895214          2.027962          0.130624   \n",
       "1911          2.024769          2.187866          1.895214          2.027962   \n",
       "1918          2.288202          2.024769          2.187866          1.895214   \n",
       "\n",
       "      ngdp_r_sa_pcha-10  \n",
       "1890           3.177823  \n",
       "1897           2.998835  \n",
       "1904           1.327969  \n",
       "1911           0.130624  \n",
       "1918           2.027962  \n",
       "\n",
       "[5 rows x 673 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping all rows with missing data\n",
    "print(\"\\nAfter dropping rows with missing data\")\n",
    "# X = X.iloc[lag:]\n",
    "# X = X.iloc[:-1]\n",
    "X = X.dropna()\n",
    "X.shape\n",
    "X.head(5)\n",
    "X.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Outcome variable dimension (145, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_step_ahead_ngdp_r_sa_pcha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>0.158923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>5.373663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>9.421777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>8.238399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>8.609839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1_step_ahead_ngdp_r_sa_pcha\n",
       "910                     0.158923\n",
       "917                     5.373663\n",
       "924                     9.421777\n",
       "931                     8.238399\n",
       "938                     8.609839"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Input matrix: X\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145, 672)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>1982Q3</td>\n",
       "      <td>2897.225</td>\n",
       "      <td>1904.8</td>\n",
       "      <td>99.543333</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>92.663</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>1515.5</td>\n",
       "      <td>1.026598</td>\n",
       "      <td>4363.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "      <td>-7.985864</td>\n",
       "      <td>1.261758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1982Q4</td>\n",
       "      <td>2897.225</td>\n",
       "      <td>1918.1</td>\n",
       "      <td>99.119667</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>93.691</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>1532.7</td>\n",
       "      <td>1.134939</td>\n",
       "      <td>4439.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "      <td>-7.985864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>1983Q1</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>1947.2</td>\n",
       "      <td>99.143000</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>92.971</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>1549.5</td>\n",
       "      <td>1.096105</td>\n",
       "      <td>4483.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>1983Q2</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>1986.3</td>\n",
       "      <td>99.945000</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>92.457</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>1561.6</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>4574.9</td>\n",
       "      <td>...</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>1983Q3</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>2029.6</td>\n",
       "      <td>101.610667</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>91.532</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>1580.2</td>\n",
       "      <td>1.191086</td>\n",
       "      <td>4657.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.421777</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time    gdpwgt      lc          le       llf   lulcm        lur  \\\n",
       "910  1982Q3  2897.225  1904.8   99.543333  0.110231  92.663   9.900000   \n",
       "917  1982Q4  2897.225  1918.1   99.119667  0.110231  93.691  10.666667   \n",
       "924  1983Q1  3136.050  1947.2   99.143000  0.111528  92.971  10.366667   \n",
       "931  1983Q2  3136.050  1986.3   99.945000  0.111528  92.457  10.133333   \n",
       "938  1983Q3  3136.050  2029.6  101.610667  0.111528  91.532   9.366667   \n",
       "\n",
       "      ncg_r  ncg_rpch   ncp_r  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "910  1515.5  1.026598  4363.3  ...          1.837425         -6.069358   \n",
       "917  1532.7  1.134939  4439.7  ...         -1.520719          1.837425   \n",
       "924  1549.5  1.096105  4483.6  ...          0.158923         -1.520719   \n",
       "931  1561.6  0.780897  4574.9  ...          5.373663          0.158923   \n",
       "938  1580.2  1.191086  4657.0  ...          9.421777          5.373663   \n",
       "\n",
       "     ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "910         -4.285831          4.872232         -2.926867          8.070747   \n",
       "917         -6.069358         -4.285831          4.872232         -2.926867   \n",
       "924          1.837425         -6.069358         -4.285831          4.872232   \n",
       "931         -1.520719          1.837425         -6.069358         -4.285831   \n",
       "938          0.158923         -1.520719          1.837425         -6.069358   \n",
       "\n",
       "     ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "910          7.668385         -0.476985         -7.985864           1.261758  \n",
       "917          8.070747          7.668385         -0.476985          -7.985864  \n",
       "924         -2.926867          8.070747          7.668385          -0.476985  \n",
       "931          4.872232         -2.926867          8.070747           7.668385  \n",
       "938         -4.285831          4.872232         -2.926867           8.070747  \n",
       "\n",
       "[5 rows x 672 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " columns in input dataset\n",
      ":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['time', 'gdpwgt', 'lc', 'le', 'llf', 'lulcm', 'lur', 'ncg_r',\n",
       "       'ncg_rpch', 'ncp_r',\n",
       "       ...\n",
       "       'ngdp_r_sa_pcha-1', 'ngdp_r_sa_pcha-2', 'ngdp_r_sa_pcha-3',\n",
       "       'ngdp_r_sa_pcha-4', 'ngdp_r_sa_pcha-5', 'ngdp_r_sa_pcha-6',\n",
       "       'ngdp_r_sa_pcha-7', 'ngdp_r_sa_pcha-8', 'ngdp_r_sa_pcha-9',\n",
       "       'ngdp_r_sa_pcha-10'],\n",
       "      dtype='object', length=672)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating input and output variables\n",
    "\n",
    "X1 = X\n",
    "\n",
    "Y1 = X1[predicted_variable]\n",
    "\n",
    "Y1 = pd.DataFrame(Y1) # very important step, gave me formatting errors, and wasted 2 hour in debugging   \n",
    "\n",
    "print(\"\\n Outcome variable dimension\", Y1.shape)\n",
    "Y1.shape\n",
    "Y1.head(5)\n",
    "\n",
    "# Dropping outcome variable from input matrix\n",
    "X1 = X1.drop(columns = [predicted_variable])\n",
    "print(\"\\n Input matrix: X\")\n",
    "X1.shape\n",
    "X1.head(5)\n",
    "\n",
    "print(\"\\n columns in input dataset\\n:\")\n",
    "X1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# items in training set: 97\n",
      "\n",
      "# items in test set: 48\n",
      "\n",
      " input training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97, 672)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>1982Q3</td>\n",
       "      <td>2897.225</td>\n",
       "      <td>1904.8</td>\n",
       "      <td>99.543333</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>92.663</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>1515.5</td>\n",
       "      <td>1.026598</td>\n",
       "      <td>4363.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "      <td>-7.985864</td>\n",
       "      <td>1.261758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1982Q4</td>\n",
       "      <td>2897.225</td>\n",
       "      <td>1918.1</td>\n",
       "      <td>99.119667</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>93.691</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>1532.7</td>\n",
       "      <td>1.134939</td>\n",
       "      <td>4439.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "      <td>-7.985864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>1983Q1</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>1947.2</td>\n",
       "      <td>99.143000</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>92.971</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>1549.5</td>\n",
       "      <td>1.096105</td>\n",
       "      <td>4483.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>1983Q2</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>1986.3</td>\n",
       "      <td>99.945000</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>92.457</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>1561.6</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>4574.9</td>\n",
       "      <td>...</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>1983Q3</td>\n",
       "      <td>3136.050</td>\n",
       "      <td>2029.6</td>\n",
       "      <td>101.610667</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>91.532</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>1580.2</td>\n",
       "      <td>1.191086</td>\n",
       "      <td>4657.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.421777</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time    gdpwgt      lc          le       llf   lulcm        lur  \\\n",
       "910  1982Q3  2897.225  1904.8   99.543333  0.110231  92.663   9.900000   \n",
       "917  1982Q4  2897.225  1918.1   99.119667  0.110231  93.691  10.666667   \n",
       "924  1983Q1  3136.050  1947.2   99.143000  0.111528  92.971  10.366667   \n",
       "931  1983Q2  3136.050  1986.3   99.945000  0.111528  92.457  10.133333   \n",
       "938  1983Q3  3136.050  2029.6  101.610667  0.111528  91.532   9.366667   \n",
       "\n",
       "      ncg_r  ncg_rpch   ncp_r  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "910  1515.5  1.026598  4363.3  ...          1.837425         -6.069358   \n",
       "917  1532.7  1.134939  4439.7  ...         -1.520719          1.837425   \n",
       "924  1549.5  1.096105  4483.6  ...          0.158923         -1.520719   \n",
       "931  1561.6  0.780897  4574.9  ...          5.373663          0.158923   \n",
       "938  1580.2  1.191086  4657.0  ...          9.421777          5.373663   \n",
       "\n",
       "     ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "910         -4.285831          4.872232         -2.926867          8.070747   \n",
       "917         -6.069358         -4.285831          4.872232         -2.926867   \n",
       "924          1.837425         -6.069358         -4.285831          4.872232   \n",
       "931         -1.520719          1.837425         -6.069358         -4.285831   \n",
       "938          0.158923         -1.520719          1.837425         -6.069358   \n",
       "\n",
       "     ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "910          7.668385         -0.476985         -7.985864           1.261758  \n",
       "917          8.070747          7.668385         -0.476985          -7.985864  \n",
       "924         -2.926867          8.070747          7.668385          -0.476985  \n",
       "931          4.872232         -2.926867          8.070747           7.668385  \n",
       "938         -4.285831          4.872232         -2.926867           8.070747  \n",
       "\n",
       "[5 rows x 672 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "910    0.158923\n",
       "917    5.373663\n",
       "924    9.421777\n",
       "931    8.238399\n",
       "938    8.609839\n",
       "Name: 1_step_ahead_ngdp_r_sa_pcha, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " input test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48, 672)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>2006Q4</td>\n",
       "      <td>12236.20</td>\n",
       "      <td>7624.0</td>\n",
       "      <td>145.606000</td>\n",
       "      <td>0.151394</td>\n",
       "      <td>96.534</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>2443.5</td>\n",
       "      <td>0.846059</td>\n",
       "      <td>10504.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620939</td>\n",
       "      <td>0.938637</td>\n",
       "      <td>5.427471</td>\n",
       "      <td>2.548700</td>\n",
       "      <td>3.614058</td>\n",
       "      <td>1.859616</td>\n",
       "      <td>4.501177</td>\n",
       "      <td>4.067524</td>\n",
       "      <td>3.836396</td>\n",
       "      <td>3.084029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>2007Q1</td>\n",
       "      <td>13021.65</td>\n",
       "      <td>7806.8</td>\n",
       "      <td>146.135000</td>\n",
       "      <td>0.153119</td>\n",
       "      <td>96.994</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2444.9</td>\n",
       "      <td>0.057295</td>\n",
       "      <td>10563.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.449636</td>\n",
       "      <td>0.620939</td>\n",
       "      <td>0.938637</td>\n",
       "      <td>5.427471</td>\n",
       "      <td>2.548700</td>\n",
       "      <td>3.614058</td>\n",
       "      <td>1.859616</td>\n",
       "      <td>4.501177</td>\n",
       "      <td>4.067524</td>\n",
       "      <td>3.836396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2007Q2</td>\n",
       "      <td>13021.65</td>\n",
       "      <td>7845.4</td>\n",
       "      <td>145.850667</td>\n",
       "      <td>0.153119</td>\n",
       "      <td>95.793</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2460.5</td>\n",
       "      <td>0.638063</td>\n",
       "      <td>10582.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945307</td>\n",
       "      <td>3.449636</td>\n",
       "      <td>0.620939</td>\n",
       "      <td>0.938637</td>\n",
       "      <td>5.427471</td>\n",
       "      <td>2.548700</td>\n",
       "      <td>3.614058</td>\n",
       "      <td>1.859616</td>\n",
       "      <td>4.501177</td>\n",
       "      <td>4.067524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>2007Q3</td>\n",
       "      <td>13021.65</td>\n",
       "      <td>7885.1</td>\n",
       "      <td>145.943667</td>\n",
       "      <td>0.153119</td>\n",
       "      <td>95.084</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2472.8</td>\n",
       "      <td>0.499898</td>\n",
       "      <td>10642.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.312389</td>\n",
       "      <td>0.945307</td>\n",
       "      <td>3.449636</td>\n",
       "      <td>0.620939</td>\n",
       "      <td>0.938637</td>\n",
       "      <td>5.427471</td>\n",
       "      <td>2.548700</td>\n",
       "      <td>3.614058</td>\n",
       "      <td>1.859616</td>\n",
       "      <td>4.501177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>2007Q4</td>\n",
       "      <td>13021.65</td>\n",
       "      <td>7978.2</td>\n",
       "      <td>146.271333</td>\n",
       "      <td>0.153119</td>\n",
       "      <td>94.925</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>2489.1</td>\n",
       "      <td>0.659172</td>\n",
       "      <td>10672.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.189473</td>\n",
       "      <td>2.312389</td>\n",
       "      <td>0.945307</td>\n",
       "      <td>3.449636</td>\n",
       "      <td>0.620939</td>\n",
       "      <td>0.938637</td>\n",
       "      <td>5.427471</td>\n",
       "      <td>2.548700</td>\n",
       "      <td>3.614058</td>\n",
       "      <td>1.859616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time    gdpwgt      lc          le       llf   lulcm       lur  \\\n",
       "1589  2006Q4  12236.20  7624.0  145.606000  0.151394  96.534  4.433333   \n",
       "1596  2007Q1  13021.65  7806.8  146.135000  0.153119  96.994  4.500000   \n",
       "1603  2007Q2  13021.65  7845.4  145.850667  0.153119  95.793  4.500000   \n",
       "1610  2007Q3  13021.65  7885.1  145.943667  0.153119  95.084  4.666667   \n",
       "1617  2007Q4  13021.65  7978.2  146.271333  0.153119  94.925  4.800000   \n",
       "\n",
       "       ncg_r  ncg_rpch    ncp_r  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "1589  2443.5  0.846059  10504.5  ...          0.620939          0.938637   \n",
       "1596  2444.9  0.057295  10563.3  ...          3.449636          0.620939   \n",
       "1603  2460.5  0.638063  10582.8  ...          0.945307          3.449636   \n",
       "1610  2472.8  0.499898  10642.5  ...          2.312389          0.945307   \n",
       "1617  2489.1  0.659172  10672.8  ...          2.189473          2.312389   \n",
       "\n",
       "      ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "1589          5.427471          2.548700          3.614058          1.859616   \n",
       "1596          0.938637          5.427471          2.548700          3.614058   \n",
       "1603          0.620939          0.938637          5.427471          2.548700   \n",
       "1610          3.449636          0.620939          0.938637          5.427471   \n",
       "1617          0.945307          3.449636          0.620939          0.938637   \n",
       "\n",
       "      ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "1589          4.501177          4.067524          3.836396           3.084029  \n",
       "1596          1.859616          4.501177          4.067524           3.836396  \n",
       "1603          3.614058          1.859616          4.501177           4.067524  \n",
       "1610          2.548700          3.614058          1.859616           4.501177  \n",
       "1617          5.427471          2.548700          3.614058           1.859616  \n",
       "\n",
       "[5 rows x 672 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1589    0.945307\n",
       "1596    2.312389\n",
       "1603    2.189473\n",
       "1610    2.455478\n",
       "1617   -2.279453\n",
       "Name: 1_step_ahead_ngdp_r_sa_pcha, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_step_ahead_ngdp_r_sa_pcha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>0.945307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>2.312389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2.189473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>2.455478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>-2.279453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1_step_ahead_ngdp_r_sa_pcha\n",
       "1589                     0.945307\n",
       "1596                     2.312389\n",
       "1603                     2.189473\n",
       "1610                     2.455478\n",
       "1617                    -2.279453"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "# Sequential train-test split\n",
    "train_test_ratio = 0.67\n",
    "\n",
    "training = int(round(X1.shape[0]*train_test_ratio, 0))\n",
    "test = X1.shape[0] - training\n",
    "\n",
    "print(\"# items in training set:\", training)\n",
    "print(\"\\n# items in test set:\", test)\n",
    "\n",
    "X_train = X1.iloc[0:(training),:]\n",
    "y_train = Y1.iloc[0:(training),0]\n",
    "X_test = X1.iloc[training:(X1.shape[0]),:]\n",
    "y_test = Y1.iloc[training:(X1.shape[0]),0]\n",
    "y_test_outcome_value = Y1.iloc[training:(X1.shape[0]),:]\n",
    "\n",
    "print(\"\\n input training set:\")\n",
    "X_train.shape\n",
    "X_train.head(5)\n",
    "\n",
    "y_train.head(5)\n",
    "\n",
    "print(\"\\n input test set:\")\n",
    "X_test.shape\n",
    "X_test.head(5)\n",
    "\n",
    "y_test.head(5)\n",
    "y_test_outcome_value.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>ncp_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2897.225</td>\n",
       "      <td>1904.8</td>\n",
       "      <td>99.543333</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>92.663</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>1515.5</td>\n",
       "      <td>1.026598</td>\n",
       "      <td>4363.3</td>\n",
       "      <td>0.669082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "      <td>-7.985864</td>\n",
       "      <td>1.261758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>2897.225</td>\n",
       "      <td>1918.1</td>\n",
       "      <td>99.119667</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>93.691</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>1532.7</td>\n",
       "      <td>1.134939</td>\n",
       "      <td>4439.7</td>\n",
       "      <td>1.750968</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "      <td>-7.985864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>3136.050</td>\n",
       "      <td>1947.2</td>\n",
       "      <td>99.143000</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>92.971</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>1549.5</td>\n",
       "      <td>1.096105</td>\n",
       "      <td>4483.6</td>\n",
       "      <td>0.988806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "      <td>-0.476985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>3136.050</td>\n",
       "      <td>1986.3</td>\n",
       "      <td>99.945000</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>92.457</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>1561.6</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>4574.9</td>\n",
       "      <td>2.036310</td>\n",
       "      <td>...</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "      <td>7.668385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>3136.050</td>\n",
       "      <td>2029.6</td>\n",
       "      <td>101.610667</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>91.532</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>1580.2</td>\n",
       "      <td>1.191086</td>\n",
       "      <td>4657.0</td>\n",
       "      <td>1.794575</td>\n",
       "      <td>...</td>\n",
       "      <td>9.421777</td>\n",
       "      <td>5.373663</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>-1.520719</td>\n",
       "      <td>1.837425</td>\n",
       "      <td>-6.069358</td>\n",
       "      <td>-4.285831</td>\n",
       "      <td>4.872232</td>\n",
       "      <td>-2.926867</td>\n",
       "      <td>8.070747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gdpwgt      lc          le       llf   lulcm        lur   ncg_r  \\\n",
       "910  2897.225  1904.8   99.543333  0.110231  92.663   9.900000  1515.5   \n",
       "917  2897.225  1918.1   99.119667  0.110231  93.691  10.666667  1532.7   \n",
       "924  3136.050  1947.2   99.143000  0.111528  92.971  10.366667  1549.5   \n",
       "931  3136.050  1986.3   99.945000  0.111528  92.457  10.133333  1561.6   \n",
       "938  3136.050  2029.6  101.610667  0.111528  91.532   9.366667  1580.2   \n",
       "\n",
       "     ncg_rpch   ncp_r  ncp_rpch  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "910  1.026598  4363.3  0.669082  ...          1.837425         -6.069358   \n",
       "917  1.134939  4439.7  1.750968  ...         -1.520719          1.837425   \n",
       "924  1.096105  4483.6  0.988806  ...          0.158923         -1.520719   \n",
       "931  0.780897  4574.9  2.036310  ...          5.373663          0.158923   \n",
       "938  1.191086  4657.0  1.794575  ...          9.421777          5.373663   \n",
       "\n",
       "     ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "910         -4.285831          4.872232         -2.926867          8.070747   \n",
       "917         -6.069358         -4.285831          4.872232         -2.926867   \n",
       "924          1.837425         -6.069358         -4.285831          4.872232   \n",
       "931         -1.520719          1.837425         -6.069358         -4.285831   \n",
       "938          0.158923         -1.520719          1.837425         -6.069358   \n",
       "\n",
       "     ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "910          7.668385         -0.476985         -7.985864           1.261758  \n",
       "917          8.070747          7.668385         -0.476985          -7.985864  \n",
       "924         -2.926867          8.070747          7.668385          -0.476985  \n",
       "931          4.872232         -2.926867          8.070747           7.668385  \n",
       "938         -4.285831          4.872232         -2.926867           8.070747  \n",
       "\n",
       "[5 rows x 671 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the training & test sets \n",
    "\n",
    "# Dropping the \"time\" column\n",
    "\n",
    "X_train.drop(columns = ['time'], inplace = True)\n",
    "X_test.drop(columns = ['time'], inplace = True)\n",
    "\n",
    "train_columns = list(X_train.columns)\n",
    "# train_columns\n",
    "\n",
    "# X_test  = X_test.drop(columns = [\"time\"], inplace = True)\n",
    "\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled training input dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>ncp_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091959</td>\n",
       "      <td>0.886700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.912787</td>\n",
       "      <td>0.886813</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018891</td>\n",
       "      <td>0.783991</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159268</td>\n",
       "      <td>0.510407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.912787</td>\n",
       "      <td>0.886813</td>\n",
       "      <td>0.431355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>0.037342</td>\n",
       "      <td>0.775827</td>\n",
       "      <td>0.019916</td>\n",
       "      <td>0.625607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288318</td>\n",
       "      <td>0.293629</td>\n",
       "      <td>0.510407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.912787</td>\n",
       "      <td>0.899275</td>\n",
       "      <td>0.431355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.018168</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.076608</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.050632</td>\n",
       "      <td>0.709567</td>\n",
       "      <td>0.035030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.402055</td>\n",
       "      <td>0.293629</td>\n",
       "      <td>0.510407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.922389</td>\n",
       "      <td>0.899275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.054834</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.071060</td>\n",
       "      <td>0.795793</td>\n",
       "      <td>0.048622</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738682</td>\n",
       "      <td>0.402055</td>\n",
       "      <td>0.293629</td>\n",
       "      <td>0.510407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.290619</td>\n",
       "      <td>0.922389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gdpwgt        lc        le       llf     lulcm       lur     ncg_r  \\\n",
       "0  0.000000  0.000000  0.009326  0.000000  0.091959  0.886700  0.000000   \n",
       "1  0.000000  0.002382  0.000000  0.000000  0.168567  1.000000  0.018891   \n",
       "2  0.025573  0.007595  0.000514  0.031524  0.114912  0.955665  0.037342   \n",
       "3  0.025573  0.014599  0.018168  0.031524  0.076608  0.921182  0.050632   \n",
       "4  0.025573  0.022356  0.054834  0.031524  0.007676  0.807882  0.071060   \n",
       "\n",
       "   ncg_rpch     ncp_r  ncp_rpch  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "0  0.761216  0.000000  0.511333  ...          0.417280          0.000000   \n",
       "1  0.783991  0.012648  0.898015  ...          0.159268          0.510407   \n",
       "2  0.775827  0.019916  0.625607  ...          0.288318          0.293629   \n",
       "3  0.709567  0.035030  1.000000  ...          0.688976          0.402055   \n",
       "4  0.795793  0.048622  0.913600  ...          1.000000          0.738682   \n",
       "\n",
       "   ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "0          0.115132          0.706313          0.202857          0.912787   \n",
       "1          0.000000          0.115132          0.706313          0.202857   \n",
       "2          0.510407          0.000000          0.115132          0.706313   \n",
       "3          0.293629          0.510407          0.000000          0.115132   \n",
       "4          0.402055          0.293629          0.510407          0.000000   \n",
       "\n",
       "   ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "0          0.886813          0.361005          0.000000           0.531239  \n",
       "1          0.912787          0.886813          0.431355           0.000000  \n",
       "2          0.202857          0.912787          0.899275           0.431355  \n",
       "3          0.706313          0.202857          0.922389           0.899275  \n",
       "4          0.115132          0.706313          0.290619           0.922389  \n",
       "\n",
       "[5 rows x 671 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled test input dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>ncp_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095128</td>\n",
       "      <td>0.103261</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.782466</td>\n",
       "      <td>0.033506</td>\n",
       "      <td>0.885535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647165</td>\n",
       "      <td>0.670012</td>\n",
       "      <td>0.992820</td>\n",
       "      <td>0.785797</td>\n",
       "      <td>0.862411</td>\n",
       "      <td>0.736243</td>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.895021</td>\n",
       "      <td>0.878400</td>\n",
       "      <td>0.824295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.119305</td>\n",
       "      <td>0.054238</td>\n",
       "      <td>0.443550</td>\n",
       "      <td>0.161546</td>\n",
       "      <td>0.122325</td>\n",
       "      <td>0.114130</td>\n",
       "      <td>0.025968</td>\n",
       "      <td>0.525182</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.695181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.647165</td>\n",
       "      <td>0.670012</td>\n",
       "      <td>0.992820</td>\n",
       "      <td>0.785797</td>\n",
       "      <td>0.862411</td>\n",
       "      <td>0.736243</td>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.895021</td>\n",
       "      <td>0.878400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119305</td>\n",
       "      <td>0.065691</td>\n",
       "      <td>0.427312</td>\n",
       "      <td>0.161546</td>\n",
       "      <td>0.051318</td>\n",
       "      <td>0.114130</td>\n",
       "      <td>0.099622</td>\n",
       "      <td>0.714620</td>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.520215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670491</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.647165</td>\n",
       "      <td>0.670012</td>\n",
       "      <td>0.992820</td>\n",
       "      <td>0.785797</td>\n",
       "      <td>0.862411</td>\n",
       "      <td>0.736243</td>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.895021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119305</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>0.432623</td>\n",
       "      <td>0.161546</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.157696</td>\n",
       "      <td>0.669553</td>\n",
       "      <td>0.086532</td>\n",
       "      <td>0.697215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768803</td>\n",
       "      <td>0.670491</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.647165</td>\n",
       "      <td>0.670012</td>\n",
       "      <td>0.992820</td>\n",
       "      <td>0.785797</td>\n",
       "      <td>0.862411</td>\n",
       "      <td>0.736243</td>\n",
       "      <td>0.926207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.119305</td>\n",
       "      <td>0.105095</td>\n",
       "      <td>0.451335</td>\n",
       "      <td>0.161546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.234655</td>\n",
       "      <td>0.721506</td>\n",
       "      <td>0.098175</td>\n",
       "      <td>0.566902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759964</td>\n",
       "      <td>0.768803</td>\n",
       "      <td>0.670491</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.647165</td>\n",
       "      <td>0.670012</td>\n",
       "      <td>0.992820</td>\n",
       "      <td>0.785797</td>\n",
       "      <td>0.862411</td>\n",
       "      <td>0.736243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gdpwgt        lc        le       llf     lulcm       lur     ncg_r  \\\n",
       "0  0.000000  0.000000  0.413340  0.000000  0.095128  0.103261  0.019358   \n",
       "1  0.119305  0.054238  0.443550  0.161546  0.122325  0.114130  0.025968   \n",
       "2  0.119305  0.065691  0.427312  0.161546  0.051318  0.114130  0.099622   \n",
       "3  0.119305  0.077471  0.432623  0.161546  0.009400  0.141304  0.157696   \n",
       "4  0.119305  0.105095  0.451335  0.161546  0.000000  0.163043  0.234655   \n",
       "\n",
       "   ncg_rpch     ncp_r  ncp_rpch  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "0  0.782466  0.033506  0.885535  ...          0.647165          0.670012   \n",
       "1  0.525182  0.056100  0.695181  ...          0.850587          0.647165   \n",
       "2  0.714620  0.063593  0.520215  ...          0.670491          0.850587   \n",
       "3  0.669553  0.086532  0.697215  ...          0.768803          0.670491   \n",
       "4  0.721506  0.098175  0.566902  ...          0.759964          0.768803   \n",
       "\n",
       "   ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "0          0.992820          0.785797          0.862411          0.736243   \n",
       "1          0.670012          0.992820          0.785797          0.862411   \n",
       "2          0.647165          0.670012          0.992820          0.785797   \n",
       "3          0.850587          0.647165          0.670012          0.992820   \n",
       "4          0.670491          0.850587          0.647165          0.670012   \n",
       "\n",
       "   ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "0          0.926207          0.895021          0.878400           0.824295  \n",
       "1          0.736243          0.926207          0.895021           0.878400  \n",
       "2          0.862411          0.736243          0.926207           0.895021  \n",
       "3          0.785797          0.862411          0.736243           0.926207  \n",
       "4          0.992820          0.785797          0.862411           0.736243  \n",
       "\n",
       "[5 rows x 671 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling all the numerical variables\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# train_columns = list(X_train.columns) # removing 'time' column for feature scaling\n",
    "# train_columns\n",
    "\n",
    "\n",
    "print(\"\\nScaled training input dataset:\")\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = train_columns)\n",
    "\n",
    "X_train.head(5)\n",
    "\n",
    "print(\"\\nScaled test input dataset:\")\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = train_columns)\n",
    "\n",
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does not exist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdpwgt</th>\n",
       "      <th>lc</th>\n",
       "      <th>le</th>\n",
       "      <th>llf</th>\n",
       "      <th>lulcm</th>\n",
       "      <th>lur</th>\n",
       "      <th>ncg_r</th>\n",
       "      <th>ncg_rpch</th>\n",
       "      <th>ncp_r</th>\n",
       "      <th>ncp_rpch</th>\n",
       "      <th>...</th>\n",
       "      <th>ngdp_r_sa_pcha-1</th>\n",
       "      <th>ngdp_r_sa_pcha-2</th>\n",
       "      <th>ngdp_r_sa_pcha-3</th>\n",
       "      <th>ngdp_r_sa_pcha-4</th>\n",
       "      <th>ngdp_r_sa_pcha-5</th>\n",
       "      <th>ngdp_r_sa_pcha-6</th>\n",
       "      <th>ngdp_r_sa_pcha-7</th>\n",
       "      <th>ngdp_r_sa_pcha-8</th>\n",
       "      <th>ngdp_r_sa_pcha-9</th>\n",
       "      <th>ngdp_r_sa_pcha-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091959</td>\n",
       "      <td>0.886700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.912787</td>\n",
       "      <td>0.886813</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018891</td>\n",
       "      <td>0.783991</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159268</td>\n",
       "      <td>0.510407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.912787</td>\n",
       "      <td>0.886813</td>\n",
       "      <td>0.431355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>0.037342</td>\n",
       "      <td>0.775827</td>\n",
       "      <td>0.019916</td>\n",
       "      <td>0.625607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288318</td>\n",
       "      <td>0.293629</td>\n",
       "      <td>0.510407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.912787</td>\n",
       "      <td>0.899275</td>\n",
       "      <td>0.431355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.018168</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.076608</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.050632</td>\n",
       "      <td>0.709567</td>\n",
       "      <td>0.035030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.402055</td>\n",
       "      <td>0.293629</td>\n",
       "      <td>0.510407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.922389</td>\n",
       "      <td>0.899275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.054834</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.071060</td>\n",
       "      <td>0.795793</td>\n",
       "      <td>0.048622</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738682</td>\n",
       "      <td>0.402055</td>\n",
       "      <td>0.293629</td>\n",
       "      <td>0.510407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.290619</td>\n",
       "      <td>0.922389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.925039</td>\n",
       "      <td>0.934741</td>\n",
       "      <td>0.950243</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>0.316715</td>\n",
       "      <td>0.157635</td>\n",
       "      <td>0.974080</td>\n",
       "      <td>0.634163</td>\n",
       "      <td>0.957206</td>\n",
       "      <td>0.619015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418985</td>\n",
       "      <td>0.682360</td>\n",
       "      <td>0.654367</td>\n",
       "      <td>0.639447</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.530720</td>\n",
       "      <td>0.693273</td>\n",
       "      <td>0.841731</td>\n",
       "      <td>0.658839</td>\n",
       "      <td>0.587434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.925039</td>\n",
       "      <td>0.950451</td>\n",
       "      <td>0.957126</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>0.271332</td>\n",
       "      <td>0.157635</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.550664</td>\n",
       "      <td>0.962189</td>\n",
       "      <td>0.378235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553782</td>\n",
       "      <td>0.511839</td>\n",
       "      <td>0.682360</td>\n",
       "      <td>0.654367</td>\n",
       "      <td>0.639447</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.530720</td>\n",
       "      <td>0.693273</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.658839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.975830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410314</td>\n",
       "      <td>0.123153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746615</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.670866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471929</td>\n",
       "      <td>0.625094</td>\n",
       "      <td>0.511839</td>\n",
       "      <td>0.682360</td>\n",
       "      <td>0.654367</td>\n",
       "      <td>0.639447</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.530720</td>\n",
       "      <td>0.727043</td>\n",
       "      <td>0.859155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989413</td>\n",
       "      <td>0.989441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379611</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.992641</td>\n",
       "      <td>0.487360</td>\n",
       "      <td>0.989604</td>\n",
       "      <td>0.453178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693110</td>\n",
       "      <td>0.556322</td>\n",
       "      <td>0.625094</td>\n",
       "      <td>0.511839</td>\n",
       "      <td>0.682360</td>\n",
       "      <td>0.654367</td>\n",
       "      <td>0.639447</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.582385</td>\n",
       "      <td>0.727043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.330352</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.996705</td>\n",
       "      <td>0.577563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.489248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348225</td>\n",
       "      <td>0.742155</td>\n",
       "      <td>0.556322</td>\n",
       "      <td>0.625094</td>\n",
       "      <td>0.511839</td>\n",
       "      <td>0.682360</td>\n",
       "      <td>0.654367</td>\n",
       "      <td>0.639447</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.582385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gdpwgt        lc        le       llf     lulcm       lur     ncg_r  \\\n",
       "0   0.000000  0.000000  0.009326  0.000000  0.091959  0.886700  0.000000   \n",
       "1   0.000000  0.002382  0.000000  0.000000  0.168567  1.000000  0.018891   \n",
       "2   0.025573  0.007595  0.000514  0.031524  0.114912  0.955665  0.037342   \n",
       "3   0.025573  0.014599  0.018168  0.031524  0.076608  0.921182  0.050632   \n",
       "4   0.025573  0.022356  0.054834  0.031524  0.007676  0.807882  0.071060   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "92  0.925039  0.934741  0.950243  0.949109  0.316715  0.157635  0.974080   \n",
       "93  0.925039  0.950451  0.957126  0.949109  0.271332  0.157635  0.974739   \n",
       "94  1.000000  0.980833  0.975830  1.000000  0.410314  0.123153  1.000000   \n",
       "95  1.000000  0.989413  0.989441  1.000000  0.379611  0.108374  0.992641   \n",
       "96  1.000000  1.000000  1.000000  1.000000  0.330352  0.108374  0.996705   \n",
       "\n",
       "    ncg_rpch     ncp_r  ncp_rpch  ...  ngdp_r_sa_pcha-1  ngdp_r_sa_pcha-2  \\\n",
       "0   0.761216  0.000000  0.511333  ...          0.417280          0.000000   \n",
       "1   0.783991  0.012648  0.898015  ...          0.159268          0.510407   \n",
       "2   0.775827  0.019916  0.625607  ...          0.288318          0.293629   \n",
       "3   0.709567  0.035030  1.000000  ...          0.688976          0.402055   \n",
       "4   0.795793  0.048622  0.913600  ...          1.000000          0.738682   \n",
       "..       ...       ...       ...  ...               ...               ...   \n",
       "92  0.634163  0.957206  0.619015  ...          0.418985          0.682360   \n",
       "93  0.550664  0.962189  0.378235  ...          0.553782          0.511839   \n",
       "94  0.746615  0.980978  0.670866  ...          0.471929          0.625094   \n",
       "95  0.487360  0.989604  0.453178  ...          0.693110          0.556322   \n",
       "96  0.577563  1.000000  0.489248  ...          0.348225          0.742155   \n",
       "\n",
       "    ngdp_r_sa_pcha-3  ngdp_r_sa_pcha-4  ngdp_r_sa_pcha-5  ngdp_r_sa_pcha-6  \\\n",
       "0           0.115132          0.706313          0.202857          0.912787   \n",
       "1           0.000000          0.115132          0.706313          0.202857   \n",
       "2           0.510407          0.000000          0.115132          0.706313   \n",
       "3           0.293629          0.510407          0.000000          0.115132   \n",
       "4           0.402055          0.293629          0.510407          0.000000   \n",
       "..               ...               ...               ...               ...   \n",
       "92          0.654367          0.639447          0.590879          0.530720   \n",
       "93          0.682360          0.654367          0.639447          0.590879   \n",
       "94          0.511839          0.682360          0.654367          0.639447   \n",
       "95          0.625094          0.511839          0.682360          0.654367   \n",
       "96          0.556322          0.625094          0.511839          0.682360   \n",
       "\n",
       "    ngdp_r_sa_pcha-7  ngdp_r_sa_pcha-8  ngdp_r_sa_pcha-9  ngdp_r_sa_pcha-10  \n",
       "0           0.886813          0.361005          0.000000           0.531239  \n",
       "1           0.912787          0.886813          0.431355           0.000000  \n",
       "2           0.202857          0.912787          0.899275           0.431355  \n",
       "3           0.706313          0.202857          0.922389           0.899275  \n",
       "4           0.115132          0.706313          0.290619           0.922389  \n",
       "..               ...               ...               ...                ...  \n",
       "92          0.693273          0.841731          0.658839           0.587434  \n",
       "93          0.530720          0.693273          0.859155           0.658839  \n",
       "94          0.590879          0.530720          0.727043           0.859155  \n",
       "95          0.639447          0.590879          0.582385           0.727043  \n",
       "96          0.654367          0.639447          0.635922           0.582385  \n",
       "\n",
       "[97 rows x 671 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'time' in X_train.columns:\n",
    "    print(\"Does not exist\")\n",
    "else:\n",
    "    print(\"Does not exist\")\n",
    "    \n",
    "X_train\n",
    "\n",
    "# train_cols = X_train.columns\n",
    "\n",
    "# train_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection by Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=5000, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test MSE:  8.794497102516218\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# random forest model creation\n",
    "rfr = RandomForestRegressor(n_estimators = 5000)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred = rfr.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Test MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top variables (> 80% variation):  147 \n",
      " Total variation explained:  0.800255015178612\n",
      "Top features: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['nfb_r-6', 'pcpi_pch-2', 'ncg_rpch', 'nm_rpch-3', 'ngdp_r_sa_ar-4',\n",
       "       'nmg_rpch-10', 'nfdd_rpch-10', 'nm_rpch-9', 'lur-7', 'ngdp_d_sa_pchy-5',\n",
       "       ...\n",
       "       'ncp_rpchy', 'pcpi_pchy', 'ngdp_rpchy-9', 'ncp_rpch-1', 'nm_rpch',\n",
       "       'lur-5', 'nfdd_rpch', 'ncp_rpch', 'nfbrgdp', 'nfi_rpch'],\n",
       "      dtype='object', length=147)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x2160 with 0 Axes>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature Importances - Random Forest Regressor')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 147 artists>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f0c94d845c0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d84cc0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d14588>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e93358>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e8cda0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e8c908>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e8c3c8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e8c550>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e93278>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e83978>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e83470>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e7de80>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e7d9b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e7d438>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e74e80>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e74908>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e74390>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e747f0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e7ddd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e6feb8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e6f9b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e6f470>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e66eb8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e66940>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e663c8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e5fe10>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e66978>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e6f908>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e5f9b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e5f438>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e56e80>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e56908>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e56390>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ed1dd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ed1860>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ed1320>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ed1940>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e56f60>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ec8e80>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ec8940>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ec83c8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ec2e10>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ec2898>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ec2358>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eb8dd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ec2ac8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ec8828>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eb8978>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eb8390>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eb3dd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eb3860>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eb3320>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eaad68>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eaa7f0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eaa278>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eaa898>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eb37b8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ea4dd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ea4898>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ea4358>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e9bdd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e9b828>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e9b2b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e95d30>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e9ba20>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ea4780>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e95908>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e95358>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f0cdd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f0c828>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f0c2b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f07cf8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f07780>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f07240>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f07828>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f0c780>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94efedd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94efe860>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94efe2e8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ef7d30>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ef77b8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ef7278>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eeecc0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ef79b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94efe748>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eee898>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eee2b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee9cf8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee9780>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee9240>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee0c88>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee0710>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee0198>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee07b8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee9e80>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94efeeb8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94e5fa58>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94edbb00>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94edb588>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94edb320>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f51a58>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f514e0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f51518>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94edb630>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94eee208>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f4ba90>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f4b550>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f42f60>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f42a20>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f424a8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f3ceb8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f3c978>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f42630>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94efe240>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f3c588>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f3c320>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f33a58>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f334e0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f2eeb8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f2e9b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f2e470>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f2e3c8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f33518>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94ee9978>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f25a20>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f254a8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f1feb8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f1f9b0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f1f470>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f17eb8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d22710>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f1f4a8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94f25be0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d22320>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d22c50>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d29208>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d29780>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d29cf8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d302e8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d30828>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d30d68>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d29cc0>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d22208>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d38240>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d387b8>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d38d30>,\n",
       "  <matplotlib.axis.YTick at 0x7f0c94d3f320>],\n",
       " <a list of 147 Text yticklabel objects>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Relative Importance')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable Importance\n",
    "# i = 20\n",
    "\n",
    "importances =  rfr.feature_importances_\n",
    "top_features = []\n",
    "\n",
    "imp_1 = sorted(np.array(importances), reverse = True)\n",
    "sum = 0 \n",
    "for i in range(len(imp_1)):\n",
    "    sum = sum + imp_1[i]\n",
    "    if sum > 0.8:\n",
    "        n = i\n",
    "        print(\"\\n Top variables (> 80% variation): \", n+1, \"\\n Total variation explained: \", sum)\n",
    "        break\n",
    "                       \n",
    "i = n\n",
    "\n",
    "indices = np.argsort(importances)[-(i+1):]\n",
    " \n",
    "print(\"Top features: \")\n",
    "\n",
    "features = X_train.columns\n",
    "\n",
    "top_features = features[indices]\n",
    "top_features\n",
    "\n",
    "plt.figure(figsize=(10,30))\n",
    "plt.title('Feature Importances - Random Forest Regressor')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total important variables:  147\n",
      "\n",
      " Important features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['nfb_r-6', 'pcpi_pch-2', 'ncg_rpch', 'nm_rpch-3', 'ngdp_r_sa_ar-4',\n",
       "       'nmg_rpch-10', 'nfdd_rpch-10', 'nm_rpch-9', 'lur-7', 'ngdp_d_sa_pchy-5',\n",
       "       ...\n",
       "       'ncp_rpchy', 'pcpi_pchy', 'ngdp_rpchy-9', 'ncp_rpch-1', 'nm_rpch',\n",
       "       'lur-5', 'nfdd_rpch', 'ncp_rpch', 'nfbrgdp', 'nfi_rpch'],\n",
       "      dtype='object', length=147)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Important features\n",
    "\n",
    "print(\"\\n Total important variables: \", len(top_features))\n",
    "print(\"\\n Important features: \\n\")\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 147)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(48, 147)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train & Test set with important features from random forest\n",
    "\n",
    "X_train_random_forest = X_train[top_features]\n",
    "X_train_random_forest.shape\n",
    "\n",
    "X_test_random_forest = X_test[top_features]\n",
    "X_test_random_forest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set reshaped: (97, 147, 1)\n",
      "test set reshaped: (48, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the training and test sets\n",
    "X_train_1 = np.array(X_train_random_forest).reshape(X_train_random_forest.shape[0], X_train_random_forest.shape[1],1)\n",
    "print(\"training set reshaped:\", X_train_1.shape)\n",
    "\n",
    "X_test_1 = np.array(X_test_random_forest).reshape(X_test_random_forest.shape[0], X_test_random_forest.shape[1],1)\n",
    "print(\"test set reshaped:\", X_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from keras.layers import LSTM\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.init(project='IMF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General tuning for all params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config_1 = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "      'name': 'val_loss',\n",
    "      'goal': 'minimize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "                  'epochs': {'values': [10, 20]},\n",
    "                  'batch_size': {'values': [32, 64]},\n",
    "                  'nn_units': {'values': [16, 32, 64]},\n",
    "                  'dout_rate': {'values': [0.0, 0.2, 0.4, 0.6]},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: gdke1z5v\n",
      "Sweep URL: https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\n"
     ]
    }
   ],
   "source": [
    "sweepid_1 = wandb.sweep(sweep_config_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1():\n",
    "    \n",
    "    # Specify the hyperparameter to be tuned along with\n",
    "    # an initial value\n",
    "    config_defaults = {\n",
    "        'epochs': 10,\n",
    "        'batch_size': 32,\n",
    "        'nn_units': 16,\n",
    "        'dout_rate': 0.0\n",
    "    }\n",
    "    \n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    \n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = config.nn_units, return_sequences = True, input_shape = (X_train_1.shape[1], 1)))\n",
    "    model.add(Dropout(config.dout_rate))\n",
    "    model.add(LSTM(units = config.nn_units, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate))\n",
    "    model.add(LSTM(units = config.nn_units, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate))\n",
    "    model.add(LSTM(units = config.nn_units, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate))\n",
    "    model.add(LSTM(units = config.nn_units, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate))\n",
    "    model.add(LSTM(units = config.nn_units, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate))\n",
    "    model.add(LSTM(units = config.nn_units))\n",
    "    model.add(Dense(units = 1, activation='relu'))\n",
    "    \n",
    "    # Complie the model\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_1, y_train, epochs = config.epochs, batch_size = config.batch_size, \n",
    "              validation_split = 0.3, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: y7bptumc with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: y7bptumc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/y7bptumc\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/y7bptumc</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "wandb: Agent Finished Run: y7bptumc \n",
      "\n",
      "wandb: Agent Starting Run: jxyb2802 with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: jxyb2802\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/jxyb2802\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/jxyb2802</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 18.9613 - mse: 18.9613 - val_loss: 12.3290 - val_mse: 12.3290\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 17.5686 - mse: 17.5686 - val_loss: 10.0546 - val_mse: 10.0546\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 14.0594 - mse: 14.0594 - val_loss: 7.0938 - val_mse: 7.0938\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 10.0961 - mse: 10.0961 - val_loss: 5.2962 - val_mse: 5.2962\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 7.3040 - mse: 7.3040 - val_loss: 4.7576 - val_mse: 4.7576\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.7641 - mse: 5.7641 - val_loss: 5.1299 - val_mse: 5.1299\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2969 - mse: 5.2969 - val_loss: 5.8663 - val_mse: 5.8663\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3462 - mse: 5.3462 - val_loss: 6.2653 - val_mse: 6.2653\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3967 - mse: 5.3967 - val_loss: 6.1781 - val_mse: 6.1781\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3735 - mse: 5.3735 - val_loss: 6.1000 - val_mse: 6.1000\n",
      "wandb: Agent Finished Run: jxyb2802 \n",
      "\n",
      "wandb: Agent Starting Run: fddht8zu with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: fddht8zu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/fddht8zu\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/fddht8zu</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 72ms/step - loss: 18.6604 - mse: 18.6604 - val_loss: 10.0009 - val_mse: 10.0009\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 12.6335 - mse: 12.6335 - val_loss: 5.0288 - val_mse: 5.0288\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 6.4252 - mse: 6.4252 - val_loss: 5.4684 - val_mse: 5.4684\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2638 - mse: 5.2638 - val_loss: 7.2303 - val_mse: 7.2303\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.7959 - mse: 5.7959 - val_loss: 7.4012 - val_mse: 7.4012\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.8548 - mse: 5.8548 - val_loss: 7.0226 - val_mse: 7.0226\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.6493 - mse: 5.6493 - val_loss: 6.3706 - val_mse: 6.3706\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.3782 - mse: 5.3782 - val_loss: 5.6555 - val_mse: 5.6555\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.2467 - mse: 5.2467 - val_loss: 5.2883 - val_mse: 5.2883\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.2499 - mse: 5.2499 - val_loss: 5.2833 - val_mse: 5.2833\n",
      "wandb: Agent Finished Run: fddht8zu \n",
      "\n",
      "wandb: Agent Starting Run: exid6qn6 with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: exid6qn6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/exid6qn6\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/exid6qn6</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "wandb: Agent Finished Run: exid6qn6 \n",
      "\n",
      "wandb: Agent Starting Run: uf378w43 with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: uf378w43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/uf378w43\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/uf378w43</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 18.9613 - mse: 18.9613 - val_loss: 12.3290 - val_mse: 12.3290\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 17.5686 - mse: 17.5686 - val_loss: 10.0546 - val_mse: 10.0546\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 14.0594 - mse: 14.0594 - val_loss: 7.0938 - val_mse: 7.0938\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 10.0961 - mse: 10.0961 - val_loss: 5.2962 - val_mse: 5.2962\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 7.3040 - mse: 7.3040 - val_loss: 4.7576 - val_mse: 4.7576\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.7641 - mse: 5.7641 - val_loss: 5.1299 - val_mse: 5.1299\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2969 - mse: 5.2969 - val_loss: 5.8663 - val_mse: 5.8663\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3467 - mse: 5.3467 - val_loss: 6.2676 - val_mse: 6.2676\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3975 - mse: 5.3975 - val_loss: 6.1791 - val_mse: 6.1791\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3738 - mse: 5.3738 - val_loss: 6.1004 - val_mse: 6.1004\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3424 - mse: 5.3424 - val_loss: 5.9557 - val_mse: 5.9557\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2914 - mse: 5.2914 - val_loss: 5.7546 - val_mse: 5.7546\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2559 - mse: 5.2559 - val_loss: 5.4700 - val_mse: 5.4700\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2332 - mse: 5.2332 - val_loss: 5.2289 - val_mse: 5.2289\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2869 - mse: 5.2869 - val_loss: 5.0515 - val_mse: 5.0515\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3443 - mse: 5.3443 - val_loss: 4.9806 - val_mse: 4.9806\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.3625 - mse: 5.3625 - val_loss: 5.0295 - val_mse: 5.0295\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.3161 - mse: 5.3161 - val_loss: 5.1308 - val_mse: 5.1308\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2738 - mse: 5.2738 - val_loss: 5.2801 - val_mse: 5.2801\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2437 - mse: 5.2437 - val_loss: 5.4950 - val_mse: 5.4950\n",
      "wandb: Agent Finished Run: uf378w43 \n",
      "\n",
      "wandb: Agent Starting Run: jf1jda79 with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: jf1jda79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/jf1jda79\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/jf1jda79</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 72ms/step - loss: 18.6604 - mse: 18.6604 - val_loss: 10.0009 - val_mse: 10.0009\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 12.6335 - mse: 12.6335 - val_loss: 5.0127 - val_mse: 5.0127\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 6.3951 - mse: 6.3951 - val_loss: 5.4844 - val_mse: 5.4844\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2670 - mse: 5.2670 - val_loss: 7.2416 - val_mse: 7.2416\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.8010 - mse: 5.8010 - val_loss: 7.4004 - val_mse: 7.4004\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.8536 - mse: 5.8536 - val_loss: 7.0136 - val_mse: 7.0136\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.6455 - mse: 5.6455 - val_loss: 6.3636 - val_mse: 6.3636\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3767 - mse: 5.3767 - val_loss: 5.6574 - val_mse: 5.6574\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2470 - mse: 5.2470 - val_loss: 5.2888 - val_mse: 5.2888\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2498 - mse: 5.2498 - val_loss: 5.2836 - val_mse: 5.2836\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2481 - mse: 5.2481 - val_loss: 5.3500 - val_mse: 5.3500\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2324 - mse: 5.2324 - val_loss: 5.6237 - val_mse: 5.6237\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3140 - mse: 5.3140 - val_loss: 6.1251 - val_mse: 6.1251\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3668 - mse: 5.3668 - val_loss: 6.2718 - val_mse: 6.2718\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3956 - mse: 5.3956 - val_loss: 6.1819 - val_mse: 6.1819\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3668 - mse: 5.3668 - val_loss: 6.0514 - val_mse: 6.0514\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3079 - mse: 5.3079 - val_loss: 5.7459 - val_mse: 5.7459\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2662 - mse: 5.2662 - val_loss: 5.3846 - val_mse: 5.3846\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2329 - mse: 5.2329 - val_loss: 5.2016 - val_mse: 5.2016\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2629 - mse: 5.2629 - val_loss: 5.1077 - val_mse: 5.1077\n",
      "wandb: Agent Finished Run: jf1jda79 \n",
      "\n",
      "wandb: Agent Starting Run: 4d9ww5jf with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: 4d9ww5jf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/4d9ww5jf\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/4d9ww5jf</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 73ms/step - loss: 18.9682 - mse: 18.9682 - val_loss: 12.7508 - val_mse: 12.7508\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 18.4814 - mse: 18.4814 - val_loss: 12.1259 - val_mse: 12.1259\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 17.6001 - mse: 17.6001 - val_loss: 11.0433 - val_mse: 11.0433\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 16.0371 - mse: 16.0371 - val_loss: 9.6485 - val_mse: 9.6485\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 14.2162 - mse: 14.2162 - val_loss: 8.4053 - val_mse: 8.4053\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 12.5761 - mse: 12.5761 - val_loss: 7.4666 - val_mse: 7.4666\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 11.2926 - mse: 11.2926 - val_loss: 6.7711 - val_mse: 6.7711\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 10.2939 - mse: 10.2939 - val_loss: 6.2654 - val_mse: 6.2654\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 9.4219 - mse: 9.4219 - val_loss: 5.9102 - val_mse: 5.9102\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 8.8545 - mse: 8.8545 - val_loss: 5.6542 - val_mse: 5.6542\n",
      "wandb: Agent Finished Run: 4d9ww5jf \n",
      "\n",
      "wandb: Agent Starting Run: cyrg4n1g with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: cyrg4n1g\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/cyrg4n1g\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/cyrg4n1g</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 73ms/step - loss: 18.9997 - mse: 18.9997 - val_loss: 12.4234 - val_mse: 12.4234\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 17.8105 - mse: 17.8105 - val_loss: 10.3983 - val_mse: 10.3983\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 14.5141 - mse: 14.5141 - val_loss: 7.0726 - val_mse: 7.0726\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 10.1364 - mse: 10.1364 - val_loss: 5.4576 - val_mse: 5.4576\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 7.7814 - mse: 7.7814 - val_loss: 4.8361 - val_mse: 4.8361\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 6.3636 - mse: 6.3636 - val_loss: 4.8026 - val_mse: 4.8026\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.6089 - mse: 5.6089 - val_loss: 5.1644 - val_mse: 5.1644\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.3652 - mse: 5.3652 - val_loss: 5.5641 - val_mse: 5.5641\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.1704 - mse: 5.1704 - val_loss: 5.6100 - val_mse: 5.6100\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.2261 - mse: 5.2261 - val_loss: 5.6374 - val_mse: 5.6374\n",
      "wandb: Agent Finished Run: cyrg4n1g \n",
      "\n",
      "wandb: Agent Starting Run: eyhf3cmo with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: eyhf3cmo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/eyhf3cmo\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/eyhf3cmo</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 75ms/step - loss: 18.7814 - mse: 18.7814 - val_loss: 11.1260 - val_mse: 11.1260\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 14.7050 - mse: 14.7050 - val_loss: 5.0113 - val_mse: 5.0113\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 6.3707 - mse: 6.3707 - val_loss: 5.8502 - val_mse: 5.8502\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3283 - mse: 5.3283 - val_loss: 6.9785 - val_mse: 6.9785\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.5920 - mse: 5.5920 - val_loss: 6.3604 - val_mse: 6.3604\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3768 - mse: 5.3768 - val_loss: 5.6627 - val_mse: 5.6627\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.1801 - mse: 5.1801 - val_loss: 5.1692 - val_mse: 5.1692\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 5.3022 - mse: 5.3022 - val_loss: 4.9476 - val_mse: 4.9476\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 5.4411 - mse: 5.4411 - val_loss: 4.9283 - val_mse: 4.9283\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 5.4509 - mse: 5.4509 - val_loss: 4.9957 - val_mse: 4.9957\n",
      "wandb: Agent Finished Run: eyhf3cmo \n",
      "\n",
      "wandb: Agent Starting Run: 64lc3lns with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: 64lc3lns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/64lc3lns\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/64lc3lns</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 72ms/step - loss: 18.9447 - mse: 18.9447 - val_loss: 12.6715 - val_mse: 12.6715\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 18.3566 - mse: 18.3566 - val_loss: 11.9439 - val_mse: 11.9439\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 17.3400 - mse: 17.3400 - val_loss: 10.7551 - val_mse: 10.7551\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 15.6552 - mse: 15.6552 - val_loss: 9.3665 - val_mse: 9.3665\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 13.8562 - mse: 13.8562 - val_loss: 8.2045 - val_mse: 8.2045\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 12.3066 - mse: 12.3066 - val_loss: 7.3277 - val_mse: 7.3277\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 11.0899 - mse: 11.0899 - val_loss: 6.6784 - val_mse: 6.6784\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 10.1529 - mse: 10.1529 - val_loss: 6.2039 - val_mse: 6.2039\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 9.3213 - mse: 9.3213 - val_loss: 5.8664 - val_mse: 5.8664\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 8.7781 - mse: 8.7781 - val_loss: 5.6225 - val_mse: 5.6225\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 8.3146 - mse: 8.3146 - val_loss: 5.4121 - val_mse: 5.4121\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 7.9259 - mse: 7.9259 - val_loss: 5.2299 - val_mse: 5.2299\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 7.4934 - mse: 7.4934 - val_loss: 5.0788 - val_mse: 5.0788\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 7.2247 - mse: 7.2247 - val_loss: 4.9613 - val_mse: 4.9613\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.8714 - mse: 6.8714 - val_loss: 4.8741 - val_mse: 4.8741\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.5422 - mse: 6.5422 - val_loss: 4.8139 - val_mse: 4.8139\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.3744 - mse: 6.3744 - val_loss: 4.7772 - val_mse: 4.7772\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.1549 - mse: 6.1549 - val_loss: 4.7597 - val_mse: 4.7597\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.0179 - mse: 6.0179 - val_loss: 4.7577 - val_mse: 4.7577\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 5.8134 - mse: 5.8134 - val_loss: 4.7713 - val_mse: 4.7713\n",
      "wandb: Agent Finished Run: 64lc3lns \n",
      "\n",
      "wandb: Agent Starting Run: kyncxcs7 with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: kyncxcs7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/kyncxcs7\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/kyncxcs7</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 74ms/step - loss: 18.9585 - mse: 18.9585 - val_loss: 12.2150 - val_mse: 12.2150\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 17.4383 - mse: 17.4383 - val_loss: 9.7377 - val_mse: 9.7377\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 13.5889 - mse: 13.5889 - val_loss: 6.6078 - val_mse: 6.6078\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 9.5368 - mse: 9.5368 - val_loss: 5.2824 - val_mse: 5.2824\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 7.4487 - mse: 7.4487 - val_loss: 4.7925 - val_mse: 4.7925\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 6.1841 - mse: 6.1841 - val_loss: 4.8401 - val_mse: 4.8401\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.5317 - mse: 5.5317 - val_loss: 5.2378 - val_mse: 5.2378\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.3443 - mse: 5.3443 - val_loss: 5.6373 - val_mse: 5.6373\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.1763 - mse: 5.1763 - val_loss: 5.6688 - val_mse: 5.6688\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.2281 - mse: 5.2281 - val_loss: 5.6812 - val_mse: 5.6812\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.2936 - mse: 5.2936 - val_loss: 5.6939 - val_mse: 5.6939\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.2503 - mse: 5.2503 - val_loss: 5.7180 - val_mse: 5.7180\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.2452 - mse: 5.2452 - val_loss: 5.7046 - val_mse: 5.7046\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2580 - mse: 5.2580 - val_loss: 5.6207 - val_mse: 5.6207\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2362 - mse: 5.2362 - val_loss: 5.5408 - val_mse: 5.5408\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2770 - mse: 5.2770 - val_loss: 5.5016 - val_mse: 5.5016\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2872 - mse: 5.2872 - val_loss: 5.4695 - val_mse: 5.4695\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2236 - mse: 5.2236 - val_loss: 5.4253 - val_mse: 5.4253\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2730 - mse: 5.2730 - val_loss: 5.4137 - val_mse: 5.4137\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2380 - mse: 5.2380 - val_loss: 5.3604 - val_mse: 5.3604\n",
      "wandb: Agent Finished Run: kyncxcs7 \n",
      "\n",
      "wandb: Agent Starting Run: lrsyh4um with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: lrsyh4um\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/lrsyh4um\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/lrsyh4um</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 18.7814 - mse: 18.7814 - val_loss: 11.1260 - val_mse: 11.1260\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 14.7050 - mse: 14.7050 - val_loss: 5.0113 - val_mse: 5.0113\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 6.3707 - mse: 6.3707 - val_loss: 5.8502 - val_mse: 5.8502\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3283 - mse: 5.3283 - val_loss: 6.9785 - val_mse: 6.9785\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.5920 - mse: 5.5920 - val_loss: 6.3604 - val_mse: 6.3604\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3768 - mse: 5.3768 - val_loss: 5.6627 - val_mse: 5.6627\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.1801 - mse: 5.1801 - val_loss: 5.1692 - val_mse: 5.1692\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3022 - mse: 5.3022 - val_loss: 4.9476 - val_mse: 4.9476\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.4411 - mse: 5.4411 - val_loss: 4.9283 - val_mse: 4.9283\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.4509 - mse: 5.4509 - val_loss: 4.9957 - val_mse: 4.9957\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2916 - mse: 5.2916 - val_loss: 5.2567 - val_mse: 5.2567\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2073 - mse: 5.2073 - val_loss: 5.5031 - val_mse: 5.5031\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2529 - mse: 5.2529 - val_loss: 5.6993 - val_mse: 5.6993\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3124 - mse: 5.3124 - val_loss: 5.6297 - val_mse: 5.6297\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2013 - mse: 5.2013 - val_loss: 5.4812 - val_mse: 5.4812\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2051 - mse: 5.2051 - val_loss: 5.4691 - val_mse: 5.4691\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2661 - mse: 5.2661 - val_loss: 5.5170 - val_mse: 5.5170\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.1960 - mse: 5.1960 - val_loss: 5.3918 - val_mse: 5.3918\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2088 - mse: 5.2088 - val_loss: 5.1596 - val_mse: 5.1596\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2549 - mse: 5.2549 - val_loss: 5.0301 - val_mse: 5.0301\n",
      "wandb: Agent Finished Run: lrsyh4um \n",
      "\n",
      "wandb: Agent Starting Run: t5l5vy0h with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: t5l5vy0h\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/t5l5vy0h\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/t5l5vy0h</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 71ms/step - loss: 18.9728 - mse: 18.9728 - val_loss: 12.7599 - val_mse: 12.7599\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 18.5218 - mse: 18.5218 - val_loss: 12.1696 - val_mse: 12.1696\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 17.6851 - mse: 17.6851 - val_loss: 11.1535 - val_mse: 11.1535\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 16.2080 - mse: 16.2080 - val_loss: 9.7876 - val_mse: 9.7876\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 14.4569 - mse: 14.4569 - val_loss: 8.5210 - val_mse: 8.5210\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 13.0247 - mse: 13.0247 - val_loss: 7.5657 - val_mse: 7.5657\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 11.7605 - mse: 11.7605 - val_loss: 6.8599 - val_mse: 6.8599\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 10.6160 - mse: 10.6160 - val_loss: 6.3487 - val_mse: 6.3487\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 9.7363 - mse: 9.7363 - val_loss: 5.9872 - val_mse: 5.9872\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 9.0928 - mse: 9.0928 - val_loss: 5.7263 - val_mse: 5.7263\n",
      "wandb: Agent Finished Run: t5l5vy0h \n",
      "\n",
      "wandb: Agent Starting Run: zmbo4ztk with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: zmbo4ztk\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/zmbo4ztk\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/zmbo4ztk</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 73ms/step - loss: 18.9995 - mse: 18.9995 - val_loss: 12.4199 - val_mse: 12.4199\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 17.8061 - mse: 17.8061 - val_loss: 10.3965 - val_mse: 10.3965\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 14.5761 - mse: 14.5761 - val_loss: 7.0791 - val_mse: 7.0791\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 10.3469 - mse: 10.3469 - val_loss: 5.4770 - val_mse: 5.4770\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 7.9833 - mse: 7.9833 - val_loss: 4.8493 - val_mse: 4.8493\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 6.5761 - mse: 6.5761 - val_loss: 4.7906 - val_mse: 4.7906\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.6532 - mse: 5.6532 - val_loss: 5.1265 - val_mse: 5.1265\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3813 - mse: 5.3813 - val_loss: 5.5176 - val_mse: 5.5176\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.1520 - mse: 5.1520 - val_loss: 5.5779 - val_mse: 5.5779\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2592 - mse: 5.2592 - val_loss: 5.6249 - val_mse: 5.6249\n",
      "wandb: Agent Finished Run: zmbo4ztk \n",
      "\n",
      "wandb: Agent Starting Run: dibp7dbr with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: dibp7dbr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/dibp7dbr\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/dibp7dbr</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 75ms/step - loss: 18.7929 - mse: 18.7929 - val_loss: 11.2071 - val_mse: 11.2071\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 14.8567 - mse: 14.8567 - val_loss: 5.0530 - val_mse: 5.0530\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 6.5882 - mse: 6.5882 - val_loss: 5.7942 - val_mse: 5.7942\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3246 - mse: 5.3246 - val_loss: 7.0491 - val_mse: 7.0491\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.5414 - mse: 5.5414 - val_loss: 6.5257 - val_mse: 6.5257\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3488 - mse: 5.3488 - val_loss: 5.8273 - val_mse: 5.8273\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2047 - mse: 5.2047 - val_loss: 5.2826 - val_mse: 5.2826\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2635 - mse: 5.2635 - val_loss: 4.9973 - val_mse: 4.9973\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3902 - mse: 5.3902 - val_loss: 4.9395 - val_mse: 4.9395\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.4897 - mse: 5.4897 - val_loss: 4.9828 - val_mse: 4.9828\n",
      "wandb: Agent Finished Run: dibp7dbr \n",
      "\n",
      "wandb: Agent Starting Run: 5qt9x7tg with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: 5qt9x7tg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/5qt9x7tg\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/5qt9x7tg</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 71ms/step - loss: 18.9728 - mse: 18.9728 - val_loss: 12.7599 - val_mse: 12.7599\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 18.5218 - mse: 18.5218 - val_loss: 12.1696 - val_mse: 12.1696\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 17.6851 - mse: 17.6851 - val_loss: 11.1535 - val_mse: 11.1535\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 16.2080 - mse: 16.2080 - val_loss: 9.7876 - val_mse: 9.7876\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 14.4569 - mse: 14.4569 - val_loss: 8.5210 - val_mse: 8.5210\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 13.0247 - mse: 13.0247 - val_loss: 7.5657 - val_mse: 7.5657\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 11.7605 - mse: 11.7605 - val_loss: 6.8599 - val_mse: 6.8599\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 10.6160 - mse: 10.6160 - val_loss: 6.3487 - val_mse: 6.3487\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 9.7363 - mse: 9.7363 - val_loss: 5.9872 - val_mse: 5.9872\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 9.0928 - mse: 9.0928 - val_loss: 5.7263 - val_mse: 5.7263\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 8.6278 - mse: 8.6278 - val_loss: 5.4986 - val_mse: 5.4986\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 8.1881 - mse: 8.1881 - val_loss: 5.3007 - val_mse: 5.3007\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 7.7969 - mse: 7.7969 - val_loss: 5.1355 - val_mse: 5.1355\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 7.4163 - mse: 7.4163 - val_loss: 5.0057 - val_mse: 5.0057\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.9546 - mse: 6.9546 - val_loss: 4.9072 - val_mse: 4.9072\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.7434 - mse: 6.7434 - val_loss: 4.8371 - val_mse: 4.8371\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.5300 - mse: 6.5300 - val_loss: 4.7911 - val_mse: 4.7911\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 6.2813 - mse: 6.2813 - val_loss: 4.7656 - val_mse: 4.7656\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 6.1571 - mse: 6.1571 - val_loss: 4.7565 - val_mse: 4.7565\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.8605 - mse: 5.8605 - val_loss: 4.7644 - val_mse: 4.7644\n",
      "wandb: Agent Finished Run: 5qt9x7tg \n",
      "\n",
      "wandb: Agent Starting Run: 3szeqcxv with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: 3szeqcxv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/3szeqcxv\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/3szeqcxv</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 73ms/step - loss: 18.9995 - mse: 18.9995 - val_loss: 12.4199 - val_mse: 12.4199\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 17.8061 - mse: 17.8061 - val_loss: 10.3965 - val_mse: 10.3965\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 14.5604 - mse: 14.5604 - val_loss: 7.0632 - val_mse: 7.0632\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 10.3250 - mse: 10.3250 - val_loss: 5.4706 - val_mse: 5.4706\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 7.9713 - mse: 7.9713 - val_loss: 4.8475 - val_mse: 4.8475\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 6.5689 - mse: 6.5689 - val_loss: 4.7921 - val_mse: 4.7921\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.6481 - mse: 5.6481 - val_loss: 5.1304 - val_mse: 5.1304\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3791 - mse: 5.3791 - val_loss: 5.5198 - val_mse: 5.5198\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.1520 - mse: 5.1520 - val_loss: 5.5792 - val_mse: 5.5792\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2590 - mse: 5.2590 - val_loss: 5.6260 - val_mse: 5.6260\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2889 - mse: 5.2889 - val_loss: 5.6762 - val_mse: 5.6762\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2599 - mse: 5.2599 - val_loss: 5.7346 - val_mse: 5.7346\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2804 - mse: 5.2804 - val_loss: 5.7528 - val_mse: 5.7528\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.3064 - mse: 5.3064 - val_loss: 5.6907 - val_mse: 5.6907\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2086 - mse: 5.2086 - val_loss: 5.6250 - val_mse: 5.6250\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 5.2626 - mse: 5.2626 - val_loss: 5.5915 - val_mse: 5.5915\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.3178 - mse: 5.3178 - val_loss: 5.5604 - val_mse: 5.5604\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2629 - mse: 5.2629 - val_loss: 5.5174 - val_mse: 5.5174\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2931 - mse: 5.2931 - val_loss: 5.5049 - val_mse: 5.5049\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2852 - mse: 5.2852 - val_loss: 5.4455 - val_mse: 5.4455\n",
      "wandb: Agent Finished Run: 3szeqcxv \n",
      "\n",
      "wandb: Agent Starting Run: wvl8n2rj with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: wvl8n2rj\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/wvl8n2rj\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/wvl8n2rj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 18.7929 - mse: 18.7929 - val_loss: 11.2071 - val_mse: 11.2071\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 14.8567 - mse: 14.8567 - val_loss: 5.0530 - val_mse: 5.0530\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 6.5882 - mse: 6.5882 - val_loss: 5.7942 - val_mse: 5.7942\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3246 - mse: 5.3246 - val_loss: 7.0491 - val_mse: 7.0491\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.5414 - mse: 5.5414 - val_loss: 6.5257 - val_mse: 6.5257\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3488 - mse: 5.3488 - val_loss: 5.8273 - val_mse: 5.8273\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2047 - mse: 5.2047 - val_loss: 5.2826 - val_mse: 5.2826\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2635 - mse: 5.2635 - val_loss: 4.9973 - val_mse: 4.9973\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3902 - mse: 5.3902 - val_loss: 4.9395 - val_mse: 4.9395\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.4897 - mse: 5.4897 - val_loss: 4.9828 - val_mse: 4.9828\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2522 - mse: 5.2522 - val_loss: 5.2330 - val_mse: 5.2330\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2093 - mse: 5.2093 - val_loss: 5.4939 - val_mse: 5.4939\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.2629 - mse: 5.2629 - val_loss: 5.7129 - val_mse: 5.7129\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.2732 - mse: 5.2732 - val_loss: 5.6575 - val_mse: 5.6575\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.1918 - mse: 5.1918 - val_loss: 5.5195 - val_mse: 5.5195\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.1807 - mse: 5.1807 - val_loss: 5.5119 - val_mse: 5.5119\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.2858 - mse: 5.2858 - val_loss: 5.5566 - val_mse: 5.5566\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2152 - mse: 5.2152 - val_loss: 5.4276 - val_mse: 5.4276\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2877 - mse: 5.2877 - val_loss: 5.1925 - val_mse: 5.1925\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 5.3761 - mse: 5.3761 - val_loss: 5.0578 - val_mse: 5.0578\n",
      "wandb: Agent Finished Run: wvl8n2rj \n",
      "\n",
      "wandb: Agent Starting Run: 7qgqcorp with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: 7qgqcorp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/7qgqcorp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/7qgqcorp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 71ms/step - loss: 18.9595 - mse: 18.9595 - val_loss: 12.6813 - val_mse: 12.6813\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 18.4257 - mse: 18.4257 - val_loss: 12.0072 - val_mse: 12.0072\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 17.5254 - mse: 17.5254 - val_loss: 10.8855 - val_mse: 10.8855\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 16.0792 - mse: 16.0792 - val_loss: 9.5131 - val_mse: 9.5131\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 14.4617 - mse: 14.4617 - val_loss: 8.3602 - val_mse: 8.3602\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 13.2906 - mse: 13.2906 - val_loss: 7.4981 - val_mse: 7.4981\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 12.1235 - mse: 12.1235 - val_loss: 6.8542 - val_mse: 6.8542\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 11.0347 - mse: 11.0347 - val_loss: 6.3741 - val_mse: 6.3741\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 10.0394 - mse: 10.0394 - val_loss: 6.0235 - val_mse: 6.0235\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 9.4996 - mse: 9.4996 - val_loss: 5.7609 - val_mse: 5.7609\n",
      "wandb: Agent Finished Run: 7qgqcorp \n",
      "\n",
      "wandb: Agent Starting Run: zxor7o5m with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: zxor7o5m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/zxor7o5m\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/zxor7o5m</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 71ms/step - loss: 18.9458 - mse: 18.9458 - val_loss: 12.2330 - val_mse: 12.2330\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 17.5447 - mse: 17.5447 - val_loss: 9.9347 - val_mse: 9.9347\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 14.0950 - mse: 14.0950 - val_loss: 6.7692 - val_mse: 6.7692\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 10.4201 - mse: 10.4201 - val_loss: 5.3779 - val_mse: 5.3779\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 8.1865 - mse: 8.1865 - val_loss: 4.8288 - val_mse: 4.8288\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 6.9167 - mse: 6.9167 - val_loss: 4.7963 - val_mse: 4.7963\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.7617 - mse: 5.7617 - val_loss: 5.1171 - val_mse: 5.1171\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.5912 - mse: 5.5912 - val_loss: 5.4849 - val_mse: 5.4849\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.1604 - mse: 5.1604 - val_loss: 5.5691 - val_mse: 5.5691\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3193 - mse: 5.3193 - val_loss: 5.6467 - val_mse: 5.6467\n",
      "wandb: Agent Finished Run: zxor7o5m \n",
      "\n",
      "wandb: Agent Starting Run: 2swkhh8f with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: 2swkhh8f\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/2swkhh8f\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/2swkhh8f</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 18.8579 - mse: 18.8579 - val_loss: 11.6642 - val_mse: 11.6642\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 15.9088 - mse: 15.9088 - val_loss: 5.4929 - val_mse: 5.4929\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 7.7655 - mse: 7.7655 - val_loss: 5.3168 - val_mse: 5.3168\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3384 - mse: 5.3384 - val_loss: 6.8003 - val_mse: 6.8003\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.4666 - mse: 5.4666 - val_loss: 6.7640 - val_mse: 6.7640\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3965 - mse: 5.3965 - val_loss: 6.2287 - val_mse: 6.2287\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.1904 - mse: 5.1904 - val_loss: 5.6272 - val_mse: 5.6272\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2586 - mse: 5.2586 - val_loss: 5.2071 - val_mse: 5.2071\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.3769 - mse: 5.3769 - val_loss: 5.0522 - val_mse: 5.0522\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.4169 - mse: 5.4169 - val_loss: 5.0229 - val_mse: 5.0229\n",
      "wandb: Agent Finished Run: 2swkhh8f \n",
      "\n",
      "wandb: Agent Starting Run: bc1u5als with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: bc1u5als\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/bc1u5als\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/bc1u5als</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 72ms/step - loss: 18.9595 - mse: 18.9595 - val_loss: 12.6813 - val_mse: 12.6813\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 18.4257 - mse: 18.4257 - val_loss: 12.0072 - val_mse: 12.0072\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 17.5254 - mse: 17.5254 - val_loss: 10.8855 - val_mse: 10.8855\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 16.0792 - mse: 16.0792 - val_loss: 9.5131 - val_mse: 9.5131\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 14.4617 - mse: 14.4617 - val_loss: 8.3602 - val_mse: 8.3602\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 13.2906 - mse: 13.2906 - val_loss: 7.4981 - val_mse: 7.4981\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 12.1235 - mse: 12.1235 - val_loss: 6.8542 - val_mse: 6.8542\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 11.0347 - mse: 11.0347 - val_loss: 6.3741 - val_mse: 6.3741\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 10.0394 - mse: 10.0394 - val_loss: 6.0235 - val_mse: 6.0235\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 9.4996 - mse: 9.4996 - val_loss: 5.7609 - val_mse: 5.7609\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 8.8313 - mse: 8.8313 - val_loss: 5.5314 - val_mse: 5.5314\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 8.4286 - mse: 8.4286 - val_loss: 5.3319 - val_mse: 5.3319\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 8.0778 - mse: 8.0778 - val_loss: 5.1644 - val_mse: 5.1644\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 7.5175 - mse: 7.5175 - val_loss: 5.0320 - val_mse: 5.0320\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 7.2218 - mse: 7.2218 - val_loss: 4.9296 - val_mse: 4.9296\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 6.8788 - mse: 6.8788 - val_loss: 4.8550 - val_mse: 4.8550\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 6.7517 - mse: 6.7517 - val_loss: 4.8042 - val_mse: 4.8042\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 6.4020 - mse: 6.4020 - val_loss: 4.7735 - val_mse: 4.7735\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 6.3384 - mse: 6.3384 - val_loss: 4.7581 - val_mse: 4.7581\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 5.9359 - mse: 5.9359 - val_loss: 4.7589 - val_mse: 4.7589\n",
      "wandb: Agent Finished Run: bc1u5als \n",
      "\n",
      "wandb: Agent Starting Run: b6fuci94 with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: b6fuci94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/b6fuci94\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/b6fuci94</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 72ms/step - loss: 18.9458 - mse: 18.9458 - val_loss: 12.1902 - val_mse: 12.1902\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 17.4518 - mse: 17.4518 - val_loss: 9.7042 - val_mse: 9.7042\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 13.8005 - mse: 13.8005 - val_loss: 6.6114 - val_mse: 6.6114\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 10.2135 - mse: 10.2135 - val_loss: 5.3146 - val_mse: 5.3146\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 8.0542 - mse: 8.0542 - val_loss: 4.8120 - val_mse: 4.8120\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 6.8374 - mse: 6.8374 - val_loss: 4.8070 - val_mse: 4.8070\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.7260 - mse: 5.7260 - val_loss: 5.1377 - val_mse: 5.1377\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.5773 - mse: 5.5773 - val_loss: 5.5058 - val_mse: 5.5058\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.1592 - mse: 5.1592 - val_loss: 5.5868 - val_mse: 5.5868\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.3170 - mse: 5.3170 - val_loss: 5.6601 - val_mse: 5.6601\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.2825 - mse: 5.2825 - val_loss: 5.7362 - val_mse: 5.7362\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.3391 - mse: 5.3391 - val_loss: 5.8174 - val_mse: 5.8174\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2028 - mse: 5.2028 - val_loss: 5.8563 - val_mse: 5.8563\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2975 - mse: 5.2975 - val_loss: 5.8100 - val_mse: 5.8100\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.3194 - mse: 5.3194 - val_loss: 5.7473 - val_mse: 5.7473\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2801 - mse: 5.2801 - val_loss: 5.7117 - val_mse: 5.7117\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2601 - mse: 5.2601 - val_loss: 5.6760 - val_mse: 5.6760\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2488 - mse: 5.2488 - val_loss: 5.6261 - val_mse: 5.6261\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.3683 - mse: 5.3683 - val_loss: 5.6027 - val_mse: 5.6027\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2903 - mse: 5.2903 - val_loss: 5.5340 - val_mse: 5.5340\n",
      "wandb: Agent Finished Run: b6fuci94 \n",
      "\n",
      "wandb: Agent Starting Run: wipfoxo2 with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 32\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: wipfoxo2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/wipfoxo2\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/wipfoxo2</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 75ms/step - loss: 18.7611 - mse: 18.7611 - val_loss: 11.0517 - val_mse: 11.0517\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 14.7594 - mse: 14.7594 - val_loss: 5.0006 - val_mse: 5.0006\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 6.9263 - mse: 6.9263 - val_loss: 5.7083 - val_mse: 5.7083\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2995 - mse: 5.2995 - val_loss: 7.1415 - val_mse: 7.1415\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 5.5555 - mse: 5.5555 - val_loss: 6.8646 - val_mse: 6.8646\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 5.4262 - mse: 5.4262 - val_loss: 6.1992 - val_mse: 6.1992\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 5.1810 - mse: 5.1810 - val_loss: 5.5718 - val_mse: 5.5718\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 5.2647 - mse: 5.2647 - val_loss: 5.1685 - val_mse: 5.1685\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3895 - mse: 5.3895 - val_loss: 5.0269 - val_mse: 5.0269\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.4236 - mse: 5.4236 - val_loss: 5.0026 - val_mse: 5.0026\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 5.2089 - mse: 5.2089 - val_loss: 5.1756 - val_mse: 5.1756\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2971 - mse: 5.2971 - val_loss: 5.3730 - val_mse: 5.3730\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3989 - mse: 5.3989 - val_loss: 5.5858 - val_mse: 5.5858\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2000 - mse: 5.2000 - val_loss: 5.5823 - val_mse: 5.5823\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.0957 - mse: 5.0957 - val_loss: 5.5044 - val_mse: 5.5044\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.1773 - mse: 5.1773 - val_loss: 5.5554 - val_mse: 5.5554\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.3036 - mse: 5.3036 - val_loss: 5.6567 - val_mse: 5.6567\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2959 - mse: 5.2959 - val_loss: 5.5613 - val_mse: 5.5613\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2865 - mse: 5.2865 - val_loss: 5.3111 - val_mse: 5.3111\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 5.2799 - mse: 5.2799 - val_loss: 5.1541 - val_mse: 5.1541\n",
      "wandb: Agent Finished Run: wipfoxo2 \n",
      "\n",
      "wandb: Agent Starting Run: cmx0xtx3 with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: cmx0xtx3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/cmx0xtx3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/cmx0xtx3</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 61ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "wandb: Agent Finished Run: cmx0xtx3 \n",
      "\n",
      "wandb: Agent Starting Run: 9rtxa2nf with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: 9rtxa2nf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/9rtxa2nf\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/9rtxa2nf</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 62ms/step - loss: 19.1062 - mse: 19.1062 - val_loss: 12.7029 - val_mse: 12.7029\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.5033 - mse: 18.5033 - val_loss: 11.7845 - val_mse: 11.7845\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.2570 - mse: 17.2570 - val_loss: 10.0311 - val_mse: 10.0311\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.8423 - mse: 14.8423 - val_loss: 7.9417 - val_mse: 7.9417\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.9491 - mse: 11.9491 - val_loss: 6.3163 - val_mse: 6.3163\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.4384 - mse: 9.4384 - val_loss: 5.2646 - val_mse: 5.2646\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.5713 - mse: 7.5713 - val_loss: 4.7980 - val_mse: 4.7980\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3212 - mse: 6.3212 - val_loss: 4.7903 - val_mse: 4.7903\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.6294 - mse: 5.6294 - val_loss: 4.9813 - val_mse: 4.9813\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.3586 - mse: 5.3586 - val_loss: 5.3183 - val_mse: 5.3183\n",
      "wandb: Agent Finished Run: 9rtxa2nf \n",
      "\n",
      "wandb: Agent Starting Run: v1jlmb8q with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: v1jlmb8q\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/v1jlmb8q\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/v1jlmb8q</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 18.9447 - mse: 18.9447 - val_loss: 11.0999 - val_mse: 11.0999\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 16.1183 - mse: 16.1183 - val_loss: 6.8761 - val_mse: 6.8761\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 10.0330 - mse: 10.0330 - val_loss: 4.8191 - val_mse: 4.8191\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.3584 - mse: 6.3584 - val_loss: 5.1305 - val_mse: 5.1305\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2529 - mse: 5.2529 - val_loss: 6.4971 - val_mse: 6.4971\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.4625 - mse: 5.4625 - val_loss: 7.9082 - val_mse: 7.9082\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.1392 - mse: 6.1392 - val_loss: 8.3152 - val_mse: 8.3152\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.3462 - mse: 6.3462 - val_loss: 7.7394 - val_mse: 7.7394\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.0550 - mse: 6.0550 - val_loss: 7.1001 - val_mse: 7.1001\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.7238 - mse: 5.7238 - val_loss: 6.5932 - val_mse: 6.5932\n",
      "wandb: Agent Finished Run: v1jlmb8q \n",
      "\n",
      "wandb: Agent Starting Run: gjowc5et with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: gjowc5et\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/gjowc5et\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/gjowc5et</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 61ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "wandb: Agent Finished Run: gjowc5et \n",
      "\n",
      "wandb: Agent Starting Run: qfln6hzf with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: qfln6hzf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/qfln6hzf\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/qfln6hzf</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 62ms/step - loss: 19.1024 - mse: 19.1024 - val_loss: 12.5670 - val_mse: 12.5670\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.3123 - mse: 18.3123 - val_loss: 11.4172 - val_mse: 11.4172\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.7529 - mse: 16.7529 - val_loss: 9.4259 - val_mse: 9.4259\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.0136 - mse: 14.0136 - val_loss: 7.4001 - val_mse: 7.4001\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.1641 - mse: 11.1641 - val_loss: 5.9415 - val_mse: 5.9415\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.8101 - mse: 8.8101 - val_loss: 5.0636 - val_mse: 5.0636\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.1148 - mse: 7.1148 - val_loss: 4.7607 - val_mse: 4.7607\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.0492 - mse: 6.0492 - val_loss: 4.8459 - val_mse: 4.8459\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.4977 - mse: 5.4977 - val_loss: 5.0698 - val_mse: 5.0698\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3064 - mse: 5.3064 - val_loss: 5.4090 - val_mse: 5.4090\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2384 - mse: 5.2384 - val_loss: 5.7705 - val_mse: 5.7705\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2786 - mse: 5.2786 - val_loss: 5.9964 - val_mse: 5.9964\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3198 - mse: 5.3198 - val_loss: 6.0096 - val_mse: 6.0096\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3191 - mse: 5.3191 - val_loss: 5.8817 - val_mse: 5.8817\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2864 - mse: 5.2864 - val_loss: 5.6814 - val_mse: 5.6814\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2597 - mse: 5.2597 - val_loss: 5.5258 - val_mse: 5.5258\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2415 - mse: 5.2415 - val_loss: 5.4571 - val_mse: 5.4571\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2377 - mse: 5.2377 - val_loss: 5.4214 - val_mse: 5.4214\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2388 - mse: 5.2388 - val_loss: 5.4195 - val_mse: 5.4195\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2373 - mse: 5.2373 - val_loss: 5.4716 - val_mse: 5.4716\n",
      "wandb: Agent Finished Run: qfln6hzf \n",
      "\n",
      "wandb: Agent Starting Run: wy2twnvg with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0\n",
      "wandb: Agent Started Run: wy2twnvg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/wy2twnvg\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/wy2twnvg</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 18.9447 - mse: 18.9447 - val_loss: 11.0999 - val_mse: 11.0999\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 16.1183 - mse: 16.1183 - val_loss: 6.8761 - val_mse: 6.8761\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 10.0330 - mse: 10.0330 - val_loss: 4.8191 - val_mse: 4.8191\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.3584 - mse: 6.3584 - val_loss: 5.1305 - val_mse: 5.1305\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2529 - mse: 5.2529 - val_loss: 6.4971 - val_mse: 6.4971\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.4625 - mse: 5.4625 - val_loss: 7.9082 - val_mse: 7.9082\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.1392 - mse: 6.1392 - val_loss: 8.3152 - val_mse: 8.3152\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.3462 - mse: 6.3462 - val_loss: 7.7394 - val_mse: 7.7394\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.0550 - mse: 6.0550 - val_loss: 7.1001 - val_mse: 7.1001\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.7238 - mse: 5.7238 - val_loss: 6.5932 - val_mse: 6.5932\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.5155 - mse: 5.5155 - val_loss: 6.1284 - val_mse: 6.1284\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3803 - mse: 5.3803 - val_loss: 5.9972 - val_mse: 5.9972\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3193 - mse: 5.3193 - val_loss: 6.0480 - val_mse: 6.0480\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3308 - mse: 5.3308 - val_loss: 5.9667 - val_mse: 5.9667\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3140 - mse: 5.3140 - val_loss: 5.8861 - val_mse: 5.8861\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2912 - mse: 5.2912 - val_loss: 5.8183 - val_mse: 5.8183\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2735 - mse: 5.2735 - val_loss: 5.6360 - val_mse: 5.6360\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2491 - mse: 5.2491 - val_loss: 5.4272 - val_mse: 5.4272\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2391 - mse: 5.2391 - val_loss: 5.2898 - val_mse: 5.2898\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2449 - mse: 5.2449 - val_loss: 5.1753 - val_mse: 5.1753\n",
      "wandb: Agent Finished Run: wy2twnvg \n",
      "\n",
      "wandb: Agent Starting Run: 366hfpcp with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: 366hfpcp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/366hfpcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/366hfpcp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0267 - mse: 19.0267 - val_loss: 12.8294 - val_mse: 12.8294\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.6998 - mse: 18.6998 - val_loss: 12.4774 - val_mse: 12.4774\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.2257 - mse: 18.2257 - val_loss: 11.9565 - val_mse: 11.9565\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 17.5423 - mse: 17.5423 - val_loss: 11.2246 - val_mse: 11.2246\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 16.6243 - mse: 16.6243 - val_loss: 10.3051 - val_mse: 10.3051\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 15.3637 - mse: 15.3637 - val_loss: 9.3599 - val_mse: 9.3599\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 14.1662 - mse: 14.1662 - val_loss: 8.5397 - val_mse: 8.5397\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.0077 - mse: 13.0077 - val_loss: 7.8657 - val_mse: 7.8657\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.1519 - mse: 12.1519 - val_loss: 7.3516 - val_mse: 7.3516\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.3180 - mse: 11.3180 - val_loss: 6.9475 - val_mse: 6.9475\n",
      "wandb: Agent Finished Run: 366hfpcp \n",
      "\n",
      "wandb: Agent Starting Run: vf5kdv4c with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: vf5kdv4c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/vf5kdv4c\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/vf5kdv4c</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.1038 - mse: 19.1038 - val_loss: 12.6188 - val_mse: 12.6188\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.3851 - mse: 18.3851 - val_loss: 11.6588 - val_mse: 11.6588\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.0117 - mse: 17.0117 - val_loss: 9.7679 - val_mse: 9.7679\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.4869 - mse: 14.4869 - val_loss: 7.4541 - val_mse: 7.4541\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.4014 - mse: 11.4014 - val_loss: 6.0262 - val_mse: 6.0262\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.1076 - mse: 9.1076 - val_loss: 5.2776 - val_mse: 5.2776\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.8232 - mse: 7.8232 - val_loss: 4.8881 - val_mse: 4.8881\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.7926 - mse: 6.7926 - val_loss: 4.7701 - val_mse: 4.7701\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1718 - mse: 6.1718 - val_loss: 4.7572 - val_mse: 4.7572\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.9054 - mse: 5.9054 - val_loss: 4.7886 - val_mse: 4.7886\n",
      "wandb: Agent Finished Run: vf5kdv4c \n",
      "\n",
      "wandb: Agent Starting Run: ks2adam9 with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: ks2adam9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/ks2adam9\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/ks2adam9</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 19.0842 - mse: 19.0842 - val_loss: 12.2539 - val_mse: 12.2539\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 17.8438 - mse: 17.8438 - val_loss: 8.6433 - val_mse: 8.6433\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 12.7075 - mse: 12.7075 - val_loss: 5.0112 - val_mse: 5.0112\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 7.1184 - mse: 7.1184 - val_loss: 4.8937 - val_mse: 4.8937\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.5098 - mse: 5.5098 - val_loss: 5.4758 - val_mse: 5.4758\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2563 - mse: 5.2563 - val_loss: 6.0494 - val_mse: 6.0494\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.3066 - mse: 5.3066 - val_loss: 6.0407 - val_mse: 6.0407\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3501 - mse: 5.3501 - val_loss: 5.7084 - val_mse: 5.7084\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.3082 - mse: 5.3082 - val_loss: 5.3422 - val_mse: 5.3422\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.3033 - mse: 5.3033 - val_loss: 5.1992 - val_mse: 5.1992\n",
      "wandb: Agent Finished Run: ks2adam9 \n",
      "\n",
      "wandb: Agent Starting Run: rjeqoqzj with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: rjeqoqzj\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/rjeqoqzj\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/rjeqoqzj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0289 - mse: 19.0289 - val_loss: 12.8846 - val_mse: 12.8846\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.7735 - mse: 18.7735 - val_loss: 12.5885 - val_mse: 12.5885\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.3740 - mse: 18.3740 - val_loss: 12.1427 - val_mse: 12.1427\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 17.7864 - mse: 17.7864 - val_loss: 11.4929 - val_mse: 11.4929\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 16.9694 - mse: 16.9694 - val_loss: 10.6234 - val_mse: 10.6234\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 15.7761 - mse: 15.7761 - val_loss: 9.6603 - val_mse: 9.6603\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 14.5641 - mse: 14.5641 - val_loss: 8.7841 - val_mse: 8.7841\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.3431 - mse: 13.3431 - val_loss: 8.0581 - val_mse: 8.0581\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.4303 - mse: 12.4303 - val_loss: 7.5048 - val_mse: 7.5048\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.5500 - mse: 11.5500 - val_loss: 7.0701 - val_mse: 7.0701\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 10.8775 - mse: 10.8775 - val_loss: 6.6907 - val_mse: 6.6907\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 10.2787 - mse: 10.2787 - val_loss: 6.3671 - val_mse: 6.3671\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 9.6854 - mse: 9.6854 - val_loss: 6.0985 - val_mse: 6.0985\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 9.3097 - mse: 9.3097 - val_loss: 5.8733 - val_mse: 5.8733\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 8.8914 - mse: 8.8914 - val_loss: 5.6818 - val_mse: 5.6818\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 8.4912 - mse: 8.4912 - val_loss: 5.5178 - val_mse: 5.5178\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 8.1569 - mse: 8.1569 - val_loss: 5.3798 - val_mse: 5.3798\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 7.8770 - mse: 7.8770 - val_loss: 5.2602 - val_mse: 5.2602\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 7.6303 - mse: 7.6303 - val_loss: 5.1509 - val_mse: 5.1509\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 7.3833 - mse: 7.3833 - val_loss: 5.0600 - val_mse: 5.0600\n",
      "wandb: Agent Finished Run: rjeqoqzj \n",
      "\n",
      "wandb: Agent Starting Run: pv2qzyig with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: pv2qzyig\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/pv2qzyig\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/pv2qzyig</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.1038 - mse: 19.1038 - val_loss: 12.6188 - val_mse: 12.6188\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.3851 - mse: 18.3851 - val_loss: 11.6588 - val_mse: 11.6588\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.0117 - mse: 17.0117 - val_loss: 9.7679 - val_mse: 9.7679\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 14.4869 - mse: 14.4869 - val_loss: 7.4541 - val_mse: 7.4541\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 11.4014 - mse: 11.4014 - val_loss: 6.0262 - val_mse: 6.0262\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 9.1076 - mse: 9.1076 - val_loss: 5.2776 - val_mse: 5.2776\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 7.8232 - mse: 7.8232 - val_loss: 4.8881 - val_mse: 4.8881\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.7926 - mse: 6.7926 - val_loss: 4.7701 - val_mse: 4.7701\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1718 - mse: 6.1718 - val_loss: 4.7572 - val_mse: 4.7572\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.9054 - mse: 5.9054 - val_loss: 4.7886 - val_mse: 4.7886\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.7878 - mse: 5.7878 - val_loss: 4.8768 - val_mse: 4.8768\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.4646 - mse: 5.4646 - val_loss: 5.0214 - val_mse: 5.0214\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.4249 - mse: 5.4249 - val_loss: 5.1735 - val_mse: 5.1735\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2896 - mse: 5.2896 - val_loss: 5.2912 - val_mse: 5.2912\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2021 - mse: 5.2021 - val_loss: 5.4129 - val_mse: 5.4129\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2829 - mse: 5.2829 - val_loss: 5.5404 - val_mse: 5.5404\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2856 - mse: 5.2856 - val_loss: 5.6269 - val_mse: 5.6269\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2106 - mse: 5.2106 - val_loss: 5.6956 - val_mse: 5.6956\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.3023 - mse: 5.3023 - val_loss: 5.7384 - val_mse: 5.7384\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2924 - mse: 5.2924 - val_loss: 5.6968 - val_mse: 5.6968\n",
      "wandb: Agent Finished Run: pv2qzyig \n",
      "\n",
      "wandb: Agent Starting Run: hkn08b7i with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.2\n",
      "wandb: Agent Started Run: hkn08b7i\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/hkn08b7i\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/hkn08b7i</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 70ms/step - loss: 19.0842 - mse: 19.0842 - val_loss: 12.2539 - val_mse: 12.2539\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 17.8438 - mse: 17.8438 - val_loss: 8.6433 - val_mse: 8.6433\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 12.7075 - mse: 12.7075 - val_loss: 5.0112 - val_mse: 5.0112\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 7.1184 - mse: 7.1184 - val_loss: 4.8937 - val_mse: 4.8937\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.5098 - mse: 5.5098 - val_loss: 5.4758 - val_mse: 5.4758\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2563 - mse: 5.2563 - val_loss: 6.0494 - val_mse: 6.0494\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 5.3066 - mse: 5.3066 - val_loss: 6.0407 - val_mse: 6.0407\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3501 - mse: 5.3501 - val_loss: 5.7084 - val_mse: 5.7084\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3082 - mse: 5.3082 - val_loss: 5.3422 - val_mse: 5.3422\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3033 - mse: 5.3033 - val_loss: 5.1992 - val_mse: 5.1992\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2619 - mse: 5.2619 - val_loss: 5.2102 - val_mse: 5.2102\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2954 - mse: 5.2954 - val_loss: 5.2596 - val_mse: 5.2596\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2714 - mse: 5.2714 - val_loss: 5.2938 - val_mse: 5.2938\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2698 - mse: 5.2698 - val_loss: 5.2251 - val_mse: 5.2251\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2435 - mse: 5.2435 - val_loss: 5.2005 - val_mse: 5.2005\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2502 - mse: 5.2502 - val_loss: 5.2928 - val_mse: 5.2928\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2818 - mse: 5.2818 - val_loss: 5.4211 - val_mse: 5.4211\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2831 - mse: 5.2831 - val_loss: 5.3776 - val_mse: 5.3776\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2502 - mse: 5.2502 - val_loss: 5.2256 - val_mse: 5.2256\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2637 - mse: 5.2637 - val_loss: 5.0974 - val_mse: 5.0974\n",
      "wandb: Agent Finished Run: hkn08b7i \n",
      "\n",
      "wandb: Agent Starting Run: rtm1ezb0 with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: rtm1ezb0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/rtm1ezb0\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/rtm1ezb0</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.0282 - mse: 19.0282 - val_loss: 12.8362 - val_mse: 12.8362\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.7245 - mse: 18.7245 - val_loss: 12.5076 - val_mse: 12.5076\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.2805 - mse: 18.2805 - val_loss: 12.0319 - val_mse: 12.0319\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 17.6340 - mse: 17.6340 - val_loss: 11.3573 - val_mse: 11.3573\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 16.8155 - mse: 16.8155 - val_loss: 10.4817 - val_mse: 10.4817\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 15.7350 - mse: 15.7350 - val_loss: 9.5434 - val_mse: 9.5434\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 14.6413 - mse: 14.6413 - val_loss: 8.7073 - val_mse: 8.7073\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.3604 - mse: 13.3604 - val_loss: 8.0185 - val_mse: 8.0185\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.6078 - mse: 12.6078 - val_loss: 7.4915 - val_mse: 7.4915\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.7451 - mse: 11.7451 - val_loss: 7.0749 - val_mse: 7.0749\n",
      "wandb: Agent Finished Run: rtm1ezb0 \n",
      "\n",
      "wandb: Agent Starting Run: 14mtrdco with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: 14mtrdco\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/14mtrdco\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/14mtrdco</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 19.0982 - mse: 19.0982 - val_loss: 12.6241 - val_mse: 12.6241\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.4042 - mse: 18.4042 - val_loss: 11.6693 - val_mse: 11.6693\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.0524 - mse: 17.0524 - val_loss: 9.7836 - val_mse: 9.7836\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.5548 - mse: 14.5548 - val_loss: 7.4772 - val_mse: 7.4772\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.6573 - mse: 11.6573 - val_loss: 6.0575 - val_mse: 6.0575\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.3784 - mse: 9.3784 - val_loss: 5.3075 - val_mse: 5.3075\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.0251 - mse: 8.0251 - val_loss: 4.9116 - val_mse: 4.9116\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0315 - mse: 7.0315 - val_loss: 4.7799 - val_mse: 4.7799\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3382 - mse: 6.3382 - val_loss: 4.7565 - val_mse: 4.7565\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1167 - mse: 6.1167 - val_loss: 4.7788 - val_mse: 4.7788\n",
      "wandb: Agent Finished Run: 14mtrdco \n",
      "\n",
      "wandb: Agent Starting Run: q536t8z2 with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: q536t8z2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/q536t8z2\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/q536t8z2</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 19.0827 - mse: 19.0827 - val_loss: 12.2512 - val_mse: 12.2512\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 17.8445 - mse: 17.8445 - val_loss: 8.6852 - val_mse: 8.6852\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 12.8672 - mse: 12.8672 - val_loss: 5.0051 - val_mse: 5.0051\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 7.3780 - mse: 7.3780 - val_loss: 4.9135 - val_mse: 4.9135\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.5993 - mse: 5.5993 - val_loss: 5.5384 - val_mse: 5.5384\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2669 - mse: 5.2669 - val_loss: 6.1769 - val_mse: 6.1769\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2689 - mse: 5.2689 - val_loss: 6.1891 - val_mse: 6.1891\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3957 - mse: 5.3957 - val_loss: 5.8228 - val_mse: 5.8228\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3116 - mse: 5.3116 - val_loss: 5.4199 - val_mse: 5.4199\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3553 - mse: 5.3553 - val_loss: 5.2625 - val_mse: 5.2625\n",
      "wandb: Agent Finished Run: q536t8z2 \n",
      "\n",
      "wandb: Agent Starting Run: blhz73dt with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: blhz73dt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/blhz73dt\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/blhz73dt</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0282 - mse: 19.0282 - val_loss: 12.8362 - val_mse: 12.8362\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.7245 - mse: 18.7245 - val_loss: 12.5076 - val_mse: 12.5076\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.2805 - mse: 18.2805 - val_loss: 12.0319 - val_mse: 12.0319\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.6340 - mse: 17.6340 - val_loss: 11.3573 - val_mse: 11.3573\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 16.8155 - mse: 16.8155 - val_loss: 10.4817 - val_mse: 10.4817\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 15.7350 - mse: 15.7350 - val_loss: 9.5434 - val_mse: 9.5434\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 14.6413 - mse: 14.6413 - val_loss: 8.7073 - val_mse: 8.7073\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.3604 - mse: 13.3604 - val_loss: 8.0185 - val_mse: 8.0185\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.6078 - mse: 12.6078 - val_loss: 7.4915 - val_mse: 7.4915\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.7451 - mse: 11.7451 - val_loss: 7.0749 - val_mse: 7.0749\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.1082 - mse: 11.1082 - val_loss: 6.7128 - val_mse: 6.7128\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 10.5520 - mse: 10.5520 - val_loss: 6.4010 - val_mse: 6.4010\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 9.9751 - mse: 9.9751 - val_loss: 6.1374 - val_mse: 6.1374\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 9.5731 - mse: 9.5731 - val_loss: 5.9153 - val_mse: 5.9153\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 9.0690 - mse: 9.0690 - val_loss: 5.7262 - val_mse: 5.7262\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 8.6423 - mse: 8.6423 - val_loss: 5.5625 - val_mse: 5.5625\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 8.3542 - mse: 8.3542 - val_loss: 5.4250 - val_mse: 5.4250\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 8.0374 - mse: 8.0374 - val_loss: 5.3056 - val_mse: 5.3056\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 7.8291 - mse: 7.8291 - val_loss: 5.1956 - val_mse: 5.1956\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 7.5126 - mse: 7.5126 - val_loss: 5.1025 - val_mse: 5.1025\n",
      "wandb: Agent Finished Run: blhz73dt \n",
      "\n",
      "wandb: Agent Starting Run: n0503rp8 with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: n0503rp8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/n0503rp8\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/n0503rp8</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 19.0982 - mse: 19.0982 - val_loss: 12.6241 - val_mse: 12.6241\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.4042 - mse: 18.4042 - val_loss: 11.6693 - val_mse: 11.6693\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.0524 - mse: 17.0524 - val_loss: 9.7836 - val_mse: 9.7836\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.5548 - mse: 14.5548 - val_loss: 7.4772 - val_mse: 7.4772\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.6573 - mse: 11.6573 - val_loss: 6.0575 - val_mse: 6.0575\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.3784 - mse: 9.3784 - val_loss: 5.3075 - val_mse: 5.3075\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.0251 - mse: 8.0251 - val_loss: 4.9116 - val_mse: 4.9116\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0315 - mse: 7.0315 - val_loss: 4.7799 - val_mse: 4.7799\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3382 - mse: 6.3382 - val_loss: 4.7565 - val_mse: 4.7565\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1167 - mse: 6.1167 - val_loss: 4.7788 - val_mse: 4.7788\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.8768 - mse: 5.8768 - val_loss: 4.8576 - val_mse: 4.8576\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.5707 - mse: 5.5707 - val_loss: 4.9929 - val_mse: 4.9929\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.5189 - mse: 5.5189 - val_loss: 5.1432 - val_mse: 5.1432\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.4397 - mse: 5.4397 - val_loss: 5.2701 - val_mse: 5.2701\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2327 - mse: 5.2327 - val_loss: 5.4044 - val_mse: 5.4044\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2819 - mse: 5.2819 - val_loss: 5.5461 - val_mse: 5.5461\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3295 - mse: 5.3295 - val_loss: 5.6516 - val_mse: 5.6516\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2121 - mse: 5.2121 - val_loss: 5.7412 - val_mse: 5.7412\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3190 - mse: 5.3190 - val_loss: 5.8039 - val_mse: 5.8039\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3283 - mse: 5.3283 - val_loss: 5.7809 - val_mse: 5.7809\n",
      "wandb: Agent Finished Run: n0503rp8 \n",
      "\n",
      "wandb: Agent Starting Run: c8t5llzp with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.4\n",
      "wandb: Agent Started Run: c8t5llzp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/c8t5llzp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/c8t5llzp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 19.0827 - mse: 19.0827 - val_loss: 12.3497 - val_mse: 12.3497\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 17.9898 - mse: 17.9898 - val_loss: 9.3698 - val_mse: 9.3698\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 13.8003 - mse: 13.8003 - val_loss: 5.2955 - val_mse: 5.2955\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 8.0565 - mse: 8.0565 - val_loss: 4.8223 - val_mse: 4.8223\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.7776 - mse: 5.7776 - val_loss: 5.4664 - val_mse: 5.4664\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2712 - mse: 5.2712 - val_loss: 6.2315 - val_mse: 6.2315\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2806 - mse: 5.2806 - val_loss: 6.3003 - val_mse: 6.3003\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.4226 - mse: 5.4226 - val_loss: 5.9206 - val_mse: 5.9206\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3236 - mse: 5.3236 - val_loss: 5.4778 - val_mse: 5.4778\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.3543 - mse: 5.3543 - val_loss: 5.2895 - val_mse: 5.2895\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2083 - mse: 5.2083 - val_loss: 5.2818 - val_mse: 5.2818\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2404 - mse: 5.2404 - val_loss: 5.3172 - val_mse: 5.3172\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2853 - mse: 5.2853 - val_loss: 5.3386 - val_mse: 5.3386\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2374 - mse: 5.2374 - val_loss: 5.2533 - val_mse: 5.2533\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2548 - mse: 5.2548 - val_loss: 5.2248 - val_mse: 5.2248\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2698 - mse: 5.2698 - val_loss: 5.3247 - val_mse: 5.3247\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.2366 - mse: 5.2366 - val_loss: 5.4651 - val_mse: 5.4651\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2574 - mse: 5.2574 - val_loss: 5.4255 - val_mse: 5.4255\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.3023 - mse: 5.3023 - val_loss: 5.2649 - val_mse: 5.2649\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 5.2449 - mse: 5.2449 - val_loss: 5.1228 - val_mse: 5.1228\n",
      "wandb: Agent Finished Run: c8t5llzp \n",
      "\n",
      "wandb: Agent Starting Run: u32ibsyg with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: u32ibsyg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/u32ibsyg\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/u32ibsyg</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.0356 - mse: 19.0356 - val_loss: 12.8399 - val_mse: 12.8399\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.7473 - mse: 18.7473 - val_loss: 12.5258 - val_mse: 12.5258\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.3069 - mse: 18.3069 - val_loss: 12.0651 - val_mse: 12.0651\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.7771 - mse: 17.7771 - val_loss: 11.4013 - val_mse: 11.4013\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 16.9169 - mse: 16.9169 - val_loss: 10.5429 - val_mse: 10.5429\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 16.0428 - mse: 16.0428 - val_loss: 9.6297 - val_mse: 9.6297\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 15.2050 - mse: 15.2050 - val_loss: 8.8087 - val_mse: 8.8087\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.9784 - mse: 13.9784 - val_loss: 8.1254 - val_mse: 8.1254\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.9826 - mse: 12.9826 - val_loss: 7.5964 - val_mse: 7.5964\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.3214 - mse: 12.3214 - val_loss: 7.1706 - val_mse: 7.1706\n",
      "wandb: Agent Finished Run: u32ibsyg \n",
      "\n",
      "wandb: Agent Starting Run: 84bcrgb9 with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: 84bcrgb9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/84bcrgb9\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/84bcrgb9</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 19.0917 - mse: 19.0917 - val_loss: 12.7461 - val_mse: 12.7461\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.5804 - mse: 18.5804 - val_loss: 12.0187 - val_mse: 12.0187\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.5235 - mse: 17.5235 - val_loss: 10.4829 - val_mse: 10.4829\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.6268 - mse: 15.6268 - val_loss: 8.1746 - val_mse: 8.1746\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.9408 - mse: 12.9408 - val_loss: 6.4737 - val_mse: 6.4737\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.5055 - mse: 10.5055 - val_loss: 5.5647 - val_mse: 5.5647\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.8697 - mse: 8.8697 - val_loss: 5.0590 - val_mse: 5.0590\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.8780 - mse: 7.8780 - val_loss: 4.8521 - val_mse: 4.8521\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0992 - mse: 7.0992 - val_loss: 4.7808 - val_mse: 4.7808\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.7102 - mse: 6.7102 - val_loss: 4.7566 - val_mse: 4.7566\n",
      "wandb: Agent Finished Run: 84bcrgb9 \n",
      "\n",
      "wandb: Agent Starting Run: ei0pimld with config:\n",
      "\tepochs: 10\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: ei0pimld\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/ei0pimld\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/ei0pimld</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 19.0851 - mse: 19.0851 - val_loss: 12.4791 - val_mse: 12.4791\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 18.1733 - mse: 18.1733 - val_loss: 9.7905 - val_mse: 9.7905\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 14.4426 - mse: 14.4426 - val_loss: 5.5617 - val_mse: 5.5617\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 9.0409 - mse: 9.0409 - val_loss: 4.7751 - val_mse: 4.7751\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.2296 - mse: 6.2296 - val_loss: 5.4367 - val_mse: 5.4367\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3572 - mse: 5.3572 - val_loss: 6.4181 - val_mse: 6.4181\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2618 - mse: 5.2618 - val_loss: 6.7010 - val_mse: 6.7010\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.4772 - mse: 5.4772 - val_loss: 6.3767 - val_mse: 6.3767\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.4935 - mse: 5.4935 - val_loss: 5.8823 - val_mse: 5.8823\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3661 - mse: 5.3661 - val_loss: 5.5926 - val_mse: 5.5926\n",
      "wandb: Agent Finished Run: ei0pimld \n",
      "\n",
      "wandb: Agent Starting Run: jipi6vfl with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 16\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: jipi6vfl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/jipi6vfl\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/jipi6vfl</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 19.0379 - mse: 19.0379 - val_loss: 12.8924 - val_mse: 12.8924\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 18.8116 - mse: 18.8116 - val_loss: 12.6255 - val_mse: 12.6255\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 18.4376 - mse: 18.4376 - val_loss: 12.2291 - val_mse: 12.2291\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 17.9749 - mse: 17.9749 - val_loss: 11.6415 - val_mse: 11.6415\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 17.1997 - mse: 17.1997 - val_loss: 10.8359 - val_mse: 10.8359\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.3650 - mse: 16.3650 - val_loss: 9.9197 - val_mse: 9.9197\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 15.5395 - mse: 15.5395 - val_loss: 9.0503 - val_mse: 9.0503\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 14.2730 - mse: 14.2730 - val_loss: 8.3149 - val_mse: 8.3149\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.2416 - mse: 13.2416 - val_loss: 7.7467 - val_mse: 7.7467\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.5453 - mse: 12.5453 - val_loss: 7.2922 - val_mse: 7.2922\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 11.9131 - mse: 11.9131 - val_loss: 6.8963 - val_mse: 6.8963\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.2277 - mse: 11.2277 - val_loss: 6.5611 - val_mse: 6.5611\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 10.6581 - mse: 10.6581 - val_loss: 6.2803 - val_mse: 6.2803\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 10.1626 - mse: 10.1626 - val_loss: 6.0448 - val_mse: 6.0448\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 9.6905 - mse: 9.6905 - val_loss: 5.8438 - val_mse: 5.8438\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 9.0887 - mse: 9.0887 - val_loss: 5.6694 - val_mse: 5.6694\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 8.7665 - mse: 8.7665 - val_loss: 5.5219 - val_mse: 5.5219\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 8.3983 - mse: 8.3983 - val_loss: 5.3928 - val_mse: 5.3928\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 8.2639 - mse: 8.2639 - val_loss: 5.2736 - val_mse: 5.2736\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 7.7908 - mse: 7.7908 - val_loss: 5.1716 - val_mse: 5.1716\n",
      "wandb: Agent Finished Run: jipi6vfl \n",
      "\n",
      "wandb: Agent Starting Run: rb8p6ciu with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 32\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: rb8p6ciu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/rb8p6ciu\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/rb8p6ciu</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0917 - mse: 19.0917 - val_loss: 12.7065 - val_mse: 12.7065\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.5288 - mse: 18.5288 - val_loss: 11.9498 - val_mse: 11.9498\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.4293 - mse: 17.4293 - val_loss: 10.3539 - val_mse: 10.3539\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.4700 - mse: 15.4700 - val_loss: 8.0424 - val_mse: 8.0424\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.7774 - mse: 12.7774 - val_loss: 6.4040 - val_mse: 6.4040\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.4001 - mse: 10.4001 - val_loss: 5.5272 - val_mse: 5.5272\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.7947 - mse: 8.7947 - val_loss: 5.0389 - val_mse: 5.0389\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.8198 - mse: 7.8198 - val_loss: 4.8422 - val_mse: 4.8422\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0525 - mse: 7.0525 - val_loss: 4.7765 - val_mse: 4.7765\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.6737 - mse: 6.6737 - val_loss: 4.7569 - val_mse: 4.7569\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1742 - mse: 6.1742 - val_loss: 4.7939 - val_mse: 4.7939\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.8127 - mse: 5.8127 - val_loss: 4.8899 - val_mse: 4.8899\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.7131 - mse: 5.7131 - val_loss: 5.0183 - val_mse: 5.0183\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.5170 - mse: 5.5170 - val_loss: 5.1427 - val_mse: 5.1427\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3759 - mse: 5.3759 - val_loss: 5.2811 - val_mse: 5.2811\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3255 - mse: 5.3255 - val_loss: 5.4371 - val_mse: 5.4371\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.3618 - mse: 5.3618 - val_loss: 5.5727 - val_mse: 5.5727\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2202 - mse: 5.2202 - val_loss: 5.6989 - val_mse: 5.6989\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.4209 - mse: 5.4209 - val_loss: 5.7971 - val_mse: 5.7971\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.3183 - mse: 5.3183 - val_loss: 5.8103 - val_mse: 5.8103\n",
      "wandb: Agent Finished Run: rb8p6ciu \n",
      "\n",
      "wandb: Agent Starting Run: 0fs54ju8 with config:\n",
      "\tepochs: 20\n",
      "\tnn_units: 64\n",
      "\tbatch_size: 64\n",
      "\tdout_rate: 0.6\n",
      "wandb: Agent Started Run: 0fs54ju8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gdke1z5v</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/0fs54ju8\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/0fs54ju8</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 19.0756 - mse: 19.0756 - val_loss: 12.2289 - val_mse: 12.2289\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 17.8171 - mse: 17.8171 - val_loss: 8.6254 - val_mse: 8.6254\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 12.9603 - mse: 12.9603 - val_loss: 5.0529 - val_mse: 5.0529\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 7.9685 - mse: 7.9685 - val_loss: 4.8787 - val_mse: 4.8787\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.8664 - mse: 5.8664 - val_loss: 5.6119 - val_mse: 5.6119\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3262 - mse: 5.3262 - val_loss: 6.4385 - val_mse: 6.4385\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2568 - mse: 5.2568 - val_loss: 6.6075 - val_mse: 6.6075\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.4568 - mse: 5.4568 - val_loss: 6.2775 - val_mse: 6.2775\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.4806 - mse: 5.4806 - val_loss: 5.8194 - val_mse: 5.8194\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 5.3615 - mse: 5.3615 - val_loss: 5.5571 - val_mse: 5.5571\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.1725 - mse: 5.1725 - val_loss: 5.4600 - val_mse: 5.4600\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3082 - mse: 5.3082 - val_loss: 5.4132 - val_mse: 5.4132\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3674 - mse: 5.3674 - val_loss: 5.3680 - val_mse: 5.3680\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2088 - mse: 5.2088 - val_loss: 5.2442 - val_mse: 5.2442\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.1779 - mse: 5.1779 - val_loss: 5.1854 - val_mse: 5.1854\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3837 - mse: 5.3837 - val_loss: 5.2457 - val_mse: 5.2457\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2677 - mse: 5.2677 - val_loss: 5.3513 - val_mse: 5.3513\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3383 - mse: 5.3383 - val_loss: 5.3397 - val_mse: 5.3397\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2117 - mse: 5.2117 - val_loss: 5.2389 - val_mse: 5.2389\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2581 - mse: 5.2581 - val_loss: 5.1524 - val_mse: 5.1524\n",
      "wandb: Agent Finished Run: 0fs54ju8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweepid_1, function=train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Better tuning for batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config_2 = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "      'name': 'val_loss',\n",
    "      'goal': 'minimize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "                  'batch_size': {'values': [32, 64, 128, 256]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: adcwqhso\n",
      "Sweep URL: https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso\n"
     ]
    }
   ],
   "source": [
    "sweepid_2 = wandb.sweep(sweep_config_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_2():\n",
    "\n",
    "    config_defaults = {\n",
    "        'batch_size': 32\n",
    "    }\n",
    "    \n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    \n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 32, return_sequences = True, input_shape = (X_train_1.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 32))\n",
    "    model.add(Dense(units = 1, activation='relu'))\n",
    "    \n",
    "    # Complie the model\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_1, y_train, epochs = 10, batch_size = config.batch_size, \n",
    "              validation_split = 0.3, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 47ia3adv with config:\n",
      "\tbatch_size: 32\n",
      "wandb: Agent Started Run: 47ia3adv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/47ia3adv\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/47ia3adv</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 18.9997 - mse: 18.9997 - val_loss: 12.4234 - val_mse: 12.4234\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 17.8105 - mse: 17.8105 - val_loss: 10.3983 - val_mse: 10.3983\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 14.5141 - mse: 14.5141 - val_loss: 7.0726 - val_mse: 7.0726\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 10.1364 - mse: 10.1364 - val_loss: 5.4576 - val_mse: 5.4576\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 7.7814 - mse: 7.7814 - val_loss: 4.8361 - val_mse: 4.8361\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 6.3636 - mse: 6.3636 - val_loss: 4.8026 - val_mse: 4.8026\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.6089 - mse: 5.6089 - val_loss: 5.1644 - val_mse: 5.1644\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.3652 - mse: 5.3652 - val_loss: 5.5641 - val_mse: 5.5641\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 5.1704 - mse: 5.1704 - val_loss: 5.6100 - val_mse: 5.6100\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 5.2261 - mse: 5.2261 - val_loss: 5.6374 - val_mse: 5.6374\n",
      "wandb: Agent Finished Run: 47ia3adv \n",
      "\n",
      "wandb: Agent Starting Run: h9o1qflg with config:\n",
      "\tbatch_size: 64\n",
      "wandb: Agent Started Run: h9o1qflg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/h9o1qflg\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/h9o1qflg</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 19.1038 - mse: 19.1038 - val_loss: 12.6188 - val_mse: 12.6188\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.3851 - mse: 18.3851 - val_loss: 11.6588 - val_mse: 11.6588\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.0117 - mse: 17.0117 - val_loss: 9.7679 - val_mse: 9.7679\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 14.4869 - mse: 14.4869 - val_loss: 7.4541 - val_mse: 7.4541\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 11.4014 - mse: 11.4014 - val_loss: 6.0262 - val_mse: 6.0262\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 9.1076 - mse: 9.1076 - val_loss: 5.2776 - val_mse: 5.2776\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 7.8232 - mse: 7.8232 - val_loss: 4.8881 - val_mse: 4.8881\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 6.7926 - mse: 6.7926 - val_loss: 4.7701 - val_mse: 4.7701\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 6.1718 - mse: 6.1718 - val_loss: 4.7572 - val_mse: 4.7572\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 5.9054 - mse: 5.9054 - val_loss: 4.7886 - val_mse: 4.7886\n",
      "wandb: Agent Finished Run: h9o1qflg \n",
      "\n",
      "wandb: Agent Starting Run: ew9peh06 with config:\n",
      "\tbatch_size: 128\n",
      "wandb: Agent Started Run: ew9peh06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/ew9peh06\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/ew9peh06</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 59ms/step - loss: 19.1111 - mse: 19.1111 - val_loss: 12.9677 - val_mse: 12.9677\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 18.8820 - mse: 18.8820 - val_loss: 12.7030 - val_mse: 12.7030\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 18.5097 - mse: 18.5097 - val_loss: 12.3728 - val_mse: 12.3728\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 18.0730 - mse: 18.0730 - val_loss: 11.8799 - val_mse: 11.8799\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 17.4223 - mse: 17.4223 - val_loss: 11.1554 - val_mse: 11.1554\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 16.4221 - mse: 16.4221 - val_loss: 10.1599 - val_mse: 10.1599\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 15.1384 - mse: 15.1384 - val_loss: 8.9610 - val_mse: 8.9610\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 13.4743 - mse: 13.4743 - val_loss: 7.7877 - val_mse: 7.7877\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 11.8047 - mse: 11.8047 - val_loss: 6.8522 - val_mse: 6.8522\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 10.4728 - mse: 10.4728 - val_loss: 6.1815 - val_mse: 6.1815\n",
      "wandb: Agent Finished Run: ew9peh06 \n",
      "\n",
      "wandb: Agent Starting Run: 5m7qzdrx with config:\n",
      "\tbatch_size: 256\n",
      "wandb: Agent Started Run: 5m7qzdrx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/adcwqhso</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/5m7qzdrx\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/5m7qzdrx</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 59ms/step - loss: 19.1111 - mse: 19.1111 - val_loss: 12.9677 - val_mse: 12.9677\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 18.8820 - mse: 18.8820 - val_loss: 12.7030 - val_mse: 12.7030\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 18.5097 - mse: 18.5097 - val_loss: 12.3728 - val_mse: 12.3728\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 18.0730 - mse: 18.0730 - val_loss: 11.8799 - val_mse: 11.8799\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 17.4223 - mse: 17.4223 - val_loss: 11.1554 - val_mse: 11.1554\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 16.4221 - mse: 16.4221 - val_loss: 10.1599 - val_mse: 10.1599\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 15.1384 - mse: 15.1384 - val_loss: 8.9610 - val_mse: 8.9610\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 13.4743 - mse: 13.4743 - val_loss: 7.7877 - val_mse: 7.7877\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 11.8047 - mse: 11.8047 - val_loss: 6.8453 - val_mse: 6.8453\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 10.4624 - mse: 10.4624 - val_loss: 6.1768 - val_mse: 6.1768\n",
      "wandb: Agent Finished Run: 5m7qzdrx \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweepid_2, function=train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best value for batch_size: 64**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Better tuning for nn_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config_3 = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "      'name': 'val_loss',\n",
    "      'goal': 'minimize'   \n",
    "    },\n",
    "    'parameters': {'nn_units_1': {'values': [8, 16, 32, 64]},\n",
    "                   'nn_units_2': {'values': [8, 16, 32, 64]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: tiykxtm3\n",
      "Sweep URL: https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\n"
     ]
    }
   ],
   "source": [
    "sweepid_3 = wandb.sweep(sweep_config_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_3():\n",
    "\n",
    "    config_defaults = {\n",
    "        'nn_units_1': 8,\n",
    "        'nn_units_2': 8\n",
    "    }\n",
    "    \n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    \n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = config.nn_units_1, return_sequences = True, input_shape = (X_train_1.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = config.nn_units_2, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = config.nn_units_2, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = config.nn_units_2, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = config.nn_units_2, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = config.nn_units_2, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = config.nn_units_2))\n",
    "    model.add(Dense(units = 1, activation='relu'))\n",
    "    \n",
    "    # Complie the model\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_1, y_train, epochs = 10, batch_size = 64, \n",
    "              validation_split = 0.3, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: mayn96ye with config:\n",
      "\tnn_units_2: 8\n",
      "\tnn_units_1: 8\n",
      "wandb: Agent Started Run: mayn96ye\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/mayn96ye\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/mayn96ye</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.1181 - mse: 19.1181 - val_loss: 13.0363 - val_mse: 13.0363\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.9880 - mse: 18.9880 - val_loss: 12.9123 - val_mse: 12.9123\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.8161 - mse: 18.8161 - val_loss: 12.7584 - val_mse: 12.7584\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.6403 - mse: 18.6403 - val_loss: 12.5659 - val_mse: 12.5659\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.3978 - mse: 18.3978 - val_loss: 12.3255 - val_mse: 12.3255\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 18.0414 - mse: 18.0414 - val_loss: 12.0277 - val_mse: 12.0277\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 17.6663 - mse: 17.6663 - val_loss: 11.6656 - val_mse: 11.6656\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 17.1959 - mse: 17.1959 - val_loss: 11.2452 - val_mse: 11.2452\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 16.6112 - mse: 16.6112 - val_loss: 10.7980 - val_mse: 10.7980\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 16.0469 - mse: 16.0469 - val_loss: 10.3693 - val_mse: 10.3693\n",
      "wandb: Agent Finished Run: mayn96ye \n",
      "\n",
      "wandb: Agent Starting Run: onjgrhld with config:\n",
      "\tnn_units_2: 16\n",
      "\tnn_units_1: 8\n",
      "wandb: Agent Started Run: onjgrhld\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/onjgrhld\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/onjgrhld</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "wandb: Agent Finished Run: onjgrhld \n",
      "\n",
      "wandb: Agent Starting Run: koahqic6 with config:\n",
      "\tnn_units_2: 32\n",
      "\tnn_units_1: 8\n",
      "wandb: Agent Started Run: koahqic6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/koahqic6\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/koahqic6</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.1032 - mse: 19.1032 - val_loss: 12.6833 - val_mse: 12.6833\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.4752 - mse: 18.4752 - val_loss: 11.8296 - val_mse: 11.8296\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 17.3293 - mse: 17.3293 - val_loss: 10.1048 - val_mse: 10.1048\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 14.9397 - mse: 14.9397 - val_loss: 7.9317 - val_mse: 7.9317\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.9675 - mse: 11.9675 - val_loss: 6.3133 - val_mse: 6.3133\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 9.6369 - mse: 9.6369 - val_loss: 5.4334 - val_mse: 5.4334\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 8.1522 - mse: 8.1522 - val_loss: 5.0037 - val_mse: 5.0037\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 7.0206 - mse: 7.0206 - val_loss: 4.8032 - val_mse: 4.8032\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.4079 - mse: 6.4079 - val_loss: 4.7579 - val_mse: 4.7579\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.8805 - mse: 5.8805 - val_loss: 4.8143 - val_mse: 4.8143\n",
      "wandb: Agent Finished Run: koahqic6 \n",
      "\n",
      "wandb: Agent Starting Run: zeagheum with config:\n",
      "\tnn_units_2: 64\n",
      "\tnn_units_1: 8\n",
      "wandb: Agent Started Run: zeagheum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/zeagheum\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/zeagheum</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 19.1087 - mse: 19.1087 - val_loss: 12.6968 - val_mse: 12.6968\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 18.4926 - mse: 18.4926 - val_loss: 11.1463 - val_mse: 11.1463\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 16.3378 - mse: 16.3378 - val_loss: 6.8999 - val_mse: 6.8999\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 10.0554 - mse: 10.0554 - val_loss: 4.7920 - val_mse: 4.7920\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.7494 - mse: 5.7494 - val_loss: 5.8824 - val_mse: 5.8824\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.1707 - mse: 5.1707 - val_loss: 7.4977 - val_mse: 7.4977\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.8642 - mse: 5.8642 - val_loss: 8.7362 - val_mse: 8.7362\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 6.5373 - mse: 6.5373 - val_loss: 8.8703 - val_mse: 8.8703\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 6.6095 - mse: 6.6095 - val_loss: 8.0963 - val_mse: 8.0963\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 6.1852 - mse: 6.1852 - val_loss: 7.0770 - val_mse: 7.0770\n",
      "wandb: Agent Finished Run: zeagheum \n",
      "\n",
      "wandb: Agent Starting Run: q7brsfu7 with config:\n",
      "\tnn_units_2: 8\n",
      "\tnn_units_1: 16\n",
      "wandb: Agent Started Run: q7brsfu7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/q7brsfu7\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/q7brsfu7</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.1146 - mse: 19.1146 - val_loss: 12.9888 - val_mse: 12.9888\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.9216 - mse: 18.9216 - val_loss: 12.8264 - val_mse: 12.8264\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.6992 - mse: 18.6992 - val_loss: 12.6413 - val_mse: 12.6413\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.4460 - mse: 18.4460 - val_loss: 12.4167 - val_mse: 12.4167\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.1586 - mse: 18.1586 - val_loss: 12.1391 - val_mse: 12.1391\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 17.7749 - mse: 17.7750 - val_loss: 11.8034 - val_mse: 11.8034\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 17.3244 - mse: 17.3244 - val_loss: 11.4087 - val_mse: 11.4087\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 16.8629 - mse: 16.8629 - val_loss: 10.9489 - val_mse: 10.9489\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 16.2275 - mse: 16.2275 - val_loss: 10.4322 - val_mse: 10.4322\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 15.5487 - mse: 15.5487 - val_loss: 9.8825 - val_mse: 9.8825\n",
      "wandb: Agent Finished Run: q7brsfu7 \n",
      "\n",
      "wandb: Agent Starting Run: 4w2o7vxx with config:\n",
      "\tnn_units_2: 16\n",
      "\tnn_units_1: 16\n",
      "wandb: Agent Started Run: 4w2o7vxx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/4w2o7vxx\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/4w2o7vxx</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.0289 - mse: 19.0289 - val_loss: 12.8846 - val_mse: 12.8846\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.7735 - mse: 18.7735 - val_loss: 12.5885 - val_mse: 12.5885\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.3740 - mse: 18.3740 - val_loss: 12.1427 - val_mse: 12.1427\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.7864 - mse: 17.7864 - val_loss: 11.4929 - val_mse: 11.4929\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 16.9694 - mse: 16.9694 - val_loss: 10.6234 - val_mse: 10.6234\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 15.7761 - mse: 15.7761 - val_loss: 9.6603 - val_mse: 9.6603\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 14.5641 - mse: 14.5641 - val_loss: 8.7841 - val_mse: 8.7841\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.3431 - mse: 13.3431 - val_loss: 8.0581 - val_mse: 8.0581\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.4303 - mse: 12.4303 - val_loss: 7.5048 - val_mse: 7.5048\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.5499 - mse: 11.5499 - val_loss: 7.0682 - val_mse: 7.0682\n",
      "wandb: Agent Finished Run: 4w2o7vxx \n",
      "\n",
      "wandb: Agent Starting Run: p2iqs0rs with config:\n",
      "\tnn_units_2: 32\n",
      "\tnn_units_1: 16\n",
      "wandb: Agent Started Run: p2iqs0rs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/p2iqs0rs\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/p2iqs0rs</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.1089 - mse: 19.1089 - val_loss: 12.8112 - val_mse: 12.8112\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.6721 - mse: 18.6721 - val_loss: 12.1562 - val_mse: 12.1562\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.7634 - mse: 17.7634 - val_loss: 10.8636 - val_mse: 10.8636\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.0560 - mse: 16.0560 - val_loss: 8.6944 - val_mse: 8.6944\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 13.1456 - mse: 13.1456 - val_loss: 6.7190 - val_mse: 6.7190\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 10.2198 - mse: 10.2198 - val_loss: 5.5584 - val_mse: 5.5584\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 8.3604 - mse: 8.3604 - val_loss: 4.9865 - val_mse: 4.9865\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.9979 - mse: 6.9979 - val_loss: 4.7703 - val_mse: 4.7703\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.1710 - mse: 6.1710 - val_loss: 4.7953 - val_mse: 4.7953\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.7292 - mse: 5.7292 - val_loss: 4.9747 - val_mse: 4.9747\n",
      "wandb: Agent Finished Run: p2iqs0rs \n",
      "\n",
      "wandb: Agent Starting Run: n5m232wy with config:\n",
      "\tnn_units_2: 64\n",
      "\tnn_units_1: 16\n",
      "wandb: Agent Started Run: n5m232wy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/n5m232wy\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/n5m232wy</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 19.1027 - mse: 19.1027 - val_loss: 12.3537 - val_mse: 12.3537\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 17.9758 - mse: 17.9758 - val_loss: 9.7686 - val_mse: 9.7686\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 14.3457 - mse: 14.3457 - val_loss: 5.3071 - val_mse: 5.3071\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 7.6236 - mse: 7.6237 - val_loss: 4.9031 - val_mse: 4.9031\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3851 - mse: 5.3851 - val_loss: 5.9529 - val_mse: 5.9529\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.2204 - mse: 5.2204 - val_loss: 7.3964 - val_mse: 7.3964\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.8455 - mse: 5.8455 - val_loss: 8.4922 - val_mse: 8.4922\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 6.3655 - mse: 6.3655 - val_loss: 8.6343 - val_mse: 8.6343\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 6.5199 - mse: 6.5199 - val_loss: 8.1129 - val_mse: 8.1129\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 6.1760 - mse: 6.1760 - val_loss: 7.2722 - val_mse: 7.2722\n",
      "wandb: Agent Finished Run: n5m232wy \n",
      "\n",
      "wandb: Agent Starting Run: ln2cwigz with config:\n",
      "\tnn_units_2: 8\n",
      "\tnn_units_1: 32\n",
      "wandb: Agent Started Run: ln2cwigz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/ln2cwigz\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/ln2cwigz</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 19.0905 - mse: 19.0905 - val_loss: 12.9756 - val_mse: 12.9756\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 18.8997 - mse: 18.8997 - val_loss: 12.8053 - val_mse: 12.8053\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 18.6700 - mse: 18.6700 - val_loss: 12.5980 - val_mse: 12.5980\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 18.3876 - mse: 18.3876 - val_loss: 12.3359 - val_mse: 12.3359\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 18.0625 - mse: 18.0625 - val_loss: 12.0031 - val_mse: 12.0031\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 17.6171 - mse: 17.6171 - val_loss: 11.5800 - val_mse: 11.5800\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 17.0130 - mse: 17.0130 - val_loss: 11.0549 - val_mse: 11.0549\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 16.3386 - mse: 16.3386 - val_loss: 10.4598 - val_mse: 10.4598\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 15.6102 - mse: 15.6102 - val_loss: 9.8626 - val_mse: 9.8626\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 14.8891 - mse: 14.8891 - val_loss: 9.3045 - val_mse: 9.3045\n",
      "wandb: Agent Finished Run: ln2cwigz \n",
      "\n",
      "wandb: Agent Starting Run: 6pcn0w3n with config:\n",
      "\tnn_units_2: 16\n",
      "\tnn_units_1: 32\n",
      "wandb: Agent Started Run: 6pcn0w3n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/6pcn0w3n\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/6pcn0w3n</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.1119 - mse: 19.1119 - val_loss: 12.8890 - val_mse: 12.8890\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.7817 - mse: 18.7817 - val_loss: 12.5128 - val_mse: 12.5128\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 18.2785 - mse: 18.2785 - val_loss: 11.8916 - val_mse: 11.8916\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 17.4092 - mse: 17.4092 - val_loss: 10.9978 - val_mse: 10.9978\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 16.2569 - mse: 16.2569 - val_loss: 9.9845 - val_mse: 9.9845\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 14.9371 - mse: 14.9371 - val_loss: 9.1190 - val_mse: 9.1190\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.8038 - mse: 13.8038 - val_loss: 8.4571 - val_mse: 8.4571\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.8747 - mse: 12.8747 - val_loss: 7.9383 - val_mse: 7.9383\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.2496 - mse: 12.2496 - val_loss: 7.4998 - val_mse: 7.4998\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.4531 - mse: 11.4531 - val_loss: 7.1036 - val_mse: 7.1036\n",
      "wandb: Agent Finished Run: 6pcn0w3n \n",
      "\n",
      "wandb: Agent Starting Run: j60k3eon with config:\n",
      "\tnn_units_2: 32\n",
      "\tnn_units_1: 32\n",
      "wandb: Agent Started Run: j60k3eon\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/j60k3eon\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/j60k3eon</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.1057 - mse: 19.1057 - val_loss: 12.6957 - val_mse: 12.6957\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.4937 - mse: 18.4937 - val_loss: 11.9027 - val_mse: 11.9027\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.3558 - mse: 17.3558 - val_loss: 10.2680 - val_mse: 10.2680\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 15.1574 - mse: 15.1574 - val_loss: 7.9161 - val_mse: 7.9161\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 12.0496 - mse: 12.0496 - val_loss: 6.2619 - val_mse: 6.2619\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.4976 - mse: 9.4976 - val_loss: 5.4031 - val_mse: 5.4031\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.0860 - mse: 8.0860 - val_loss: 4.9470 - val_mse: 4.9470\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.9789 - mse: 6.9789 - val_loss: 4.7898 - val_mse: 4.7898\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3069 - mse: 6.3069 - val_loss: 4.7575 - val_mse: 4.7575\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.0056 - mse: 6.0056 - val_loss: 4.7737 - val_mse: 4.7737\n",
      "wandb: Agent Finished Run: j60k3eon \n",
      "\n",
      "wandb: Agent Starting Run: mulhbyq0 with config:\n",
      "\tnn_units_2: 64\n",
      "\tnn_units_1: 32\n",
      "wandb: Agent Started Run: mulhbyq0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/mulhbyq0\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/mulhbyq0</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 19.0968 - mse: 19.0968 - val_loss: 11.9938 - val_mse: 11.9938\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 17.4778 - mse: 17.4778 - val_loss: 8.4013 - val_mse: 8.4013\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 12.3815 - mse: 12.3815 - val_loss: 4.9999 - val_mse: 4.9999\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.9956 - mse: 6.9956 - val_loss: 5.0943 - val_mse: 5.0943\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.2324 - mse: 5.2324 - val_loss: 6.5864 - val_mse: 6.5864\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.4744 - mse: 5.4744 - val_loss: 7.7597 - val_mse: 7.7597\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 6.0732 - mse: 6.0732 - val_loss: 7.5821 - val_mse: 7.5821\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.8771 - mse: 5.8771 - val_loss: 6.7412 - val_mse: 6.7412\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.4835 - mse: 5.4835 - val_loss: 5.9101 - val_mse: 5.9101\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.2251 - mse: 5.2251 - val_loss: 5.2697 - val_mse: 5.2697\n",
      "wandb: Agent Finished Run: mulhbyq0 \n",
      "\n",
      "wandb: Agent Starting Run: 6e2ecq8s with config:\n",
      "\tnn_units_2: 8\n",
      "\tnn_units_1: 64\n",
      "wandb: Agent Started Run: 6e2ecq8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/6e2ecq8s\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/6e2ecq8s</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 19.1236 - mse: 19.1236 - val_loss: 13.1431 - val_mse: 13.1431\n",
      "wandb: Agent Finished Run: 6e2ecq8s \n",
      "\n",
      "wandb: Agent Starting Run: lvgk69hm with config:\n",
      "\tnn_units_2: 16\n",
      "\tnn_units_1: 64\n",
      "wandb: Agent Started Run: lvgk69hm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/lvgk69hm\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/lvgk69hm</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0772 - mse: 19.0772 - val_loss: 12.8383 - val_mse: 12.8383\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.6941 - mse: 18.6941 - val_loss: 12.4282 - val_mse: 12.4282\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.1825 - mse: 18.1825 - val_loss: 11.8817 - val_mse: 11.8817\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.4037 - mse: 17.4037 - val_loss: 11.2310 - val_mse: 11.2310\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.6279 - mse: 16.6279 - val_loss: 10.4993 - val_mse: 10.4993\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 15.6872 - mse: 15.6872 - val_loss: 9.7325 - val_mse: 9.7325\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 14.6823 - mse: 14.6823 - val_loss: 8.9685 - val_mse: 8.9685\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 13.6535 - mse: 13.6535 - val_loss: 8.2445 - val_mse: 8.2445\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.6242 - mse: 12.6242 - val_loss: 7.5956 - val_mse: 7.5956\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.6790 - mse: 11.6790 - val_loss: 7.0275 - val_mse: 7.0275\n",
      "wandb: Agent Finished Run: lvgk69hm \n",
      "\n",
      "wandb: Agent Starting Run: 646r1ipm with config:\n",
      "\tnn_units_2: 32\n",
      "\tnn_units_1: 64\n",
      "wandb: Agent Started Run: 646r1ipm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/646r1ipm\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/646r1ipm</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.1120 - mse: 19.1120 - val_loss: 12.8444 - val_mse: 12.8444\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.7197 - mse: 18.7197 - val_loss: 12.2504 - val_mse: 12.2504\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.9164 - mse: 17.9164 - val_loss: 10.9915 - val_mse: 10.9915\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 16.2063 - mse: 16.2063 - val_loss: 8.9869 - val_mse: 8.9869\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 13.5451 - mse: 13.5451 - val_loss: 7.1338 - val_mse: 7.1338\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 10.8614 - mse: 10.8614 - val_loss: 5.9254 - val_mse: 5.9254\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 8.9825 - mse: 8.9825 - val_loss: 5.2083 - val_mse: 5.2083\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 7.6346 - mse: 7.6346 - val_loss: 4.8744 - val_mse: 4.8744\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 6.6987 - mse: 6.6987 - val_loss: 4.7610 - val_mse: 4.7610\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 6.1241 - mse: 6.1241 - val_loss: 4.7950 - val_mse: 4.7950\n",
      "wandb: Agent Finished Run: 646r1ipm \n",
      "\n",
      "wandb: Agent Starting Run: zopazeg9 with config:\n",
      "\tnn_units_2: 64\n",
      "\tnn_units_1: 64\n",
      "wandb: Agent Started Run: zopazeg9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/tiykxtm3</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/zopazeg9\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/zopazeg9</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 67ms/step - loss: 19.0842 - mse: 19.0842 - val_loss: 12.2539 - val_mse: 12.2539\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 17.8438 - mse: 17.8438 - val_loss: 8.6433 - val_mse: 8.6433\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 12.7075 - mse: 12.7075 - val_loss: 5.0112 - val_mse: 5.0112\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 7.1184 - mse: 7.1184 - val_loss: 4.8937 - val_mse: 4.8937\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.5098 - mse: 5.5098 - val_loss: 5.4758 - val_mse: 5.4758\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.2563 - mse: 5.2563 - val_loss: 6.0494 - val_mse: 6.0494\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3066 - mse: 5.3066 - val_loss: 6.0407 - val_mse: 6.0407\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3501 - mse: 5.3501 - val_loss: 5.7084 - val_mse: 5.7084\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3082 - mse: 5.3082 - val_loss: 5.3422 - val_mse: 5.3422\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 5.3033 - mse: 5.3033 - val_loss: 5.1992 - val_mse: 5.1992\n",
      "wandb: Agent Finished Run: zopazeg9 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweepid_3, function=train_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best values for nn_units_1 and nn_units_2: (32, 32)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Better tuning for dout_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config_4 = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "      'name': 'val_loss',\n",
    "      'goal': 'minimize'   \n",
    "    },\n",
    "    'parameters': {'dout_rate_1': {'values': [0.0, 0.1, 0.2, 0.4, 0.6]},\n",
    "                   'dout_rate_2': {'values': [0.0, 0.1, 0.2, 0.4, 0.6]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: gtjs5xcp\n",
      "Sweep URL: https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\n"
     ]
    }
   ],
   "source": [
    "sweepid_4 = wandb.sweep(sweep_config_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_4():\n",
    "\n",
    "    config_defaults = {\n",
    "        'dout_rate_1': 0.0,\n",
    "        'dout_rate_2': 0.0\n",
    "    }\n",
    "    \n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    \n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 32, return_sequences = True, input_shape = (X_train_1.shape[1], 1)))\n",
    "    model.add(Dropout(config.dout_rate_1))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate_2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate_2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate_2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate_2))\n",
    "    model.add(LSTM(units = 32, return_sequences = True))\n",
    "    model.add(Dropout(config.dout_rate_2))\n",
    "    model.add(LSTM(units = 32))\n",
    "    model.add(Dense(units = 1, activation='relu'))\n",
    "    \n",
    "    # Complie the model\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_1, y_train, epochs = 10, batch_size = 64, \n",
    "              validation_split = 0.3, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 6gerai06 with config:\n",
      "\tdout_rate_2: 0\n",
      "\tdout_rate_1: 0\n",
      "wandb: Agent Started Run: 6gerai06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/6gerai06\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/6gerai06</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 61ms/step - loss: 19.1062 - mse: 19.1062 - val_loss: 12.7029 - val_mse: 12.7029\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.5033 - mse: 18.5033 - val_loss: 11.7845 - val_mse: 11.7845\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.2570 - mse: 17.2570 - val_loss: 10.0311 - val_mse: 10.0311\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.8423 - mse: 14.8423 - val_loss: 7.9417 - val_mse: 7.9417\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.9491 - mse: 11.9491 - val_loss: 6.3163 - val_mse: 6.3163\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.4383 - mse: 9.4383 - val_loss: 5.2641 - val_mse: 5.2641\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.5702 - mse: 7.5702 - val_loss: 4.7979 - val_mse: 4.7979\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3205 - mse: 6.3205 - val_loss: 4.7904 - val_mse: 4.7904\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.6291 - mse: 5.6291 - val_loss: 4.9814 - val_mse: 4.9814\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.3585 - mse: 5.3585 - val_loss: 5.3184 - val_mse: 5.3184\n",
      "wandb: Agent Finished Run: 6gerai06 \n",
      "\n",
      "wandb: Agent Starting Run: s1mpnya9 with config:\n",
      "\tdout_rate_2: 0.1\n",
      "\tdout_rate_1: 0\n",
      "wandb: Agent Started Run: s1mpnya9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/s1mpnya9\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/s1mpnya9</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0994 - mse: 19.0994 - val_loss: 12.5167 - val_mse: 12.5167\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.2353 - mse: 18.2353 - val_loss: 11.3143 - val_mse: 11.3143\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 16.5572 - mse: 16.5572 - val_loss: 9.2954 - val_mse: 9.2954\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 13.7895 - mse: 13.7895 - val_loss: 7.1106 - val_mse: 7.1106\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.7949 - mse: 10.7949 - val_loss: 5.8634 - val_mse: 5.8634\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.8307 - mse: 8.8307 - val_loss: 5.2231 - val_mse: 5.2231\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.5892 - mse: 7.5892 - val_loss: 4.9038 - val_mse: 4.9038\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.7267 - mse: 6.7267 - val_loss: 4.7680 - val_mse: 4.7680\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1590 - mse: 6.1590 - val_loss: 4.7900 - val_mse: 4.7900\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.6392 - mse: 5.6392 - val_loss: 4.9676 - val_mse: 4.9676\n",
      "wandb: Agent Finished Run: s1mpnya9 \n",
      "\n",
      "wandb: Agent Starting Run: rldo1d6c with config:\n",
      "\tdout_rate_2: 0.2\n",
      "\tdout_rate_1: 0\n",
      "wandb: Agent Started Run: rldo1d6c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/rldo1d6c\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/rldo1d6c</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.0939 - mse: 19.0939 - val_loss: 12.4118 - val_mse: 12.4118\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.1062 - mse: 18.1062 - val_loss: 10.9949 - val_mse: 10.9949\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.1555 - mse: 16.1555 - val_loss: 8.7850 - val_mse: 8.7850\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 13.1269 - mse: 13.1269 - val_loss: 6.7136 - val_mse: 6.7136\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.2490 - mse: 10.2490 - val_loss: 5.6381 - val_mse: 5.6381\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.5183 - mse: 8.5183 - val_loss: 5.1103 - val_mse: 5.1103\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.3703 - mse: 7.3703 - val_loss: 4.8591 - val_mse: 4.8591\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.6416 - mse: 6.6416 - val_loss: 4.7611 - val_mse: 4.7611\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 6.1529 - mse: 6.1529 - val_loss: 4.7971 - val_mse: 4.7971\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.6136 - mse: 5.6136 - val_loss: 4.9694 - val_mse: 4.9694\n",
      "wandb: Agent Finished Run: rldo1d6c \n",
      "\n",
      "wandb: Agent Starting Run: f2cbtrq4 with config:\n",
      "\tdout_rate_2: 0.4\n",
      "\tdout_rate_1: 0\n",
      "wandb: Agent Started Run: f2cbtrq4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/f2cbtrq4\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/f2cbtrq4</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0918 - mse: 19.0918 - val_loss: 12.4210 - val_mse: 12.4210\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.1251 - mse: 18.1251 - val_loss: 11.0214 - val_mse: 11.0214\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.2030 - mse: 16.2030 - val_loss: 8.7983 - val_mse: 8.7983\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 13.2305 - mse: 13.2305 - val_loss: 6.7104 - val_mse: 6.7104\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.4429 - mse: 10.4429 - val_loss: 5.6294 - val_mse: 5.6294\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.6758 - mse: 8.6758 - val_loss: 5.1027 - val_mse: 5.1027\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.5502 - mse: 7.5502 - val_loss: 4.8547 - val_mse: 4.8547\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.7758 - mse: 6.7758 - val_loss: 4.7602 - val_mse: 4.7602\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.2390 - mse: 6.2390 - val_loss: 4.7983 - val_mse: 4.7983\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.7697 - mse: 5.7697 - val_loss: 4.9619 - val_mse: 4.9619\n",
      "wandb: Agent Finished Run: f2cbtrq4 \n",
      "\n",
      "wandb: Agent Starting Run: ktac6pzi with config:\n",
      "\tdout_rate_2: 0.6\n",
      "\tdout_rate_1: 0\n",
      "wandb: Agent Started Run: ktac6pzi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/ktac6pzi\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/ktac6pzi</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0820 - mse: 19.0820 - val_loss: 12.4069 - val_mse: 12.4069\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.1086 - mse: 18.1086 - val_loss: 11.0095 - val_mse: 11.0095\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.2644 - mse: 16.2644 - val_loss: 8.7847 - val_mse: 8.7847\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 13.5419 - mse: 13.5419 - val_loss: 6.7075 - val_mse: 6.7075\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.8960 - mse: 10.8960 - val_loss: 5.6313 - val_mse: 5.6313\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.1939 - mse: 9.1939 - val_loss: 5.1006 - val_mse: 5.1006\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.9351 - mse: 7.9351 - val_loss: 4.8494 - val_mse: 4.8494\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.1795 - mse: 7.1795 - val_loss: 4.7590 - val_mse: 4.7590\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.4501 - mse: 6.4501 - val_loss: 4.8030 - val_mse: 4.8030\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.9200 - mse: 5.9200 - val_loss: 4.9723 - val_mse: 4.9723\n",
      "wandb: Agent Finished Run: ktac6pzi \n",
      "\n",
      "wandb: Agent Starting Run: q3n9jo7t with config:\n",
      "\tdout_rate_2: 0\n",
      "\tdout_rate_1: 0.1\n",
      "wandb: Agent Started Run: q3n9jo7t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/q3n9jo7t\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/q3n9jo7t</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 62ms/step - loss: 19.0481 - mse: 19.0481 - val_loss: 12.6303 - val_mse: 12.6303\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.3881 - mse: 18.3881 - val_loss: 11.7003 - val_mse: 11.7003\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.1100 - mse: 17.1100 - val_loss: 9.9029 - val_mse: 9.9029\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.6115 - mse: 14.6115 - val_loss: 7.4680 - val_mse: 7.4680\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.2661 - mse: 11.2661 - val_loss: 5.7686 - val_mse: 5.7686\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.5217 - mse: 8.5217 - val_loss: 4.9511 - val_mse: 4.9511\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.8081 - mse: 6.8081 - val_loss: 4.7652 - val_mse: 4.7652\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.7878 - mse: 5.7878 - val_loss: 5.0439 - val_mse: 5.0439\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2904 - mse: 5.2904 - val_loss: 5.6036 - val_mse: 5.6036\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2281 - mse: 5.2281 - val_loss: 6.3765 - val_mse: 6.3765\n",
      "wandb: Agent Finished Run: q3n9jo7t \n",
      "\n",
      "wandb: Agent Starting Run: vklxxi30 with config:\n",
      "\tdout_rate_2: 0.1\n",
      "\tdout_rate_1: 0.1\n",
      "wandb: Agent Started Run: vklxxi30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/vklxxi30\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/vklxxi30</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.1068 - mse: 19.1068 - val_loss: 12.6195 - val_mse: 12.6195\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.3769 - mse: 18.3769 - val_loss: 11.6564 - val_mse: 11.6564\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.0238 - mse: 17.0238 - val_loss: 9.7536 - val_mse: 9.7536\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.4129 - mse: 14.4129 - val_loss: 7.4332 - val_mse: 7.4332\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.2509 - mse: 11.2509 - val_loss: 6.0053 - val_mse: 6.0053\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.9935 - mse: 8.9935 - val_loss: 5.2606 - val_mse: 5.2606\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.6387 - mse: 7.6387 - val_loss: 4.8769 - val_mse: 4.8769\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.6905 - mse: 6.6905 - val_loss: 4.7668 - val_mse: 4.7668\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.1340 - mse: 6.1340 - val_loss: 4.7576 - val_mse: 4.7576\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.8682 - mse: 5.8682 - val_loss: 4.7881 - val_mse: 4.7881\n",
      "wandb: Agent Finished Run: vklxxi30 \n",
      "\n",
      "wandb: Agent Starting Run: c6tkpvvg with config:\n",
      "\tdout_rate_2: 0.2\n",
      "\tdout_rate_1: 0.1\n",
      "wandb: Agent Started Run: c6tkpvvg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/c6tkpvvg\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/c6tkpvvg</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 19.1058 - mse: 19.1058 - val_loss: 12.7380 - val_mse: 12.7380\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.5501 - mse: 18.5501 - val_loss: 11.9765 - val_mse: 11.9765\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.4692 - mse: 17.4692 - val_loss: 10.3690 - val_mse: 10.3690\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 15.2967 - mse: 15.2967 - val_loss: 8.0210 - val_mse: 8.0210\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.1996 - mse: 12.1996 - val_loss: 6.3211 - val_mse: 6.3211\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 9.5929 - mse: 9.5929 - val_loss: 5.4373 - val_mse: 5.4373\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.1548 - mse: 8.1548 - val_loss: 4.9647 - val_mse: 4.9647\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0308 - mse: 7.0308 - val_loss: 4.7969 - val_mse: 4.7969\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3455 - mse: 6.3455 - val_loss: 4.7588 - val_mse: 4.7588\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.0353 - mse: 6.0353 - val_loss: 4.7705 - val_mse: 4.7705\n",
      "wandb: Agent Finished Run: c6tkpvvg \n",
      "\n",
      "wandb: Agent Starting Run: 0kmdlrze with config:\n",
      "\tdout_rate_2: 0.4\n",
      "\tdout_rate_1: 0.1\n",
      "wandb: Agent Started Run: 0kmdlrze\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/0kmdlrze\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/0kmdlrze</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 19.0983 - mse: 19.0983 - val_loss: 12.6226 - val_mse: 12.6226\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 18.4034 - mse: 18.4034 - val_loss: 11.6656 - val_mse: 11.6656\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 17.0513 - mse: 17.0513 - val_loss: 9.7749 - val_mse: 9.7749\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 14.5403 - mse: 14.5403 - val_loss: 7.4710 - val_mse: 7.4710\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 11.6512 - mse: 11.6512 - val_loss: 6.0596 - val_mse: 6.0596\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.3768 - mse: 9.3768 - val_loss: 5.3123 - val_mse: 5.3123\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.0325 - mse: 8.0325 - val_loss: 4.9150 - val_mse: 4.9150\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0403 - mse: 7.0403 - val_loss: 4.7814 - val_mse: 4.7814\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3467 - mse: 6.3467 - val_loss: 4.7566 - val_mse: 4.7566\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1257 - mse: 6.1257 - val_loss: 4.7772 - val_mse: 4.7772\n",
      "wandb: Agent Finished Run: 0kmdlrze \n",
      "\n",
      "wandb: Agent Starting Run: dzm2qzm8 with config:\n",
      "\tdout_rate_2: 0.6\n",
      "\tdout_rate_1: 0.1\n",
      "wandb: Agent Started Run: dzm2qzm8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/dzm2qzm8\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/dzm2qzm8</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.0917 - mse: 19.0917 - val_loss: 12.6675 - val_mse: 12.6675\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.4727 - mse: 18.4727 - val_loss: 11.8638 - val_mse: 11.8638\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.3048 - mse: 17.3048 - val_loss: 10.1819 - val_mse: 10.1819\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.2591 - mse: 15.2591 - val_loss: 7.8489 - val_mse: 7.8489\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.5276 - mse: 12.5276 - val_loss: 6.3037 - val_mse: 6.3037\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 10.2275 - mse: 10.2275 - val_loss: 5.4746 - val_mse: 5.4746\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 8.6850 - mse: 8.6850 - val_loss: 5.0123 - val_mse: 5.0123\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 7.7301 - mse: 7.7301 - val_loss: 4.8304 - val_mse: 4.8304\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.9839 - mse: 6.9839 - val_loss: 4.7719 - val_mse: 4.7719\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.6265 - mse: 6.6265 - val_loss: 4.7576 - val_mse: 4.7576\n",
      "wandb: Agent Finished Run: dzm2qzm8 \n",
      "\n",
      "wandb: Agent Starting Run: cst747uf with config:\n",
      "\tdout_rate_2: 0\n",
      "\tdout_rate_1: 0.2\n",
      "wandb: Agent Started Run: cst747uf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/cst747uf\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/cst747uf</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 62ms/step - loss: 19.0417 - mse: 19.0417 - val_loss: 12.4811 - val_mse: 12.4811\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.1796 - mse: 18.1796 - val_loss: 11.3139 - val_mse: 11.3139\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.5666 - mse: 16.5665 - val_loss: 9.1871 - val_mse: 9.1871\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 13.6181 - mse: 13.6181 - val_loss: 6.7601 - val_mse: 6.7601\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.2107 - mse: 10.2107 - val_loss: 5.3793 - val_mse: 5.3793\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.7989 - mse: 7.7989 - val_loss: 4.8371 - val_mse: 4.8371\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.4441 - mse: 6.4441 - val_loss: 4.7958 - val_mse: 4.7958\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.6415 - mse: 5.6415 - val_loss: 5.1284 - val_mse: 5.1284\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.2565 - mse: 5.2565 - val_loss: 5.6873 - val_mse: 5.6873\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2399 - mse: 5.2399 - val_loss: 6.4293 - val_mse: 6.4293\n",
      "wandb: Agent Finished Run: cst747uf \n",
      "\n",
      "wandb: Agent Starting Run: ie59jn8d with config:\n",
      "\tdout_rate_2: 0.1\n",
      "\tdout_rate_1: 0.2\n",
      "wandb: Agent Started Run: ie59jn8d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/ie59jn8d\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/ie59jn8d</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.1067 - mse: 19.1067 - val_loss: 12.6209 - val_mse: 12.6209\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.3817 - mse: 18.3817 - val_loss: 11.6602 - val_mse: 11.6602\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.0171 - mse: 17.0171 - val_loss: 9.7634 - val_mse: 9.7634\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.4223 - mse: 14.4223 - val_loss: 7.4405 - val_mse: 7.4405\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.2581 - mse: 11.2581 - val_loss: 6.0055 - val_mse: 6.0055\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.9939 - mse: 8.9939 - val_loss: 5.2593 - val_mse: 5.2593\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.6365 - mse: 7.6365 - val_loss: 4.8762 - val_mse: 4.8762\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.6880 - mse: 6.6880 - val_loss: 4.7666 - val_mse: 4.7666\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1333 - mse: 6.1333 - val_loss: 4.7577 - val_mse: 4.7577\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.8675 - mse: 5.8675 - val_loss: 4.7883 - val_mse: 4.7883\n",
      "wandb: Agent Finished Run: ie59jn8d \n",
      "\n",
      "wandb: Agent Starting Run: sx1bab9g with config:\n",
      "\tdout_rate_2: 0.2\n",
      "\tdout_rate_1: 0.2\n",
      "wandb: Agent Started Run: sx1bab9g\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/sx1bab9g\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/sx1bab9g</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.1038 - mse: 19.1038 - val_loss: 12.6188 - val_mse: 12.6188\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.3851 - mse: 18.3851 - val_loss: 11.6588 - val_mse: 11.6588\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.0117 - mse: 17.0117 - val_loss: 9.7679 - val_mse: 9.7679\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.4869 - mse: 14.4869 - val_loss: 7.4541 - val_mse: 7.4541\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.4014 - mse: 11.4014 - val_loss: 6.0262 - val_mse: 6.0262\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.1076 - mse: 9.1076 - val_loss: 5.2776 - val_mse: 5.2776\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.8232 - mse: 7.8232 - val_loss: 4.8881 - val_mse: 4.8881\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.7926 - mse: 6.7926 - val_loss: 4.7701 - val_mse: 4.7701\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 6.1718 - mse: 6.1718 - val_loss: 4.7572 - val_mse: 4.7572\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.9054 - mse: 5.9054 - val_loss: 4.7886 - val_mse: 4.7886\n",
      "wandb: Agent Finished Run: sx1bab9g \n",
      "\n",
      "wandb: Agent Starting Run: nqgaukf1 with config:\n",
      "\tdout_rate_2: 0.4\n",
      "\tdout_rate_1: 0.2\n",
      "wandb: Agent Started Run: nqgaukf1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/nqgaukf1\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/nqgaukf1</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0982 - mse: 19.0982 - val_loss: 12.6251 - val_mse: 12.6251\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.4102 - mse: 18.4102 - val_loss: 11.6719 - val_mse: 11.6719\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.0482 - mse: 17.0482 - val_loss: 9.7914 - val_mse: 9.7914\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.5607 - mse: 14.5607 - val_loss: 7.4901 - val_mse: 7.4901\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.6764 - mse: 11.6764 - val_loss: 6.0711 - val_mse: 6.0711\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.3988 - mse: 9.3988 - val_loss: 5.3186 - val_mse: 5.3186\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.0481 - mse: 8.0481 - val_loss: 4.9179 - val_mse: 4.9179\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0510 - mse: 7.0510 - val_loss: 4.7823 - val_mse: 4.7823\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3542 - mse: 6.3542 - val_loss: 4.7567 - val_mse: 4.7567\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1300 - mse: 6.1300 - val_loss: 4.7770 - val_mse: 4.7770\n",
      "wandb: Agent Finished Run: nqgaukf1 \n",
      "\n",
      "wandb: Agent Starting Run: fq75xjr7 with config:\n",
      "\tdout_rate_2: 0.6\n",
      "\tdout_rate_1: 0.2\n",
      "wandb: Agent Started Run: fq75xjr7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/fq75xjr7\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/fq75xjr7</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0929 - mse: 19.0929 - val_loss: 12.7437 - val_mse: 12.7437\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.5757 - mse: 18.5757 - val_loss: 12.0149 - val_mse: 12.0149\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.5031 - mse: 17.5031 - val_loss: 10.4742 - val_mse: 10.4742\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.6122 - mse: 15.6122 - val_loss: 8.1409 - val_mse: 8.1409\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.8873 - mse: 12.8873 - val_loss: 6.4491 - val_mse: 6.4491\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.4503 - mse: 10.4503 - val_loss: 5.5500 - val_mse: 5.5500\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.8383 - mse: 8.8383 - val_loss: 5.0517 - val_mse: 5.0517\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.8480 - mse: 7.8480 - val_loss: 4.8492 - val_mse: 4.8492\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0761 - mse: 7.0761 - val_loss: 4.7800 - val_mse: 4.7800\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.6993 - mse: 6.6993 - val_loss: 4.7566 - val_mse: 4.7566\n",
      "wandb: Agent Finished Run: fq75xjr7 \n",
      "\n",
      "wandb: Agent Starting Run: jkwzaj7o with config:\n",
      "\tdout_rate_2: 0\n",
      "\tdout_rate_1: 0.4\n",
      "wandb: Agent Started Run: jkwzaj7o\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/jkwzaj7o\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/jkwzaj7o</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 62ms/step - loss: 19.0411 - mse: 19.0411 - val_loss: 12.4831 - val_mse: 12.4831\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.1797 - mse: 18.1797 - val_loss: 11.3250 - val_mse: 11.3250\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 16.5816 - mse: 16.5816 - val_loss: 9.2124 - val_mse: 9.2124\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 13.6495 - mse: 13.6495 - val_loss: 6.7866 - val_mse: 6.7866\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.2601 - mse: 10.2601 - val_loss: 5.3939 - val_mse: 5.3939\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.8345 - mse: 7.8345 - val_loss: 4.8408 - val_mse: 4.8408\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.4595 - mse: 6.4595 - val_loss: 4.7944 - val_mse: 4.7944\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.6464 - mse: 5.6464 - val_loss: 5.1249 - val_mse: 5.1249\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2577 - mse: 5.2577 - val_loss: 5.6829 - val_mse: 5.6829\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2391 - mse: 5.2391 - val_loss: 6.4298 - val_mse: 6.4298\n",
      "wandb: Agent Finished Run: jkwzaj7o \n",
      "\n",
      "wandb: Agent Starting Run: 9xl78i5u with config:\n",
      "\tdout_rate_2: 0.1\n",
      "\tdout_rate_1: 0.4\n",
      "wandb: Agent Started Run: 9xl78i5u\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/9xl78i5u\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/9xl78i5u</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.1060 - mse: 19.1060 - val_loss: 12.6218 - val_mse: 12.6218\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.3767 - mse: 18.3767 - val_loss: 11.6630 - val_mse: 11.6630\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.0305 - mse: 17.0305 - val_loss: 9.7703 - val_mse: 9.7703\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.4340 - mse: 14.4340 - val_loss: 7.4481 - val_mse: 7.4481\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 11.2682 - mse: 11.2682 - val_loss: 6.0100 - val_mse: 6.0100\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.0040 - mse: 9.0040 - val_loss: 5.2611 - val_mse: 5.2611\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.6406 - mse: 7.6406 - val_loss: 4.8767 - val_mse: 4.8767\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.6901 - mse: 6.6901 - val_loss: 4.7667 - val_mse: 4.7667\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.1341 - mse: 6.1341 - val_loss: 4.7577 - val_mse: 4.7577\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 5.8675 - mse: 5.8675 - val_loss: 4.7883 - val_mse: 4.7883\n",
      "wandb: Agent Finished Run: 9xl78i5u \n",
      "\n",
      "wandb: Agent Starting Run: zu8cfc84 with config:\n",
      "\tdout_rate_2: 0.2\n",
      "\tdout_rate_1: 0.4\n",
      "wandb: Agent Started Run: zu8cfc84\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/zu8cfc84\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/zu8cfc84</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.1056 - mse: 19.1056 - val_loss: 12.7389 - val_mse: 12.7389\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.5480 - mse: 18.5480 - val_loss: 11.9797 - val_mse: 11.9797\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 17.4711 - mse: 17.4711 - val_loss: 10.4094 - val_mse: 10.4094\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.3497 - mse: 15.3497 - val_loss: 8.0576 - val_mse: 8.0576\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 12.2435 - mse: 12.2435 - val_loss: 6.3325 - val_mse: 6.3325\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 9.6150 - mse: 9.6150 - val_loss: 5.4384 - val_mse: 5.4384\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.1574 - mse: 8.1574 - val_loss: 4.9642 - val_mse: 4.9642\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0295 - mse: 7.0295 - val_loss: 4.7966 - val_mse: 4.7966\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3448 - mse: 6.3448 - val_loss: 4.7587 - val_mse: 4.7587\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.0341 - mse: 6.0341 - val_loss: 4.7706 - val_mse: 4.7706\n",
      "wandb: Agent Finished Run: zu8cfc84 \n",
      "\n",
      "wandb: Agent Starting Run: 3zqpi66t with config:\n",
      "\tdout_rate_2: 0.4\n",
      "\tdout_rate_1: 0.4\n",
      "wandb: Agent Started Run: 3zqpi66t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/3zqpi66t\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/3zqpi66t</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.1002 - mse: 19.1002 - val_loss: 12.7428 - val_mse: 12.7428\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 18.5679 - mse: 18.5679 - val_loss: 11.9880 - val_mse: 11.9880\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.4934 - mse: 17.4934 - val_loss: 10.4262 - val_mse: 10.4262\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.3967 - mse: 15.3967 - val_loss: 8.0869 - val_mse: 8.0869\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.4811 - mse: 12.4811 - val_loss: 6.3755 - val_mse: 6.3755\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.8961 - mse: 9.8961 - val_loss: 5.4804 - val_mse: 5.4804\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.3801 - mse: 8.3801 - val_loss: 4.9978 - val_mse: 4.9978\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.2975 - mse: 7.2975 - val_loss: 4.8148 - val_mse: 4.8148\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.5391 - mse: 6.5391 - val_loss: 4.7637 - val_mse: 4.7637\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.2682 - mse: 6.2682 - val_loss: 4.7634 - val_mse: 4.7634\n",
      "wandb: Agent Finished Run: 3zqpi66t \n",
      "\n",
      "wandb: Agent Starting Run: 4icu42i1 with config:\n",
      "\tdout_rate_2: 0.6\n",
      "\tdout_rate_1: 0.4\n",
      "wandb: Agent Started Run: 4icu42i1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/4icu42i1\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/4icu42i1</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.0927 - mse: 19.0927 - val_loss: 12.7081 - val_mse: 12.7081\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.5217 - mse: 18.5217 - val_loss: 11.9535 - val_mse: 11.9535\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.4286 - mse: 17.4286 - val_loss: 10.3590 - val_mse: 10.3590\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.4738 - mse: 15.4738 - val_loss: 8.0423 - val_mse: 8.0423\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.7626 - mse: 12.7626 - val_loss: 6.4000 - val_mse: 6.4000\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.3819 - mse: 10.3819 - val_loss: 5.5234 - val_mse: 5.5234\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.7869 - mse: 8.7869 - val_loss: 5.0368 - val_mse: 5.0368\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.8089 - mse: 7.8089 - val_loss: 4.8415 - val_mse: 4.8415\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 7.0435 - mse: 7.0435 - val_loss: 4.7764 - val_mse: 4.7764\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.6714 - mse: 6.6714 - val_loss: 4.7568 - val_mse: 4.7568\n",
      "wandb: Agent Finished Run: 4icu42i1 \n",
      "\n",
      "wandb: Agent Starting Run: x07ewzde with config:\n",
      "\tdout_rate_2: 0\n",
      "\tdout_rate_1: 0.6\n",
      "wandb: Agent Started Run: x07ewzde\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/x07ewzde\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/x07ewzde</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 19.0429 - mse: 19.0429 - val_loss: 12.4858 - val_mse: 12.4858\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 18.1935 - mse: 18.1935 - val_loss: 11.3316 - val_mse: 11.3316\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 16.6021 - mse: 16.6021 - val_loss: 9.2262 - val_mse: 9.2262\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 13.7009 - mse: 13.7009 - val_loss: 6.8064 - val_mse: 6.8064\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 10.3067 - mse: 10.3067 - val_loss: 5.4112 - val_mse: 5.4112\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 7.8764 - mse: 7.8764 - val_loss: 4.8466 - val_mse: 4.8466\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.4843 - mse: 6.4843 - val_loss: 4.7911 - val_mse: 4.7911\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.6577 - mse: 5.6577 - val_loss: 5.1150 - val_mse: 5.1150\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2612 - mse: 5.2612 - val_loss: 5.6677 - val_mse: 5.6677\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 5.2369 - mse: 5.2369 - val_loss: 6.4109 - val_mse: 6.4109\n",
      "wandb: Agent Finished Run: x07ewzde \n",
      "\n",
      "wandb: Agent Starting Run: 5emxsf8n with config:\n",
      "\tdout_rate_2: 0.1\n",
      "\tdout_rate_1: 0.6\n",
      "wandb: Agent Started Run: 5emxsf8n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/5emxsf8n\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/5emxsf8n</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.1062 - mse: 19.1062 - val_loss: 12.7407 - val_mse: 12.7407\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.5536 - mse: 18.5536 - val_loss: 11.9819 - val_mse: 11.9819\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.4902 - mse: 17.4902 - val_loss: 10.4109 - val_mse: 10.4109\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.3116 - mse: 15.3116 - val_loss: 8.0396 - val_mse: 8.0396\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.1213 - mse: 12.1213 - val_loss: 6.3171 - val_mse: 6.3171\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.5183 - mse: 9.5183 - val_loss: 5.4250 - val_mse: 5.4250\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.9816 - mse: 7.9816 - val_loss: 4.9539 - val_mse: 4.9539\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.9313 - mse: 6.9313 - val_loss: 4.7928 - val_mse: 4.7928\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3105 - mse: 6.3105 - val_loss: 4.7586 - val_mse: 4.7586\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.0009 - mse: 6.0009 - val_loss: 4.7687 - val_mse: 4.7687\n",
      "wandb: Agent Finished Run: 5emxsf8n \n",
      "\n",
      "wandb: Agent Starting Run: h493ewjn with config:\n",
      "\tdout_rate_2: 0.2\n",
      "\tdout_rate_1: 0.6\n",
      "wandb: Agent Started Run: h493ewjn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/h493ewjn\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/h493ewjn</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 19.1040 - mse: 19.1040 - val_loss: 12.7394 - val_mse: 12.7394\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.5569 - mse: 18.5569 - val_loss: 11.9826 - val_mse: 11.9826\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.4849 - mse: 17.4849 - val_loss: 10.4154 - val_mse: 10.4154\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 15.3632 - mse: 15.3632 - val_loss: 8.0644 - val_mse: 8.0644\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 12.2748 - mse: 12.2748 - val_loss: 6.3345 - val_mse: 6.3345\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 9.6293 - mse: 9.6293 - val_loss: 5.4394 - val_mse: 5.4394\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 8.1604 - mse: 8.1604 - val_loss: 4.9650 - val_mse: 4.9650\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 7.0320 - mse: 7.0320 - val_loss: 4.7973 - val_mse: 4.7973\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.3487 - mse: 6.3487 - val_loss: 4.7589 - val_mse: 4.7589\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.0371 - mse: 6.0371 - val_loss: 4.7702 - val_mse: 4.7702\n",
      "wandb: Agent Finished Run: h493ewjn \n",
      "\n",
      "wandb: Agent Starting Run: uqh4wt7u with config:\n",
      "\tdout_rate_2: 0.4\n",
      "\tdout_rate_1: 0.6\n",
      "wandb: Agent Started Run: uqh4wt7u\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/uqh4wt7u\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/uqh4wt7u</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 61ms/step - loss: 19.0970 - mse: 19.0970 - val_loss: 12.6242 - val_mse: 12.6242\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.4162 - mse: 18.4162 - val_loss: 11.6712 - val_mse: 11.6712\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.0641 - mse: 17.0641 - val_loss: 9.7894 - val_mse: 9.7894\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.5666 - mse: 14.5666 - val_loss: 7.4841 - val_mse: 7.4841\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 11.6833 - mse: 11.6833 - val_loss: 6.0614 - val_mse: 6.0614\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 9.3927 - mse: 9.3927 - val_loss: 5.3098 - val_mse: 5.3098\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 8.0300 - mse: 8.0300 - val_loss: 4.9123 - val_mse: 4.9123\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 7.0348 - mse: 7.0348 - val_loss: 4.7800 - val_mse: 4.7800\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 6.3403 - mse: 6.3403 - val_loss: 4.7565 - val_mse: 4.7565\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 6.1167 - mse: 6.1167 - val_loss: 4.7788 - val_mse: 4.7788\n",
      "wandb: Agent Finished Run: uqh4wt7u \n",
      "\n",
      "wandb: Agent Starting Run: jjvz00ay with config:\n",
      "\tdout_rate_2: 0.6\n",
      "\tdout_rate_1: 0.6\n",
      "wandb: Agent Started Run: jjvz00ay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/sweeps/gtjs5xcp</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/fiscal-forcast/IMF/runs/jjvz00ay\" target=\"_blank\">https://app.wandb.ai/fiscal-forcast/IMF/runs/jjvz00ay</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 67 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 19.0898 - mse: 19.0898 - val_loss: 12.6265 - val_mse: 12.6265\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 18.4218 - mse: 18.4218 - val_loss: 11.7005 - val_mse: 11.7005\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 17.0888 - mse: 17.0888 - val_loss: 9.8319 - val_mse: 9.8319\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 14.8430 - mse: 14.8430 - val_loss: 7.5496 - val_mse: 7.5496\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 12.1488 - mse: 12.1488 - val_loss: 6.1468 - val_mse: 6.1468\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 9.9922 - mse: 9.9922 - val_loss: 5.3877 - val_mse: 5.3877\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 8.5048 - mse: 8.5048 - val_loss: 4.9670 - val_mse: 4.9670\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 7.5980 - mse: 7.5980 - val_loss: 4.8088 - val_mse: 4.8088\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 6.8779 - mse: 6.8779 - val_loss: 4.7639 - val_mse: 4.7639\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 6.5400 - mse: 6.5400 - val_loss: 4.7609 - val_mse: 4.7609\n",
      "wandb: Agent Finished Run: jjvz00ay \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweepid_4, function=train_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best values for dout_rate_1 and dout_rate_2: (0.2, 0.6)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size: 64   \n",
    "epoch: 20   \n",
    "nn_units_1: 32   \n",
    "nn_units_2: 32   \n",
    "dout_rate_1: 0.2   \n",
    "dout_rate_2: 0.6   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
